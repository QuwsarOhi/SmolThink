{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohi/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "from datasets import load_dataset, concatenate_datasets,  load_from_disk\n",
    "import peft\n",
    "\n",
    "# from safetensors.torch import load_model, save_model\n",
    "\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "import ast\n",
    "from copy import deepcopy\n",
    "from enum import Enum\n",
    "\n",
    "from typing import Optional\n",
    "from jinja2 import Template\n",
    "from transformers.utils import get_json_schema\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = \"360M\"\n",
    "MODEL_PATH = f\"HuggingFaceTB/SmolLM2-{SIZE}-Instruct\"\n",
    "LORA_PATH = None\n",
    "# dataset = load_from_disk(\"/Users/ohi/Documents/GitHub/PersonalAssistant/dataset\")\n",
    "dataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model took 0.72 GB of space (with buffer)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    # \"Qwen/Qwen2.5-Coder-0.5B-Instruct\",\n",
    "    device_map=\"cpu\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    # attn_implementation='sdpa',\n",
    "    # attn_implementation='eager', # 'flash_attention_2',\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    tie_word_embeddings=True,\n",
    "    trust_remote_code=True,\n",
    "    use_cache=False\n",
    ")\n",
    "\n",
    "# Gradient checkpointing - Could take more memory in MPS\n",
    "# model.gradient_checkpointing_enable(dict(use_reentrant=False))\n",
    "model.gradient_checkpointing_disable()\n",
    "# model.resize_token_embeddings(49162)\n",
    "print(f\"Model took {model.get_memory_footprint()/1e9:.2f} GB of space (with buffer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = peft.PeftModel.from_pretrained(\n",
    "   model,\n",
    "   \"/Users/ohi/Documents/GitHub/PersonalAssistant/SmolThink-360M-sft-r64-old/checkpoint-8700/smolthink\",\n",
    "   is_trainable=False, # ðŸ‘ˆ here,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): LlamaForCausalLM(\n",
      "      (model): LlamaModel(\n",
      "        (embed_tokens): ModulesToSaveWrapper(\n",
      "          (original_module): Embedding(49152, 960, padding_idx=2)\n",
      "          (modules_to_save): ModuleDict(\n",
      "            (default): Embedding(49152, 960, padding_idx=2)\n",
      "          )\n",
      "        )\n",
      "        (layers): ModuleList(\n",
      "          (0-31): 32 x LlamaDecoderLayer(\n",
      "            (self_attn): LlamaAttention(\n",
      "              (q_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=960, out_features=960, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=960, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=960, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=960, out_features=320, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=960, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=320, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=960, out_features=320, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=960, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=320, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=960, out_features=960, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=960, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=960, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "            )\n",
      "            (mlp): LlamaMLP(\n",
      "              (gate_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=960, out_features=2560, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=960, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=2560, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (up_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=960, out_features=2560, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=960, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=2560, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (down_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=2560, out_features=960, bias=False)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=2560, out_features=64, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=64, out_features=960, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
      "            (post_attention_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (norm): LlamaRMSNorm((960,), eps=1e-05)\n",
      "        (rotary_emb): LlamaRotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): ModulesToSaveWrapper(\n",
      "        (original_module): Linear(in_features=960, out_features=49152, bias=False)\n",
      "        (modules_to_save): ModuleDict(\n",
      "          (default): Linear(in_features=960, out_features=49152, bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "# 49152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed_tokens -> base_model.model.model.embed_tokens.original_module.weight : False\n",
      "embed_tokens -> base_model.model.model.embed_tokens.modules_to_save.smolthink.weight : True\n",
      "lm_head -> base_model.model.lm_head.modules_to_save.smolthink.weight : True\n",
      "Total LoRA params: 34.73 million (7.61 %) = 34.73 million\n",
      "Total LoRA layers: 448\n",
      "Approx size: 69.47 mb\n"
     ]
    }
   ],
   "source": [
    "# if lora_r:\n",
    "lora_r = 64\n",
    "# SAVE_PATH += f'r{lora_r}'\n",
    "peft_config = peft.LoraConfig(\n",
    "    r=lora_r,                   # 64\n",
    "    lora_alpha=2*lora_r,        # alpha = 4 * r\n",
    "    lora_dropout=0.05,\n",
    "    target_modules='all-linear',\n",
    "    modules_to_save = [\n",
    "        \"embed_tokens\", \n",
    "        \"lm_head\"\n",
    "    ],\n",
    "    use_rslora=True,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    init_lora_weights=\"gaussian\",\n",
    "    inference_mode=False,\n",
    ")\n",
    "model = peft.get_peft_model(model, peft_config, adapter_name=\"smolthink\", autocast_adapter_dtype=False)\n",
    "\n",
    "# Sanity check\n",
    "non_lora_param = 0\n",
    "lora_param = 0\n",
    "lora_layers = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if 'lora' in name:\n",
    "        # param.requires_grad = True\n",
    "        assert param.requires_grad == True, f\"{name} is not trainable\"\n",
    "        lora_param += param.numel()\n",
    "        lora_layers += 1\n",
    "    else:\n",
    "        # if not param.requires_grad:\n",
    "        #     print(f\"{name} is trainable\")\n",
    "        non_lora_param += param.numel()\n",
    "\n",
    "    if 'lm_head' in name:\n",
    "        print(\"lm_head ->\", name, \":\", param.requires_grad)\n",
    "    if 'embed_tokens' in name:\n",
    "        print(\"embed_tokens ->\", name, \":\", param.requires_grad)\n",
    "\n",
    "\n",
    "def into_million(val):\n",
    "    return f\"{val / 1000 / 1000 :.2f} million\"\n",
    "\n",
    "# print(\"LoRA adapter added.\")\n",
    "print(f\"Total LoRA params: {into_million(lora_param)} ({(lora_param/non_lora_param)*100:.2f} %) = {into_million(lora_param)}\")\n",
    "print(f\"Total LoRA layers: {lora_layers}\")\n",
    "print(f\"Approx size: {lora_param * 2e-6:.2f} mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModulesToSaveWrapper(\n",
       "  (original_module): Embedding(49152, 960, padding_idx=2)\n",
       "  (modules_to_save): ModuleDict(\n",
       "    (smolthink): Embedding(49152, 960, padding_idx=2)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model.model.model.embed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is same weight of embed_tokens and lm_head? True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(\"Is same weight of embed_tokens and lm_head?\", torch.equal(model.base_model.model.model.embed_tokens.modules_to_save[\"smolthink\"].weight, model.base_model.model.lm_head.modules_to_save[\"smolthink\"].weight))\n",
    "print(model.base_model.model.model.embed_tokens.original_module.weight.data.data_ptr() == model.base_model.model.lm_head.original_module.weight.data.data_ptr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.base_model.model.model.decoder.embed_tokens.modules_to_save[\"default\"].weight = model.base_model.model.lm_head.modules_to_save[\"default\"].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model took 0.72 GB of space (with buffer)\n"
     ]
    }
   ],
   "source": [
    "model = model.merge_and_unload(safe_merge=True).eval().to(torch.bfloat16)\n",
    "print(f\"Model took {model.get_memory_footprint()/1e9:.2f} GB of space (with buffer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409.00704\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters()) / 1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(49152, 960, padding_idx=2)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear(in_features=960, out_features=960, bias=False)\n",
      "          (k_proj): Linear(in_features=960, out_features=320, bias=False)\n",
      "          (v_proj): Linear(in_features=960, out_features=320, bias=False)\n",
      "          (o_proj): Linear(in_features=960, out_features=960, bias=False)\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
      "          (up_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
      "          (down_proj): Linear(in_features=2560, out_features=960, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
      "        (post_attention_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm((960,), eps=1e-05)\n",
      "    (rotary_emb): LlamaRotaryEmbedding()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=960, out_features=49152, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "embed_tokens -> base_model.model.model.embed_tokens.original_module.weight : False\n",
    "embed_tokens -> base_model.model.model.embed_tokens.modules_to_save.smolthink.weight : True\n",
    "lm_head -> base_model.model.lm_head.modules_to_save.smolthink.weight : True\n",
    "Total LoRA params: 34.73 million (7.61 %) = 34.73 million\n",
    "Total LoRA layers: 448\n",
    "Approx size: 69.47 mb\n",
    "Model took 0.82 GB of space (with buffer)\n",
    "409.00704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "69468160\n"
     ]
    }
   ],
   "source": [
    "total_param = 0\n",
    "for name, param in model.named_parameters():\n",
    "    print('lora' in name.lower())\n",
    "    total_param += param.numel()\n",
    "\n",
    "print(lora_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer length: 49152\n",
      "[44, 17400, 46]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "chat_template = \"\"\"{%- if tools %}\n",
    "    {{- '<|im_start|>system\\\\n' }}\n",
    "        {%- if messages[0]['role'] == 'system' %}\n",
    "            {- messages[0]['content'] }}\n",
    "        {%- else %}\n",
    "            {{- 'You are a helpful AI assistant named SmolThink.' }}\n",
    "        {%- endif %}\n",
    "    {{- \\\"\\\\n\\\\n# Tools\\\\n\\\\nYou may call one or more functions to assist with the user query.\\\\n\\\\nYou are provided with function signatures within <tools></tools> tags:\\\\n<tools>\\\" }}\n",
    "    {%- for tool in tools %}\n",
    "        {{- \\\"\\\\n\\\" }}\n",
    "            {{- tool | tojson }}\n",
    "    {%- endfor %}\n",
    "    {{- \\\"\\\\n</tools>\\\\n\\\\nYou first think/plan inside <think></think> tags.\\\\nThen for each function call, return a json object with function name and arguments within <tool_call></tool_call> tags.<|im_end|>\\\\n\\\" }}\n",
    "{%- else %}\n",
    "    {%- if messages[0]['role'] == 'system' %}\n",
    "        {{- '<|im_start|>system\\\\n' + messages[0]['content'] + '<|im_end|>\\\\n' }}\n",
    "    {%- else %}\n",
    "        {{- '<|im_start|>system\\\\nYou are a helpful AI assistant named SmolThink. First plan/reason/code/validate inside \\\\'think\\\\' tag and provide final answer to user query inside \\\\'answer\\\\' tag.\\\\nRespond in the following format:\\\\n<think>\\\\nLet\\\\'s think step by step...\\\\n</think>\\\\n<answer>\\\\nThe final answer is...\\\\n</answer><|im_end|>\\\\n' }}\n",
    "    {%- endif %}\n",
    "{%- endif %}\n",
    "{%- for message in messages %}\n",
    "    {%- if (message.role == \\\"user\\\") or (message.role == \\\"system\\\" and not loop.first) or (message.role == \\\"assistant\\\" and not message.tool_calls) %}\n",
    "        {{- '<|im_start|>' + message.role + '\\\\n' + message.content + '<|im_end|>' + '\\\\n' }}\n",
    "    {%- elif message.role == \\\"assistant\\\" %}\n",
    "        {{- '<|im_start|>' + message.role }}\n",
    "        {%- if message.content %}\n",
    "            {{- '\\\\n' + message.content }}\n",
    "        {%- endif %}\n",
    "        {%- for tool_call in message.tool_calls %}\n",
    "            {%- if tool_call.function is defined %}\n",
    "                {%- set tool_call = tool_call.function %}\n",
    "            {%- endif %}\n",
    "            {{- '\\\\n<tool_call>\\\\n{\\\"name\\\": \\\"' }}\n",
    "            {{- tool_call.name }}\n",
    "            {{- '\\\", \\\"arguments\\\": ' }}\n",
    "            {{- tool_call.arguments | tojson }}\n",
    "            {{- '}\\\\n</tool_call>' }}\n",
    "        {%- endfor %}\n",
    "        {{- '<|im_end|>\\\\n' }}\n",
    "    {%- elif message.role == \\\"tool\\\" %}\n",
    "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \\\"tool\\\") %}\n",
    "            {{- '<|im_start|>user' }}\n",
    "        {%- endif %}\n",
    "        {{- '\\\\n<tool_response>\\\\n' }}\n",
    "        {{- message.content }}\n",
    "        {{- '\\\\n</tool_response>' }}\n",
    "        {%- if loop.last or (messages[loop.index0 + 1].role != \\\"tool\\\") %}\n",
    "            {{- '<|im_end|>\\\\n' }}\n",
    "        {%- endif %}\n",
    "    {%- endif %}\n",
    "{%- endfor %}\n",
    "{%- if add_generation_prompt %}\n",
    "    {{- '<|im_start|>assistant\\\\n' }}\n",
    "{%- endif %}\"\"\"\n",
    "\n",
    "special_tokens_dict = {\n",
    "    \"bos_token\": \"<|im_start|>\",\n",
    "    \"eos_token\": \"<|im_end|>\",\n",
    "    \"pad_token\": \"<|im_end|>\",\n",
    "    \"unk_token\": \"<|endoftext|>\",\n",
    "    \"think_start\": \"<think>\",\n",
    "    \"think_end\": \"</think>\",\n",
    "    \"answer_start\": \"<answer>\",\n",
    "    \"answer_end\": \"</answer>\",\n",
    "    \"tool_def_start\": \"<tool>\",\n",
    "    \"tool_def_end\": \"</tool>\",\n",
    "    \"tool_call_start\": \"<tool_call>\",\n",
    "    \"tool_call_end\": \"</tool_call>\",\n",
    "    \"tool_res_start\": \"<tool_response>\",\n",
    "    \"tool_res_end\": \"</tool_response>\",\n",
    "}\n",
    "\n",
    "class SpecialTokens(str, Enum):\n",
    "    think_start = \"<think>\",\n",
    "    think_end = \"</think>\",\n",
    "    answer_start = \"<answer>\",\n",
    "    answer_end = \"</answer>\",\n",
    "    tool_def_start = \"<tool>\",\n",
    "    tool_def_end = \"</tool>\",\n",
    "    tool_call_start = \"<tool_call>\",\n",
    "    tool_call_end = \"</tool_call>\",\n",
    "    tool_res_start = \"<tool_response>\",\n",
    "    tool_res_end = \"</tool_response>\",\n",
    "\n",
    "    @classmethod\n",
    "    def list(cls):\n",
    "        return [c.value for c in cls]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    add_bos_token=True,\n",
    "    add_eos_token=True,\n",
    "    # additional_special_tokens=SpecialTokens.list()\n",
    ")\n",
    "tokenizer.chat_template = chat_template\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "\n",
    "print(\"Tokenizer length:\", len(tokenizer))\n",
    "tokenizer.save_pretrained(\"SmolThink-360M-Tokenizer\")\n",
    "\n",
    "\n",
    "# tokenizer.add_special_tokens(\n",
    "#     # special_tokens_dict=special_tokens_dict, \n",
    "#     {\"additional_special_tokens\":[\"<think>\"]},\n",
    "#     replace_additional_special_tokens=True)\n",
    "# print(\"Tokenizer length:\", len(tokenizer))\n",
    "\n",
    "# print(\"New token map\")\n",
    "# for v in SpecialTokens.list():\n",
    "#     print(v, '->', tokenizer.encode(v))\n",
    "# print(\"---\")\n",
    "\n",
    "# print(tokenizer.apply_chat_template([\n",
    "#     {\"role\": \"user\", \"content\": \"How are you?\"},\n",
    "#     {\"role\": \"assistant\", \"content\": \"I am fine\"}\n",
    "# ], tokenize=False))\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"retrieve_payment_status\",\n",
    "            \"description\": \"Get payment status of a transaction\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"transaction_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The transaction id.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"transaction_id\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"retrieve_payment_date\",\n",
    "            \"description\": \"Get payment date of a transaction\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"transaction_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The transaction id.\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"transaction_id\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "# print(\"\\n-----\\n\")\n",
    "# print(tokenizer.apply_chat_template([\n",
    "#     {\"role\": \"user\", \"content\": \"How are you?\"},\n",
    "#     {\"role\": \"assistant\", \"content\": \"<tool_call>[retrieve_payment_date(12)]</tool_call>\"},\n",
    "#     {\"role\": \"tool\", \"content\": \"12/12/12\"},\n",
    "#     {\"role\": \"assistant\", \"content\": \"12/12/12\"}\n",
    "# ], tools=tools, tokenize=False))\n",
    "\n",
    "print(tokenizer.encode(\"<think>\"))\n",
    "print(tokenizer.encode(\"<|im_start|>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/3570 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'Hi, can you tell me the current stock price of Apple?'}, {'role': 'assistant', 'content': \"<think>\\nAlright, the user asked for the current stock price of Apple. Looking at the tools available, there's a function called get_stock_price which exactly fits this request. I'll need to call this function with the parameter company set to 'Apple' to retrieve the information the user is asking for. This seems like the most straightforward and appropriate action to take.\\n</think>\\n<tool_call>\\n[{'name': 'get_stock_price', 'arguments': {'company': 'Apple'}}]\\n</tool_call>\"}, {'role': 'tool', 'content': \"{'stock_price': '$150.75'}\"}, {'role': 'assistant', 'content': 'The current stock price of Apple is $150.75.'}, {'role': 'user', 'content': \"That's great. Can you also tell me the stock price for Microsoft?\"}, {'role': 'assistant', 'content': \"<think>\\nAlright, let me try to figure out how to handle this user's request. The user first asked about Apple's stock price, and I responded by calling the get_stock_price function with 'Apple' as the argument. The tool provided the price, and I passed that information back to the user.\\n\\nNow, the user is asking for the stock price of Microsoft. I need to determine the appropriate action here. Looking at the tools available, there's still the get_stock_price function, which is designed to fetch current stock prices. Since the user is requesting another company's stock price, it makes sense to use the same function again but with the company name changed to Microsoft. \\n\\nI shouldn't assume any other tools are needed because the available functions are specifically tailored for stock prices and movie details. In this case, the relevant function is get_stock_price. I should ensure that the function is called with the correct parameter, 'Microsoft' in this case, to retrieve the accurate information the user is seeking. This approach is efficient and aligns directly with the user's request without making unnecessary assumptions or using unrelated tools.\\n</think>\\n<tool_call>\\n[{'name': 'get_stock_price', 'arguments': {'company': 'Microsoft'}}]\\n</tool_call>\"}, {'role': 'tool', 'content': \"{'stock_price': '$210.22'}\"}, {'role': 'assistant', 'content': 'The current stock price of Microsoft is $210.22.'}, {'role': 'user', 'content': 'Thank you for the information.'}, {'role': 'assistant', 'content': \"You're welcome! If you have any other questions, feel free to ask.\"}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m fc_dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJofthomas/hermes-function-calling-thinking-V1\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# fc_dataset = fc_dataset.select(range(100))\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m fc_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfc_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhermes_fc_thinking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m fc_dataset \u001b[38;5;241m=\u001b[39m fc_dataset\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconversations\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction calling dataset length (after filter):\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(fc_dataset))\n",
      "File \u001b[0;32m~/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:562\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    560\u001b[0m }\n\u001b[1;32m    561\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 562\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3079\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3074\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3075\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3076\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3077\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3078\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3079\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3080\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3081\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m~/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3495\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m batched:\n\u001b[1;32m   3494\u001b[0m     _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m-> 3495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miter_outputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_iterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mupdate_data\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3497\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3469\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.iter_outputs\u001b[0;34m(shard_iterable)\u001b[0m\n\u001b[1;32m   3467\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3469\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m i, \u001b[43mapply_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:3392\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function\u001b[0;34m(pa_inputs, indices, offset)\u001b[0m\n\u001b[1;32m   3390\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Utility to apply the function on a selection of columns.\"\"\"\u001b[39;00m\n\u001b[1;32m   3391\u001b[0m inputs, fn_args, additional_args, fn_kwargs \u001b[38;5;241m=\u001b[39m prepare_inputs(pa_inputs, indices, offset\u001b[38;5;241m=\u001b[39moffset)\n\u001b[0;32m-> 3392\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prepare_outputs(pa_inputs, inputs, processed_inputs)\n",
      "Cell \u001b[0;32mIn[7], line 52\u001b[0m, in \u001b[0;36mhermes_fc_thinking\u001b[0;34m(raw_data)\u001b[0m\n\u001b[1;32m     49\u001b[0m random\u001b[38;5;241m.\u001b[39mshuffle(tool_def)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(seq)\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[1;32m     53\u001b[0m ret \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(seq, tools\u001b[38;5;241m=\u001b[39mtool_def, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m#+ \"<tool_call>\\n\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconversations\u001b[39m\u001b[38;5;124m\"\u001b[39m: ret}\n",
      "\u001b[0;31mValueError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def extract_tag(input_str, tag):\n",
    "    tool_def = re.findall(f\"<{tag}>(.*?)</{tag}>\", input_str, re.DOTALL)\n",
    "    tool_def = map(str.strip, tool_def)\n",
    "    tool_def = filter(lambda x: len(x) > 0, tool_def)\n",
    "    return list(tool_def)\n",
    "\n",
    "def hermes_fc_thinking(raw_data):\n",
    "    data = deepcopy(raw_data['conversations'])\n",
    "    seq = []\n",
    "    tool_def = None\n",
    "    tool_names = None\n",
    "    for d in data:\n",
    "        if d['role'] == 'system':\n",
    "            tool_def = extract_tag(d['content'], 'tools')\n",
    "            if len(tool_def) != 0:\n",
    "                try:\n",
    "                    tool_def = ast.literal_eval(tool_def[0])\n",
    "                    tool_names = [tool['function']['name'] for tool in tool_def]\n",
    "                    continue\n",
    "                except Exception as E:\n",
    "                    return {\"conversations\": \"\"}\n",
    "            else:\n",
    "                return {\"conversations\": \"\"}\n",
    "\n",
    "        seq.append({})\n",
    "        seq[-1]['role'] = {\"human\": \"user\", \"model\": \"assistant\", \"system\": \"system\", \"tool\": \"tool\"}[d['role']]\n",
    "        seq[-1]['content'] = d['content']\n",
    "        if seq[-1]['role'] == 'assistant':\n",
    "            seq[-1]['content'] = seq[-1]['content'].replace('<think>', '<think>\\n')\n",
    "            seq[-1]['content'] = seq[-1]['content'].replace('</think>', '</think>\\n')\n",
    "            seq[-1]['content'] = seq[-1]['content'].replace('<tool_call>\\n', '<tool_call>\\n[')\n",
    "            seq[-1]['content'] = seq[-1]['content'].replace('\\n</tool_call>', ']\\n</tool_call>')\n",
    "            tool_calls = re.findall(r\"<tool_call>(.*?)</tool_call>\", seq[-1]['content'], re.DOTALL)\n",
    "            if tool_calls:\n",
    "                # print(tool_calls, tool_def)\n",
    "                try:\n",
    "                    tool_calls = json.loads(tool_calls[0].strip().replace(\"'\", '\"'))\n",
    "                    for tool_call in tool_calls:\n",
    "                        if tool_call['name'] not in tool_names:\n",
    "                            raise NotImplementedError\n",
    "                except Exception as E:\n",
    "                    return {\"conversations\": \"\"}\n",
    "        if seq[-1]['role'] == 'tool':\n",
    "            seq[-1]['content'] = seq[-1]['content'].replace(\"<tool_response>\", \"\")\n",
    "            seq[-1]['content'] = seq[-1]['content'].replace(\"</tool_response>\", \"\")\n",
    "            seq[-1]['content'] = seq[-1]['content'].strip()\n",
    "        # seq[-1]['content'] = d['value']\n",
    "    \n",
    "    random.shuffle(tool_def)\n",
    "    print(seq)\n",
    "\n",
    "    raise ValueError\n",
    "    ret = tokenizer.apply_chat_template(seq, tools=tool_def, tokenize=False, add_generation_prompt=False) #+ \"<tool_call>\\n\"\n",
    "    return {\"conversations\": ret}\n",
    "\n",
    "fc_dataset = load_dataset(\"Jofthomas/hermes-function-calling-thinking-V1\")['train']\n",
    "# fc_dataset = fc_dataset.select(range(100))\n",
    "fc_dataset = fc_dataset.map(hermes_fc_thinking)\n",
    "fc_dataset = fc_dataset.filter(lambda x: len(x['conversations']) > 0)\n",
    "print(\"Function calling dataset length (after filter):\", len(fc_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(49162, 960, padding_idx=2)\n"
     ]
    }
   ],
   "source": [
    "print(model.cpu().resize_token_embeddings(len(tokenizer)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(49162, 960, padding_idx=2)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "          (k_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "          (v_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "          (o_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "          (up_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "          (down_proj): Linear(in_features=2560, out_features=960, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((960,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=960, out_features=49162, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"/Users/ohi/Documents/GitHub/PersonalAssistant/SmolThink-Tokenizer\",\n",
    "    add_bos_token=True,\n",
    "    add_eos_token=True,\n",
    "    # additional_special_tokens=SpecialTokens.list()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49152]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokenizer.encode(\"<think>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/Users/ohi/Documents/GitHub/PersonalAssistant/SmolThink-Tokenizer/tokenizer_config.json',\n",
       " '/Users/ohi/Documents/GitHub/PersonalAssistant/SmolThink-Tokenizer/special_tokens_map.json',\n",
       " '/Users/ohi/Documents/GitHub/PersonalAssistant/SmolThink-Tokenizer/vocab.json',\n",
       " '/Users/ohi/Documents/GitHub/PersonalAssistant/SmolThink-Tokenizer/merges.txt',\n",
       " '/Users/ohi/Documents/GitHub/PersonalAssistant/SmolThink-Tokenizer/added_tokens.json',\n",
       " '/Users/ohi/Documents/GitHub/PersonalAssistant/SmolThink-Tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"/Users/ohi/Documents/GitHub/PersonalAssistant/SmolThink-Tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_end|> <|im_end|>\n",
      "[2]\n",
      "<issue_comment>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token, tokenizer.eos_token)\n",
    "print(tokenizer.encode(\"<|im_end|>\"))\n",
    "print(tokenizer.decode([9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_filter(data, limit):\n",
    "    # if data['thought_len'] + data['answer_len'] > 896:\n",
    "        # return False\n",
    "    return 0 < data['thought_len'] <= limit and 0 < data['answer_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1-distill dataset length (after filter): 29290\n"
     ]
    }
   ],
   "source": [
    "def r1distillsft_conv(data):\n",
    "    thought_len, answer_len = 0, 0\n",
    "    for idx, conv in enumerate(data['reannotated_messages']):\n",
    "        # print(conv)\n",
    "        role = conv['role']\n",
    "        if role == 'assistant':\n",
    "            reply = data['reannotated_messages'][idx]['content']\n",
    "            # print(reply)\n",
    "            thought = re.findall(r\"<think>(.*?)</think>\", reply, re.DOTALL)\n",
    "            thought = ''.join(thought).strip()\n",
    "            thought_len += len(thought.split()) #len(tokenizer.encode(thought))\n",
    "\n",
    "            end_tag = \"</think>\"\n",
    "            if end_tag in reply:\n",
    "                answer = reply[reply.find(end_tag)+len(end_tag):]\n",
    "                answer = answer.strip()\n",
    "            else:\n",
    "                answer = ''\n",
    "            if thought.lower() == answer.lower():\n",
    "                answer = ''\n",
    "            # print(\"Think:\", thought)\n",
    "            # print(\"Answer:\", answer)\n",
    "            # print(\"----\")\n",
    "            answer_len += len(answer.split()) #len(tokenizer.encode(answer))\n",
    "            data['reannotated_messages'][idx]['content'] = f\"<think>\\n{thought}\\n</think>\\n<answer>\\n{answer}\\n</answer>\"\n",
    "\n",
    "    if 'system' in data:\n",
    "        del data['system']\n",
    "    data['thought_len'] = thought_len\n",
    "    data['answer_len'] = answer_len\n",
    "    return data\n",
    "\n",
    "r1_dataset = load_dataset(\"ServiceNow-AI/R1-Distill-SFT\", \"v1\")['train']\n",
    "r1_dataset.shuffle(123)\n",
    "r1_dataset = r1_dataset.select(range(90_000))\n",
    "r1_dataset = r1_dataset.map(r1distillsft_conv)\n",
    "r1_dataset = r1_dataset.filter(lambda x: length_filter(x, 256))\n",
    "delete_keys = list(r1_dataset.column_names)\n",
    "r1_dataset = r1_dataset.map(lambda x: {\"conversations\": tokenizer.apply_chat_template(x['reannotated_messages'], tools=None, tokenize=False)})\n",
    "r1_dataset = r1_dataset.remove_columns(delete_keys)\n",
    "print(\"R1-distill dataset length (after filter):\", len(r1_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing dataset length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 666.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of data: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class DatasetGen_v1(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cache = None\n",
    "        self.cache_idx = -1\n",
    "        self.cache_len = 0\n",
    "        self.indices = []\n",
    "        self._get_len()\n",
    "\n",
    "    def _get_len(self):\n",
    "        print(\"Computing dataset length\")\n",
    "        for idx in tqdm(range(len(self.dataset))):\n",
    "            self.gen(idx)\n",
    "            for i in range(self.cache_len):\n",
    "                self.indices.append((idx, i))\n",
    "        print(\"Total length of data:\", len(self.indices))\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def gen(self, idx):\n",
    "        self.cache = self.dataset[idx]['conversations'].rstrip()\n",
    "        self.cache = self.tokenizer(\n",
    "            self.cache,\n",
    "            max_length=CONTEXT_LEN,\n",
    "            truncation=True,\n",
    "            return_overflowing_tokens=True, # Return the overflowing tokens\n",
    "            stride=CONTEXT_LEN // 8,\n",
    "            padding='max_length'\n",
    "        )\n",
    "        self.cache_idx = idx\n",
    "        self.cache_len = len(self.cache['input_ids'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        p, q = self.indices[idx]\n",
    "        if self.cache_idx != p:\n",
    "            self.gen(p)\n",
    "        \n",
    "        input_ids = self.cache['input_ids'][q]\n",
    "        attention_mask = self.cache['attention_mask'][q]\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "\n",
    "\n",
    "CONTEXT_LEN = 832 # 1024\n",
    "train_ds = DatasetGen_v1(\n",
    "    dataset=r1_dataset.select(range(10)), \n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolThink. First plan/reason/code/validate inside 'think' tag and provide final answer to user query inside 'answer' tag.\n",
      "Respond in the following format:\n",
      "<think>\n",
      "Let's think step by step...\n",
      "</think>\n",
      "<answer>\n",
      "The final answer is...\n",
      "</answer><|im_end|>\n",
      "<|im_start|>user\n",
      "There were 27 boys and 35 girls on the playground at recess. There were _____ children on the playground at recess.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "First, I need to determine the total number of children on the playground by adding the number of boys and girls.\n",
      "\n",
      "There are 27 boys and 35 girls.\n",
      "\n",
      "Adding these together: 27 boys + 35 girls = 62 children.\n",
      "\n",
      "Therefore, the total number of children on the playground is 62.\n",
      "</think>\n",
      "<answer>\n",
      "To find the total number of children on the playground, we simply add the number of boys and girls together.\n",
      "\n",
      "\\[\n",
      "\\text{Total children} = \\text{Number of boys} + \\text{Number of girls}\n",
      "\\]\n",
      "\n",
      "Plugging in the given values:\n",
      "\n",
      "\\[\n",
      "\\text{Total children} = 27 \\text{ boys} + 35 \\text{ girls} = 62 \\text{ children}\n",
      "\\]\n",
      "\n",
      "**Final Answer:**\n",
      "\n",
      "\\[\n",
      "\\boxed{62}\n",
      "\\]\n",
      "</answer><|im_end|>"
     ]
    }
   ],
   "source": [
    "for (t, m) in zip(train_ds[0]['input_ids'], train_ds[0]['attention_mask']):\n",
    "    if m == 1:\n",
    "        print(tokenizer.decode(t), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11770 17520\n"
     ]
    }
   ],
   "source": [
    "long, short = 0, 0\n",
    "for idx, d in enumerate(r1_dataset):\n",
    "    \n",
    "    # print(d['conversations'])\n",
    "#     s = d['conversations'].replace('''<|im_start|>system\n",
    "# You are a helpful AI assistant named SmolThink. First plan/reason/code/validate inside 'think' tag and provide final answer to user query inside 'answer' tag.\n",
    "# Respond in the following format:\n",
    "# <think>\n",
    "# Let's think step by step...\n",
    "# </think>\n",
    "# <answer>\n",
    "# The final answer is...\n",
    "# </answer><|im_end|>''', '')\n",
    "#     think_cnt = s.count(\"<think>\")\n",
    "#     ans_cnt = s.count(\"<answer>\")\n",
    "\n",
    "#     # print(s)\n",
    "#     if think_cnt > 1 or ans_cnt > 1:\n",
    "#         print(\"Check idx:\", idx)\n",
    "#         break\n",
    "    # break\n",
    "\n",
    "    en = tokenizer.encode(d['conversations'])\n",
    "    if len(en) > 832:\n",
    "        # print(idx, len(en))\n",
    "        long += 1\n",
    "    else:\n",
    "        short += 1\n",
    "\n",
    "print(long, short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4973 24317\n"
     ]
    }
   ],
   "source": [
    "long, short = 0, 0\n",
    "for idx, d in enumerate(r1_dataset):\n",
    "    \n",
    "    # print(d['conversations'])\n",
    "#     s = d['conversations'].replace('''<|im_start|>system\n",
    "# You are a helpful AI assistant named SmolThink. First plan/reason/code/validate inside 'think' tag and provide final answer to user query inside 'answer' tag.\n",
    "# Respond in the following format:\n",
    "# <think>\n",
    "# Let's think step by step...\n",
    "# </think>\n",
    "# <answer>\n",
    "# The final answer is...\n",
    "# </answer><|im_end|>''', '')\n",
    "#     think_cnt = s.count(\"<think>\")\n",
    "#     ans_cnt = s.count(\"<answer>\")\n",
    "\n",
    "#     # print(s)\n",
    "#     if think_cnt > 1 or ans_cnt > 1:\n",
    "#         print(\"Check idx:\", idx)\n",
    "#         break\n",
    "    # break\n",
    "\n",
    "    en = tokenizer.encode(d['conversations'])\n",
    "    if len(en) > 1024:\n",
    "        # print(idx, len(en))\n",
    "        long += 1\n",
    "    else:\n",
    "        short += 1\n",
    "\n",
    "print(long, short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 48026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolThink. First plan/reason/code/validate inside 'think' tag and provide final answer to user query inside 'answer' tag.\n",
      "Respond in the following format:\n",
      "<think>\n",
      "Let's think step by step...\n",
      "</think>\n",
      "<answer>\n",
      "The final answer is...\n",
      "</answer><|im_end|>\n",
      "<|im_start|>user\n",
      "Michael and Thomas are selling their lego collections. They agree to split any money they earn. They sell them based on how many circles are on top. Each circle costs 1 cent. They sold a certain number of single pieces, 45 double pieces, 50 triple pieces and 165 quadruple pieces. They earned $5 each. How many single pieces did they sell?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "First, I need to determine the total amount of money Michael and Thomas earned together. Since each earned $5 and they split the money equally, the total earnings amount to $10.\n",
      "\n",
      "Next, I'll calculate the earnings from the double, triple, and quadruple pieces separately.\n",
      "\n",
      "For the double pieces, there are 45 pieces with 2 circles each. Each circle costs 1 cent, so the earnings from double pieces are 45 * 2 * $0.01 = $0.90.\n",
      "\n",
      "For the triple pieces, there are 50 pieces with 3 circles each. The earnings from triple pieces are 50 * 3 * $0.01 = $1.50.\n",
      "\n",
      "For the quadruple pieces, there are 165 pieces with 4 circles each. The earnings from quadruple pieces are 165 * 4 * $0.01 = $6.60.\n",
      "\n",
      "Adding up the earnings from double, triple, and quadruple pieces: $0.90 + $1.50 + $6.60 = $9.00.\n",
      "\n",
      "Subtracting this from the total earnings gives the amount earned from single pieces: $10 - $9.00 = $1.00.\n",
      "\n",
      "Since each single piece earns 1 cent, the number of single pieces sold is $1.00 / $0.01 = 100.\n",
      "\n",
      "Therefore, Michael and Thomas sold 100 single pieces.\n",
      "</think>\n",
      "<answer>\n",
      "To determine how many single pieces Michael and Thomas sold, let's break down the problem step by step.\n",
      "\n",
      "### **Given:**\n",
      "- **Single pieces:** \\( x \\) pieces (unknown)\n",
      "- **Double pieces:** 45 pieces (each with 2 circles)\n",
      "- **Triple pieces:** 50 pieces (each with 3 circles)\n",
      "- **Quadruple pieces:** 165 pieces (each with 4 circles)\n",
      "- **Earnings per person:** \\$5\n",
      "- **Total earnings:** \\$10 (since they split the money equally)\n",
      "\n",
      "### **Step 1: Calculate Earnings from Each Type of Piece**\n",
      "\n",
      "1. **Double Pieces:**\n",
      "   \\[\n",
      "   45 \\text{ pieces} \\times 2 \\text{ circles/piece} \\times \\$0.01/\\text{circle} = \\$0.90\n",
      "   \\]\n",
      "\n",
      "2. **Triple Pieces:**\n",
      "   \\[\n",
      "   50 \\text{ pieces} \\times 3 \\text{ circles/piece} \\times \\$0.01/\\text{circle} = \\$1.50\n",
      "   \\]\n",
      "\n",
      "3. **Quadruple Pieces:**\n",
      "   \\[\n",
      "   165 \\text{ pieces} \\times 4 \\text{ circles/piece} \\times \\$0.01/\\text{circle} = \\$6.60\n",
      "   \\]\n",
      "\n",
      "### **Step 2: Calculate Total Earnings from Double, Triple, and Quadruple Pieces**\n",
      "\n",
      "\\[\n",
      "\\$0.90 + \\$1.50 + \\$6.60 = \\$9.00\n",
      "\\]\n",
      "\n",
      "### **Step 3: Determine Earnings from Single Pieces**\n",
      "\n",
      "Total earnings: \\$10  \n",
      "Earnings from other pieces: \\$9.00  \n",
      "Earnings from single pieces:  \n",
      "\\[\n",
      "\\$10 - \\$9.00 = \\$1.00\n",
      "\\]\n",
      "\n",
      "### **Step 4: Calculate the Number of Single Pieces Sold**\n",
      "\n",
      "Each single piece earns \\$0.01.  \n",
      "Number of single pieces:  \n",
      "\\[\n",
      "\\$1.00 \\div \\$0.01 = 100 \\text{ pieces}\n",
      "\\]\n",
      "\n",
      "### **Final Answer**\n",
      "\n",
      "\\[\n",
      "\\boxed{100}\n",
      "\\]\n",
      "</answer><|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(d['conversations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function calling dataset length (after filter): 3497\n"
     ]
    }
   ],
   "source": [
    "def extract_tag(input_str, tag):\n",
    "    tool_def = re.findall(f\"<{tag}>(.*?)</{tag}>\", input_str, re.DOTALL)\n",
    "    tool_def = map(str.strip, tool_def)\n",
    "    tool_def = filter(lambda x: len(x) > 0, tool_def)\n",
    "    return list(tool_def)\n",
    "\n",
    "def hermes_fc_thinking(raw_data):\n",
    "    data = deepcopy(raw_data['conversations'])\n",
    "    seq = []\n",
    "    tool_def = None\n",
    "    tool_names = None\n",
    "    for d in data:\n",
    "        if d['role'] == 'system':\n",
    "            tool_def = extract_tag(d['content'], 'tools')\n",
    "            if len(tool_def) != 0:\n",
    "                try:\n",
    "                    tool_def = ast.literal_eval(tool_def[0])\n",
    "                    tool_names = [tool['function']['name'] for tool in tool_def]\n",
    "                    continue\n",
    "                except Exception as E:\n",
    "                    return {\"conversations\": \"\"}\n",
    "            else:\n",
    "                return {\"conversations\": \"\"}\n",
    "\n",
    "        seq.append({})\n",
    "        seq[-1]['role'] = {\"human\": \"user\", \"model\": \"assistant\", \"system\": \"system\", \"tool\": \"tool\"}[d['role']]\n",
    "        seq[-1]['content'] = d['content']\n",
    "        if seq[-1]['role'] == 'assistant':\n",
    "            seq[-1]['content'] = seq[-1]['content'].replace('<think>', '<think>\\n')\n",
    "            seq[-1]['content'] = seq[-1]['content'].replace('</think>', '</think>\\n')\n",
    "            # seq[-1]['content'] = seq[-1]['content'].replace('<tool_call>\\n', '<tool_call>\\n[')\n",
    "            # seq[-1]['content'] = seq[-1]['content'].replace('\\n</tool_call>', ']\\n</tool_call>')\n",
    "            tool_calls = re.findall(r\"<tool_call>(.*?)</tool_call>\", seq[-1]['content'], re.DOTALL)\n",
    "            seq[-1]['tool-call'] = []\n",
    "            if tool_calls:\n",
    "                # print(tool_calls, tool_def)\n",
    "                for tool_call in tool_calls:\n",
    "                    try:\n",
    "                        tool_call = json.loads(tool_call.strip().replace(\"'\", '\"'))\n",
    "                        if tool_call['name'] not in tool_names:\n",
    "                            raise NotImplementedError\n",
    "                        seq[-1]['tool_call'] = tool_call\n",
    "                    except Exception as E:\n",
    "                        return {\"conversations\": \"\"}\n",
    "        if seq[-1]['role'] == 'tool':\n",
    "            seq[-1]['content'] = seq[-1]['content'].replace(\"<tool_response>\", \"\")\n",
    "            seq[-1]['content'] = seq[-1]['content'].replace(\"</tool_response>\", \"\")\n",
    "            seq[-1]['content'] = seq[-1]['content'].strip()\n",
    "        # seq[-1]['content'] = d['value']\n",
    "    \n",
    "    random.shuffle(tool_def)\n",
    "    ret = tokenizer.apply_chat_template(seq, tools=tool_def, tokenize=False, add_generation_prompt=False) #+ \"<tool_call>\\n\"\n",
    "    return {\"conversations\": ret}\n",
    "\n",
    "fc_dataset = load_dataset(\"Jofthomas/hermes-function-calling-thinking-V1\")['train']\n",
    "# fc_dataset = fc_dataset.select(range(100))\n",
    "fc_dataset = fc_dataset.map(hermes_fc_thinking)\n",
    "fc_dataset = fc_dataset.filter(lambda x: len(x['conversations']) > 0)\n",
    "print(\"Function calling dataset length (after filter):\", len(fc_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolThink.\n",
      "\n",
      "# Tools\n",
      "\n",
      "You may call one or more functions to assist with the user query.\n",
      "\n",
      "You are provided with function signatures within <tools></tools> tags:\n",
      "<tools>\n",
      "{\"type\": \"function\", \"function\": {\"name\": \"get_stock_price\", \"description\": \"Get the current stock price of a company\", \"parameters\": {\"type\": \"object\", \"properties\": {\"company\": {\"type\": \"string\", \"description\": \"The name of the company\"}}, \"required\": [\"company\"]}}}\n",
      "{\"type\": \"function\", \"function\": {\"name\": \"get_movie_details\", \"description\": \"Get details about a movie\", \"parameters\": {\"type\": \"object\", \"properties\": {\"title\": {\"type\": \"string\", \"description\": \"The title of the movie\"}}, \"required\": [\"title\"]}}}\n",
      "</tools>\n",
      "\n",
      "You first think/plan inside <think></think> tags.\n",
      "Then for each function call, return a json object with function name and arguments within <tool_call></tool_call> tags.<|im_end|>\n",
      "<|im_start|>user\n",
      "Hi, can you tell me the current stock price of Apple?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "Alright, the user asked for the current stock price of Apple. Looking at the tools available, there's a function called get_stock_price which exactly fits this request. I'll need to call this function with the parameter company set to 'Apple' to retrieve the information the user is asking for. This seems like the most straightforward and appropriate action to take.\n",
      "</think>\n",
      "<tool_call>\n",
      "{'name': 'get_stock_price', 'arguments': {'company': 'Apple'}}\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "<tool_response>\n",
      "{'stock_price': '$150.75'}\n",
      "</tool_response><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The current stock price of Apple is $150.75.<|im_end|>\n",
      "<|im_start|>user\n",
      "That's great. Can you also tell me the stock price for Microsoft?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "Alright, let me try to figure out how to handle this user's request. The user first asked about Apple's stock price, and I responded by calling the get_stock_price function with 'Apple' as the argument. The tool provided the price, and I passed that information back to the user.\n",
      "\n",
      "Now, the user is asking for the stock price of Microsoft. I need to determine the appropriate action here. Looking at the tools available, there's still the get_stock_price function, which is designed to fetch current stock prices. Since the user is requesting another company's stock price, it makes sense to use the same function again but with the company name changed to Microsoft. \n",
      "\n",
      "I shouldn't assume any other tools are needed because the available functions are specifically tailored for stock prices and movie details. In this case, the relevant function is get_stock_price. I should ensure that the function is called with the correct parameter, 'Microsoft' in this case, to retrieve the accurate information the user is seeking. This approach is efficient and aligns directly with the user's request without making unnecessary assumptions or using unrelated tools.\n",
      "</think>\n",
      "<tool_call>\n",
      "{'name': 'get_stock_price', 'arguments': {'company': 'Microsoft'}}\n",
      "</tool_call><|im_end|>\n",
      "<|im_start|>user\n",
      "<tool_response>\n",
      "{'stock_price': '$210.22'}\n",
      "</tool_response><|im_end|>\n",
      "<|im_start|>assistant\n",
      "The current stock price of Microsoft is $210.22.<|im_end|>\n",
      "<|im_start|>user\n",
      "Thank you for the information.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "You're welcome! If you have any other questions, feel free to ask.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fc_dataset[0]['conversations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk(\"/Users/ohi/Documents/GitHub/PersonalAssistant/datasets/merged_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'input', 'output', 'thought_len', 'answer_len', 'conversations'],\n",
       "    num_rows: 34125\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in ds:\n",
    "    conv = d['conversations']\n",
    "    if conv.count(\"</answer>\") > 2:\n",
    "        print(conv)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since XeTute/Open-Coding-Thoughts couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /Users/ohi/.cache/huggingface/datasets/XeTute___open-coding-thoughts/default/0.0.0/b63d89b184b9048a18e2cd42be298db6e44ab255 (last modified on Sun Mar 16 12:25:21 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length: 1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1025/1025 [00:00<00:00, 15778.30 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n    Before organizing my code, I should consider the following to avoid mistakes:\\n    *   Make sure to create a clear directory structure to keep related files together.\\n    *   Use a consistent naming convention for your files and variables to avoid confusion.\\n    *   Be mindful of the file path and import statements to avoid errors.\\n    ', \"\\n    Before defining variables, I should consider the following to avoid mistakes:\\n    *   Make sure to use a consistent naming convention for variables to avoid confusion.\\n    *   Avoid using magic numbers or hardcoded values, as they can be difficult to maintain.\\n    *   Consider using a preprocessor-specific syntax for variables, such as Sass's `$` symbol or Less's `@` symbol.\\n    \", \"\\n    Before creating mixins and functions, I should consider the following to avoid mistakes:\\n    *   Make sure to use a consistent naming convention for mixins and functions to avoid confusion.\\n    *   Avoid over-engineering and keep the code simple and easy to understand.\\n    *   Consider using a preprocessor-specific syntax for mixins and functions, such as Sass's `@mixin` directive or Less's `.extend` method.\\n    \", \"\\n    Before using inheritance and nesting, I should consider the following to avoid mistakes:\\n    *   Make sure to use a consistent naming convention for classes and IDs to avoid confusion.\\n    *   Avoid over-nesting and keep the code simple and easy to understand.\\n    *   Consider using a preprocessor-specific syntax for inheritance and nesting, such as Sass's `@extend` directive or Less's `.extend` method.\\n    \", \"\\n    Before using a preprocessor-specific syntax, I should consider the following to avoid mistakes:\\n    *   Make sure to read and understand the documentation for the preprocessor you're using.\\n    *   Avoid using outdated or deprecated features, as they may not be supported in future versions.\\n    *   Consider using a code editor or IDE that provides support for the preprocessor-specific syntax, such as Sass's `scss` file type or Less's `less` file type.\\n    \"]\n",
      "[\"\\n\\n*   When dealing with large-scale projects, it's easy to get overwhelmed by the sheer amount of CSS code.\\n*   Modularizing your CSS code will help you break it down into smaller, manageable chunks.\\n*   This will make it easier to maintain and update individual components without affecting the entire project.\\n*   To modularize your CSS, consider creating separate files for different components or sections of your project.\\n\\n\", \"\\n\\n*   When working on a large team, it's essential to establish a consistent naming convention for your CSS classes.\\n*   This will help prevent conflicts and make it easier for others to understand your code.\\n*   Consider using a naming convention like BEM (Block, Element, Modifier) or OOCSS (Object-Oriented CSS).\\n\\n\", '\\n\\n*   Using broad, generic CSS selectors can lead to unintended styling of other elements on your page.\\n*   Instead, use specific selectors that target the exact elements you want to style.\\n*   Consider using the descendant combinator (` `) to target specific elements within a parent element.\\n\\n', '\\n\\n*   Inline styles can make it difficult to maintain and update your CSS code.\\n*   Instead, define your styles in an external CSS file.\\n*   Use a tool like a CSS preprocessor to help manage your styles.\\n\\n', '\\n\\n*   CSS preprocessors like Sass and Less can help you write more efficient and maintainable CSS code.\\n*   Tools like Gulp and Webpack can automate the concatenation and minification of your CSS files.\\n*   Consider using a tool like CSS Lint to help identify potential issues with your CSS code.\\n\\n', '\\n\\n*   Testing and debugging your CSS code is crucial to ensuring it works as intended.\\n*   Use tools like the Chrome DevTools or Firefox Developer Edition to test and debug your CSS code.\\n*   Consider using a tool like CSS Lint to help identify potential issues with your CSS code.\\n\\n', '\\n\\n*   Reviewing and refactoring your CSS code is essential to ensuring it remains maintainable and efficient.\\n*   Consider using a tool like CSS Lint to help identify potential issues with your CSS code.\\n*   Use a tool like a code analyzer to help identify potential issues with your CSS code.\\n\\n']\n",
      "[\"\\n\\nFirst, I need to design the HTML structure for the table. This will include a header row, a dropdown menu for selecting the number, and the table itself.\\n\\nNext, I need to think about how to link the dropdown menu to the table. I will use JavaScript to update the table when a number is selected from the dropdown menu.\\n\\nI will use CSS to style the table, making it look visually appealing.\\n\\nI will also think about how to handle errors, such as when the user selects a number outside the range of 1-10.\\n\\nNow, let's start designing the HTML code.\\n\\n\", \"\\n\\nNext, I need to write the CSS code to style the table. This will include setting the table's width and border, and styling the table's rows and columns.\\n\\nI will also think about how to handle errors, such as when the user selects a number outside the range of 1-10.\\n\\nNow, let's start writing the CSS code.\\n\\n\", \"\\n\\nNext, I need to write the JavaScript code to update the table when a number is selected. This will include getting the selected number from the dropdown menu, creating the table rows and columns, and updating the table's content.\\n\\nI will also think about how to handle errors, such as when the user selects a number outside the range of 1-10.\\n\\nNow, let's start writing the JavaScript code.\\n\\n\"]\n",
      "[\"\\n\\nTo create a responsive navigation menu, I'll consider the following requirements:\\n\\n*   A navigation menu that adapts to different screen sizes and devices (responsive design)\\n*   A clean and simple layout\\n*   Easy navigation for users with assistive technologies (e.g., screen readers)\\n\\nI'll start by designing a basic HTML structure for the navigation menu and then apply CSS styles to make it responsive.\\n\\n\", \"\\n\\nTo make this navigation menu responsive, I'll use CSS media queries to apply different styles based on screen size. I'll also use a CSS framework (in this case, Bootstrap) to simplify the process.\\n\\nOne potential mistake I might make is not considering screen reader users, who may have difficulty navigating menus with complex layouts. To fix this, I'll use ARIA attributes to provide a clear and consistent navigation experience.\\n\\nAnother potential mistake is not testing the responsiveness of the navigation menu on different devices and browsers. To fix this, I'll use tools like BrowserStack or CodePen to test the menu on various devices and browsers.\\n\\n\", \"\\n\\nTo further improve this design, I could use a CSS framework like Bootstrap to simplify the process of creating a responsive navigation menu. I could also use JavaScript to add interactivity to the menu, such as hover effects or animations.\\n\\nOne potential mistake I might make is not considering the accessibility of the navigation menu. To fix this, I'll use ARIA attributes to provide a clear and consistent navigation experience.\\n\\nAnother potential mistake is not testing the responsiveness of the navigation menu on different devices and browsers. To fix this, I'll use tools like BrowserStack or CodePen to test the menu on various devices and browsers.\\n\\n\"]\n",
      "['\\nFirst, I need to create a basic HTML file structure. I will include a `<script>` tag to link the JavaScript file.\\nNext, I will write the JavaScript code to display a greeting message when the page loads.\\nI need to ensure that the JavaScript code is correct and will not throw any errors.\\nI will also consider the security implications of directly executing JavaScript code from an HTML file. \\n', '\\nI will create a new file called greeting.js and write the JavaScript code to display the greeting message.\\nI will use the `window.onload` event to ensure that the code is executed when the page has finished loading.\\nI will also consider the best practices for coding, such as using a more secure way to execute the JavaScript code.\\n']\n",
      "[\"\\nI need to create a CSS rule that targets an HTML element with the class 'submit-button'. The rule should specify the styles for this element. However, I need to consider that CSS rules are case-sensitive and class selectors are usually defined inside a CSS selector, so I'll need to use a CSS selector that targets the class.\\n\", \"\\nTo ensure I don't make any mistakes, I've double-checked the CSS syntax. The above code defines a CSS rule that targets an HTML element with the class 'submit-button'. The styles defined are for a basic button with a green background color and white text. The padding and border radius are set to 10px and 5px respectively. The cursor is set to a pointing hand to indicate that the button is clickable. The font size is set to 16px. However, I also need to consider that this is a basic example and might need to be adjusted based on the specific requirements of the project.\\n\"]\n",
      "[\"\\n\\nBefore writing the script, I need to consider the following:\\n\\n1. What is the structure of the CSV file? Are there any header rows or specific column names?\\n2. What data manipulation is required? Is it as simple as filtering, sorting, or grouping data or do we need to perform more complex operations like data cleansing or data transformation?\\n3. Are there any specific libraries or dependencies required to read and manipulate the CSV file?\\n4. How should I handle errors or exceptions that may occur during the data manipulation process?\\n\\nAssuming the CSV file is well-structured and the data manipulation is relatively simple, I'll provide a basic script to get us started.\\n\\n\", '\\n\\nTo improve this script, I could consider the following:\\n\\n1. Add error handling mechanisms to handle exceptions that may occur during the data manipulation process.\\n2. Validate the structure of the CSV file to ensure it matches the expected format.\\n3. Provide more complex data manipulation operations, such as data cleansing or transformation.\\n4. Consider using more advanced libraries or tools to handle large-scale data manipulation tasks.\\n\\n']\n",
      "['\\n\\n*   The DOCTYPE declaration must be included at the beginning of the file.\\n*   The HTML tag is the root element of the HTML document.\\n*   The head section is used for the metadata of the document, such as the title, styles, and scripts.\\n*   The body section is where the content of the HTML document is placed.\\n*   In the head section, a link tag is used to link the external CSS file.\\n*   A script tag is used to link the external JavaScript file.\\n\\n', '\\n\\n*   The CSS style block is linked in the head section of the HTML file.\\n*   The CSS style block must have the same name as the linked file, in this case, style.css.\\n*   The body tag in CSS is used to select the HTML element with the tag name body.\\n*   The background-color property is used to set the background color of the element.\\n\\n', '\\n\\n*   The JavaScript function is linked in the body section of the HTML file.\\n*   The JavaScript function must be placed inside a script tag.\\n*   The console.log() function is used to output messages to the console.\\n*   The message to be logged must be placed inside the console.log() function.\\n\\n']\n",
      "[\"\\n\\nFirst, I need to determine the best way to simulate a coin toss. Since C++ does not have a built-in random number generator, I can use the `rand()` function to generate a random number. However, `rand()` is not recommended for generating random numbers for security or statistical purposes, so I will use the `random` library which is more secure.\\n\\nNext, I need to decide how to use the generated random number to determine the outcome of the coin toss. I can use a simple if statement to check if the number is even or odd, and return 'heads' or 'tails' accordingly.\\n\\nHowever, I also need to consider the potential mistakes I could make. One mistake could be to forget to include the necessary headers for the `random` library. Another mistake could be to not check if the random number generator is actually generating a random number.\\n\\n\", '\\n\\nA better way to simulate a coin toss would be to use the XOR shift algorithm to generate a random number. This algorithm is more complex than a simple if statement, but it is also more secure and more unpredictable.\\n\\nTo use the XOR shift algorithm, I need to generate a random number using the `random` library, and then use that number to calculate a new number using the XOR shift formula. I can then use that new number to determine the outcome of the coin toss.\\n\\nHowever, I also need to consider the potential mistakes I could make. One mistake could be to forget to include the necessary headers for the `random` library. Another mistake could be to not check if the random number generator is actually generating a random number.\\n\\n']\n",
      "[\"\\n\\nTo solve this problem, we need to:\\n\\n1. Import a library that will allow us to generate HTML. We'll use `string` and `template` for this, although it's worth noting that using Jinja2 or a similar templating engine would be a more conventional approach.\\n\\n2. Define a function that will take in the title and generate the HTML.\\n\\n3. Ensure that we're handling any potential errors that might occur during this process.\\n\\n\", \"\\n\\nIn this script, we use the `string` module to check if the title is a string and to remove any non-ASCII characters from it. We then define a function `generate_html` that takes in the title and returns the generated HTML.\\n\\nThe function first checks if the title is a string. If it's not, it raises a `TypeError`. It then removes any non-ASCII characters from the title to avoid encoding issues. Finally, it generates the HTML using an f-string and returns it.\\n\\nIn the example usage, we define a title and pass it to the `generate_html` function. The generated HTML is then printed out.\\n\\nMistakes I could make:\\n\\n* Not checking if the title is a string, which could lead to a `TypeError` or other errors.\\n* Not removing non-ASCII characters from the title, which could lead to encoding issues.\\n* Not handling potential errors that might occur during the generation of the HTML.\\n\\nTo fix these mistakes, I would:\\n\\n* Add a type check for the title to ensure it's a string.\\n* Remove non-ASCII characters from the title to avoid encoding issues.\\n* Handle potential errors that might occur during the generation of the HTML, such as raising a `TypeError` or other exceptions.\\n\\n\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1025/1025 [00:00<00:00, 13955.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenThought dataset length (after filter): 1025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def openthought_code(data):\n",
    "    thought_len, answer_len = 0, 0\n",
    "\n",
    "    reply = data['output']\n",
    "    thought = re.findall(r\"<thoughts>(.*?)</thoughts>\", reply, re.DOTALL)\n",
    "    if len(thought) > 1:\n",
    "        print(thought)\n",
    "    thought = ''.join(thought).strip()\n",
    "    thought_len += len(thought.split())\n",
    "    \n",
    "    end_tag = \"</thoughts>\"\n",
    "    answer = reply[reply.find(end_tag)+len(end_tag):]\n",
    "    answer = answer.strip()\n",
    "    answer_len += len(answer.split()) #len(tokenizer.encode(answer))\n",
    "\n",
    "    if end_tag not in reply:\n",
    "        answer_len = 0\n",
    "\n",
    "    final_answer = f\"<think>\\n{thought}\\n</think>\\n<answer>\\n{answer}\\n</answer>\"\n",
    "    final_answer = final_answer.replace(\"<thoughts>\", \"\").replace(\"</thoughts>\", \"\")\n",
    "    \n",
    "    output_data = {\n",
    "        'thought_len': thought_len,\n",
    "        'answer_len': answer_len,\n",
    "        'conversations': [\n",
    "            {\"role\": \"user\", 'content': data['input']},\n",
    "            {\"role\": \"assistant\", 'content': final_answer}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    return output_data\n",
    "\n",
    "openthought_dataset = load_dataset(\"XeTute/Open-Coding-Thoughts\")['train']\n",
    "print(\"Dataset length:\", len(openthought_dataset))\n",
    "openthought_dataset = openthought_dataset.map(openthought_code)\n",
    "openthought_dataset = openthought_dataset.map(lambda x: {\"conversations\": tokenizer.apply_chat_template(x['conversations'], tools=None, tokenize=False)})\n",
    "print(\"OpenThought dataset length (after filter):\", len(openthought_dataset))\n",
    "# print(openthought_dataset[0]['conversations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8133/8133 [00:08<00:00, 984.77 examples/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"open-r1/codeforces-cots\", \"solutions_py_decontaminated\")['train']\n",
    "\n",
    "def take(d):\n",
    "    return len(d['generation'].split()) <= 2000\n",
    "\n",
    "ds = ds.filter(take)\n",
    "print(len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to solve this problem where I have to convert a given integer n into its binary representation without leading zeros. Let's think about how to approach this.\n",
      "\n",
      "The problem says that n can be up to 1e6. Wait, 1e6 isn't that big. But even so, I need an efficient way to convert it to binary. But what's the standard way to do this in Python?\n",
      "\n",
      "Hmm, Python has built-in functions for this. Like bin(n), which returns a string starting with '0b', so I can just slice that off. For example, bin(5) gives '0b101', so removing the first two characters gives '101'. That's exactly what the examples show. So for the input 5, output is 101. So using bin() seems straightforward.\n",
      "\n",
      "But wait, the problem says to output without leading zeros. But bin() automatically doesn't have leading zeros except for the case when n is 0, but since n is a positive integer (as per the problem statement), n can't be zero. So using bin(n)[2:] should give the correct result.\n",
      "\n",
      "So the code would be something like:\n",
      "\n",
      "n = int(input())\n",
      "print(bin(n)[2:])\n",
      "\n",
      "That's really simple. But is there any case where this might not work? Like when n is 1? Let's see. bin(1) is '0b1', so [2:] is '1', which is correct.\n",
      "\n",
      "What about edge cases like n=1e6? Let's compute 1e6 in binary. Well, bin(1000000) is '0b11110100001001000000', which when sliced gives the correct binary.\n",
      "\n",
      "This approach is O(1) time because converting an integer to binary in Python is done efficiently, even for large numbers. Since the maximum n is 1e6, which is manageable, this method should work within the time constraints. The built-in functions are optimized in C, so they're much faster than any manual implementation.\n",
      "\n",
      "Another approach would be to manually compute the binary digits by dividing n by 2 each time and collecting the remainders. But that's more code and possibly less efficient. For example:\n",
      "\n",
      "res = []\n",
      "while n > 0:\n",
      "    res.append(str(n % 2))\n",
      "    n = n // 2\n",
      "res.reverse()\n",
      "print(''.join(res))\n",
      "\n",
      "But this would also work and has O(log n) time complexity, which is acceptable. But why write all that code when Python's built-in does it more efficiently?\n",
      "\n",
      "So the optimal approach is to use bin() and slice off the first two characters. It's the fastest and most memory-efficient way. The code is straightforward and will handle all test cases within the constraints.\n",
      "\n",
      "Testing the examples:\n",
      "\n",
      "For input 5: bin(5)[2:] â†’ '101', correct.\n",
      "\n",
      "For input 13: bin(13)[2:] â†’ '1101', correct.\n",
      "\n",
      "So the code should work.\n",
      "</think>\n",
      "\n",
      "```python\n",
      "n = int(input())\n",
      "print(bin(n)[2:])\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(ds[0]['generation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is 16*8?\n",
      "Assistant: 16 * 8 = 128\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>{% for message in messages %}{{message['role'] | capitalize}}{% if message['content'][0]['type'] == 'image' %}{{':'}}{% else %}{{': '}}{% endif %}{% for line in message['content'] %}{% if line['type'] == 'text' %}{{line['text']}}{% elif line['type'] == 'image' %}{{ '<image>' }}{% endif %}{% endfor %}<end_of_utterance>\n",
      "{% endfor %}{% if add_generation_prompt %}{{ 'Assistant:' }}{% endif %}\n"
     ]
    }
   ],
   "source": [
    "print(processor.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<|im_start|>{% for message in messages %}\n",
    "  {{message['role'] | capitalize}}\n",
    "  {% if message['content'][0]['type'] == 'image' %}{{':'}}\n",
    "  {% else %}{{': '}}\n",
    "  {% endif %}\n",
    "  {% for line in message['content'] %}\n",
    "    {% if line['type'] == 'text' %}{{line['text']}}\n",
    "    {% elif line['type'] == 'image' %}{{ '<image>' }}\n",
    "    {% endif %}\n",
    "  {% endfor %}<end_of_utterance>\n",
    "{% endfor %}{% if add_generation_prompt %}{{ 'Assistant:' }}{% endif %}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [\"Muhammad Yunus[a] (born 28 June 1940) is a Bangladeshi economist, businessman, and politician who has been serving as Chief Adviser of the Interim Government of Bangladesh since 8 August 2024.[1] Yunus was awarded the Nobel Peace Prize in 2006 for founding the Grameen Bank and pioneering the concepts of microcredit and microfinance.[2] Yunus has received several other national and international honors, including the United States Presidential Medal of Freedom in 2009 and the Congressional Gold Medal in 2010.[3]\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohi/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Search Results\n",
      "\n",
      "[List of presidents of Russia - Wikipedia](https://en.wikipedia.org/wiki/List_of_presidents_of_Russia)\n",
      "The office of the president of Russia is the highest authority in the Russian Federation.The holder is the federation's head of state and has formal presidency over the State Council as well as being the commander in chief of the Russian Armed Forces.The office was introduced in 1918 after the February Revolution with the current office emerging after a referendum of 1991. [1]\n",
      "\n",
      "[Vladimir Putin - Wikipedia](https://en.wikipedia.org/wiki/Vladimir_Putin)\n",
      "Putin, FIFA president Gianni Infantino and French president Emmanuel Macron at the 2018 FIFA World Cup Final in Russia as French forward Kylian MbappÃ© receives the best young player award In 2007, Putin led a successful effort on behalf of Sochi for the 2014 Winter Olympics and the 2014 Winter Paralympics , [ 469 ] the first Winter Olympic Games to ever be hosted by Russia.\n",
      "\n",
      "[President of Russia - Wikipedia](https://en.wikipedia.org/wiki/President_of_Russia)\n",
      "The president of Russia, officially the president of the Russian Federation (Russian: ÐŸÑ€ÐµÐ·Ð¸Ð´ÐµÐ½Ñ‚ Ð Ð¾ÑÑÐ¸Ð¹ÑÐºÐ¾Ð¹ Ð¤ÐµÐ´ÐµÑ€Ð°Ñ†Ð¸Ð¸, romanized: Prezident Rossiyskoy Federatsii), is the executive head of state of Russia.The president is the chair of the Federal State Council and the supreme commander-in-chief of the Russian Armed Forces.It is the highest office in Russia.\n",
      "\n",
      "[Vladimir Putin | Biography, KGB, Political Career, & Facts | Britannica](https://www.britannica.com/biography/Vladimir-Putin)\n",
      "Vladimir Putin (born October 7, 1952, Leningrad, Russia, U.S.S.R. [now St. Petersburg, Russia]) is a Russian intelligence officer and politician who has served as president (1999-2008 and 2012- ) of Russia and as the country's prime minister (1999 and 2008-12). One of the 21st century's most influential leaders, Putin has shaped his country's political landscape for decades with a ...\n",
      "\n",
      "[Biographies of presidents of Russia - President of Russia](http://www.en.kremlin.ru/structure/president/presidents)\n",
      "Since May 8, 2008, Vladimir Putin is a Prime Minister of Russia. 2012 On March 4, 2012, he was elected President of Russia and inaugurated on May 7, 2012. 2018 On March 18, 2018, he was re-elected President of Russia. Assumed office on May 7, 2018. 2024 Won Russia's presidential election held on March 15-17, 2024.\n",
      "\n",
      "[Who has power in Russia president or prime minister?](https://www.ncesc.com/geographic-faq/who-has-power-in-russia-president-or-prime-minister/)\n",
      "The current president of Russia is Vladimir Putin. He has held positions as both president and prime minister since 1999. Is Putin a prime minister or a president? Vladimir Putin has served as both president and prime minister of Russia. Since 1999, he has continuously held these positions, serving as prime minister from 1999 to 2000 and from ...\n",
      "\n",
      "[Persons âˆ™ Directory âˆ™ President of Russia](http://en.kremlin.ru/catalog/persons/54/biography)\n",
      "On March 14, 2004, he was elected President of Russia for the second term. 2008 Since May 8, 2008, Vladimir Putin is a Prime Minister of Russia. 2012 On March 4, 2012, he was elected President of Russia and inaugurated on May 7, 2012. 2018 On March 18, 2018, he was re-elected President of Russia. Assumed office on May 7, 2018. 2024\n",
      "\n",
      "[President âˆ™ Structure âˆ™ President of Russia](http://en.kremlin.ru/structure/president)\n",
      "President of Russia The President of the Russian Federation is the head of state and guarantor of the Constitution and of human and civil rights and freedoms. The President is elected for a 6-year term by the Russian Federation's citizens on the basis of universal, equal and direct suffrage by secret ballot.\n",
      "\n",
      "[Vladimir Putin: Who is the Russian President, and what does he want? - BBC](https://www.bbc.co.uk/newsround/60521909)\n",
      "Vladimir Putin is the President of Russia, and has been the country's leader for more than 22 years. He has been in the news a lot recently because of his decision to invade the country of Ukraine.\n",
      "\n",
      "[Putin inaugurated as president for fifth term with Russia under ... - CNN](https://www.cnn.com/2024/05/07/europe/putin-inauguration-russia-president-fifth-term-intl/index.html)\n",
      "Vladimir Putin has formally begun his fifth term as Russia's president in a carefully choreographed inauguration ceremony, in a country he has shaped in his image after first taking office ...\n"
     ]
    }
   ],
   "source": [
    "from smolagents import DuckDuckGoSearchTool\n",
    "\n",
    "search_tool = DuckDuckGoSearchTool()\n",
    "print(search_tool(\"Who's the current president of Russia?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 251/251 [00:00<00:00, 3643.22 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 251/251 [00:00<00:00, 4417.61 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General reason dataset length: 251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "def process(data):\n",
    "    for idx, message in enumerate(data['messages']):\n",
    "        if message['role'] != 'assistant': continue\n",
    "        content = message['content']\n",
    "        tag = \"</think>\"\n",
    "        pos = content.find(tag)\n",
    "        answer = content[pos+len(tag):].strip()\n",
    "        data['messages'][idx]['content'] = content[:pos].strip() + f\"\\n</think>\\n<answer>\\n{answer}\\n</answer>\"\n",
    "    return data\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "codeforces_cot = load_dataset(\"open-r1/codeforces-cots\", \"solutions_py_decontaminated\")['train']#.select(range(500))\n",
    "codeforces_cot = codeforces_cot.filter(lambda x: len(str(x['messages'])) < 8000)\n",
    "delete_keys = list(codeforces_cot.column_names)\n",
    "codeforces_cot = codeforces_cot.map(process)\n",
    "codeforces_cot = codeforces_cot.map(lambda x: {\"conversations\": tokenizer.apply_chat_template(x['messages'], tools=None, tokenize=False)})\n",
    "codeforces_cot = codeforces_cot.remove_columns(delete_keys)\n",
    "print(\"Codeforces CoT dataset length:\", len(codeforces_cot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful AI assistant named SmolThink. First plan/reason/code/validate inside 'think' tag and provide final answer to user query inside 'answer' tag.\n",
      "Respond in the following format:\n",
      "<think>\n",
      "Let's think step by step...\n",
      "</think>\n",
      "<answer>\n",
      "The final answer is...\n",
      "</answer><|im_end|>\n",
      "<|im_start|>user\n",
      "You will be given a competitive programming problem.\n",
      "Analyze the maximum input constraints and identify the optimal algorithmic approach and data structures needed to process the largest possible test cases within the time and memory limits, then explain why your chosen implementation strategy is the most efficient solution. Please reason step by step about your solution approach, then provide a complete implementation in Python 3 that is thoroughly optimized for both speed and memory usage.\n",
      "\n",
      "Your solution must read input from standard input (input()), write output to standard output (print()).\n",
      "Do not include any debug prints or additional output.\n",
      "\n",
      "Put your final solution within a single code block:\n",
      "```python\n",
      "<your code here>\n",
      "```\n",
      "\n",
      "# Problem\n",
      "\n",
      "You are given a positive integer n. Output its binary notation.\n",
      "\n",
      "## Constraints\n",
      "Time limit per test: 2.0 seconds\n",
      "Memory limit per test: 256.0 megabytes\n",
      "\n",
      "## Input Format\n",
      "The only line of input data contains an integer n (1 â‰¤ n â‰¤ 106).\n",
      "\n",
      "## Output Format\n",
      "Output the binary notation of n (without any leading zeros).\n",
      "\n",
      "## Examples\n",
      "```input\n",
      "5\n",
      "```\n",
      "```output\n",
      "101\n",
      "```\n",
      "-----\n",
      "```input\n",
      "13\n",
      "```\n",
      "```output\n",
      "1101\n",
      "```\n",
      "\n",
      "## Note\n",
      "In the first example 5 = 1 * 22 + 0 * 21 + 1 * 20.\n",
      "<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "Okay, I need to solve this problem where I have to convert a given integer n into its binary representation without leading zeros. Let's think about how to approach this.\n",
      "\n",
      "The problem says that n can be up to 1e6. Wait, 1e6 isn't that big. But even so, I need an efficient way to convert it to binary. But what's the standard way to do this in Python?\n",
      "\n",
      "Hmm, Python has built-in functions for this. Like bin(n), which returns a string starting with '0b', so I can just slice that off. For example, bin(5) gives '0b101', so removing the first two characters gives '101'. That's exactly what the examples show. So for the input 5, output is 101. So using bin() seems straightforward.\n",
      "\n",
      "But wait, the problem says to output without leading zeros. But bin() automatically doesn't have leading zeros except for the case when n is 0, but since n is a positive integer (as per the problem statement), n can't be zero. So using bin(n)[2:] should give the correct result.\n",
      "\n",
      "So the code would be something like:\n",
      "\n",
      "n = int(input())\n",
      "print(bin(n)[2:])\n",
      "\n",
      "That's really simple. But is there any case where this might not work? Like when n is 1? Let's see. bin(1) is '0b1', so [2:] is '1', which is correct.\n",
      "\n",
      "What about edge cases like n=1e6? Let's compute 1e6 in binary. Well, bin(1000000) is '0b11110100001001000000', which when sliced gives the correct binary.\n",
      "\n",
      "This approach is O(1) time because converting an integer to binary in Python is done efficiently, even for large numbers. Since the maximum n is 1e6, which is manageable, this method should work within the time constraints. The built-in functions are optimized in C, so they're much faster than any manual implementation.\n",
      "\n",
      "Another approach would be to manually compute the binary digits by dividing n by 2 each time and collecting the remainders. But that's more code and possibly less efficient. For example:\n",
      "\n",
      "res = []\n",
      "while n > 0:\n",
      "    res.append(str(n % 2))\n",
      "    n = n // 2\n",
      "res.reverse()\n",
      "print(''.join(res))\n",
      "\n",
      "But this would also work and has O(log n) time complexity, which is acceptable. But why write all that code when Python's built-in does it more efficiently?\n",
      "\n",
      "So the optimal approach is to use bin() and slice off the first two characters. It's the fastest and most memory-efficient way. The code is straightforward and will handle all test cases within the constraints.\n",
      "\n",
      "Testing the examples:\n",
      "\n",
      "For input 5: bin(5)[2:] â†’ '101', correct.\n",
      "\n",
      "For input 13: bin(13)[2:] â†’ '1101', correct.\n",
      "\n",
      "So the code should work.\n",
      "</think>\n",
      "<answer>\n",
      "```python\n",
      "n = int(input())\n",
      "print(bin(n)[2:])\n",
      "```\n",
      "</answer><|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(codeforces_cot[0]['conversations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: smolagents 1.12.0\n",
      "Uninstalling smolagents-1.12.0:\n",
      "  Would remove:\n",
      "    /Users/ohi/Documents/GitHub/PersonalAssistant/.venv/bin/smolagent\n",
      "    /Users/ohi/Documents/GitHub/PersonalAssistant/.venv/bin/webagent\n",
      "    /Users/ohi/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/smolagents-1.12.0.dist-info/*\n",
      "    /Users/ohi/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/smolagents/*\n",
      "Proceed (Y/n)? ^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall smolagents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "15 Best CI/CD Tools That You Should Know - GeeksforGeeks\n",
      "\n",
      "Skip to content\n",
      "CoursesDSA to DevelopmentMachine Learning & Data ScienceGenerative AI & ChatGPTBecome AWS CertifiedDSA CoursesData Structure & Algorithm(C++/JAVA)Data Structure & Algorithm(Python)Data Structure & Algorithm(JavaScript)Programming LanguagesCPPJavaPythonJavaScriptCAll CoursesTutorialsPythonPython TutorialPython ProgramsPython QuizPython ProjectsPython Interview QuestionsPython Data StructuresJavaJava TutorialJava CollectionsJava 8 TutorialJava ProgramsJava QuizJava ProjectsJava Interview QuestionsAdvanced JavaProgramming LanguagesJavaScriptC++R TutorialSQLPHPC#CScalaPerlGo LanguageKotlinInterview CornerSystem Design TutorialCompany PreparationTop TopicsPractice Company QuestionsInterview ExperiencesExperienced InterviewsInternship InterviewsCompetitive ProgrammingMultiple Choice QuizzesAptitude for PlacementsComputer Science SubjectsOperating SystemDBMSComputer NetworksEngineering MathematicsComputer Organization and ArchitectureTheory of ComputationCompiler DesignDigital LogicSoftware EngineeringDevOps and LinuxDevOps TutorialGITAWSDockerKubernetesMicrosoft Azure TutorialGoogle Cloud PlatformLinux TutorialSoftware TestingSoftware Testing TutorialSoftware Engineering TutorialTesting Interview QuestionsJiraDatabasesDBMS TutorialSQL TutorialPostgreSQL TutorialMongoDB TutorialSQL Interview QuestionsMySQL Interview QuestionsPL/SQL Interview QuestionsAndroidAndroid TutorialAndroid Studio TutorialKotlin For AndroidAndroid ProjectsAndroid Interview Questions6 Weeks of Android App DevelopmentExcelMS Excel TutorialIntroduction to MS ExcelData Analysis in ExcelBasic Excel Formulas & FunctionsData Analysis in Advanced ExcelWorkbooksStatistical FunctionsData Visualization in ExcelPivot Tables in ExcelExcel Spreadsheets in PythonBasic Excel ShortcutsMathematicsNumber SystemAlgebraLinear AlgebraTrigonometrySet TheoryStatisticsProbabilityGeometryMensurationLogarithmsCalculusDSADSA TutorialPracticePractice Coding ProblemsProblem of the DayGfG SDE SheetCompetitive ProgrammingCompany Wise SDE SheetsFacebook SDE SheetAmazon SDE SheetApple SDE SheetNetflix SDE SheetGoogle SDE SheetTop Interview QuestionsPuzzlesAll PuzzlesTop 100 Puzzles Asked In InterviewsTop 20 Puzzles Commonly Asked During SDE InterviewsData SciencePython TutorialR TutorialMachine LearningData Science using PythonData Science using RData Science PackagesPandas TutorialNumPy TutorialData VisualizationPython Data Visualization TutorialData Visualization with RData AnalysisData Analysis with PythonData Analysis with RDeep LearningNLP TutorialWeb TechHTML TutorialCSS TutorialJavaScript TutorialPHP TutorialReactJS TutorialNodeJS TutorialBootstrap TutorialTypescriptWeb Development Using PythonDjango TutorialFlask TutorialPostmanGithubCheat SheetsHTML Cheat SheetCSS Cheat SheetJavaScript Cheat SheetReact Cheat SheetAngular Cheat SheetjQuery Cheat SheetBootstrap Cheat SheetLearn Complete Web Development\n",
      "DevOps LifecycleDevOps RoadmapDocker TutorialKubernetes TutorialsAmazon Web Services [AWS] TutorialAZURE TutorialsGCP TutorialsDocker Cheat sheetKubernetes cheat sheetAWS interview questionsDocker Interview QuestionsAnsible Interview QuestionsJenkins Interview Questions \n",
      "\n",
      "â–²\n",
      "\n",
      "Open In App\n",
      "\n",
      "Next Article:\n",
      "Understanding Deployment Automation\n",
      "15 Best CI/CD Tools That You Should Know\n",
      "Last Updated : \n",
      "18 Sep, 2024\n",
      "\n",
      "Summarize\n",
      "\n",
      "Comments\n",
      "Improve\n",
      "Suggest changes\n",
      "\n",
      "Like Article\n",
      "Like\n",
      "\n",
      "Share\n",
      "Report\n",
      "Follow\n",
      "Continuous Integration and Continuous Delivery (CI/CD) is modern-day practices to continuously improve the software by adding new feature and for that we have to change the existing files and deploy them. Doing it manually every time may consume a lot of developer's time, so to make the process more simple and reliable developers use CI/CD tools that are much more efficient and make the whole process automated. As a software Engineer or beginner in development, you should know the best CI/CD tools.As you go deep into software development, you will ultimately need these tools to save time and release a more reliable and stable version of your software application with proper automated testing and deploying processes. But before knowing the tools letâ€™s first under what exactly is CI and CD.What is CI/CD?CI and CD stand for continuous Integration and are continuous Deployment/Delivery which is used in the process of building efficient software. These are the approaches that are used to integrate the code changes into a shared repository (Continuous Integration) while automating the testing and deployment process to the staging and production environment (Continuous Delivery). These approaches are used to provide a more reliable and stable version of a software application by testing it before release to end-users with the help of CI/CD Tools.Â To learn more about CI/CD, refer to this article- Continuous Integration and Continuous Delivery15 Best CI/CD Tools For DevelopersContinuous Integration and Continuous Delivery are not only necessary to build a great application but also help the business in meeting its various requirements, from automating tasks to receiving quick feedback, so that developers can improve the application accordingly. They are both combined known as continuous software development. In this process of developing efficient applications, developers have created some CI/CS Tools that help the software engineers test the software application effectively. Here are some of the best CI/CD tools that you should know1. JenkinsJenkins is one of the most popular and effective CI/CD tools which is an open-source automation server. It provides several functionalities like automation testing, deploying code changes for smooth collaboration among the teams of product development, and faster identification of issues. It has a feature â€œPipeline as Codeâ€ which allows developers to manage their deployment pipelines programmatically. It has a master-slave architecture which is very useful in their efficient resource usage. It also has a large community support to help new developers. To enhance the quality of software and increase the speed of delivery of applications, Jenkins has played a very important role.To learn more, refer to - JenkinsFeatures:Extensibility with PluginsPipeline as CodeDistributed Builds2. Travis CIFor the automation process of building, testing, and deploying software applications there are various CI/CD tools in the market but among those Travis CI is one of the most popular and useful tools that software developers prefer over other tools due to its crucial role in the software development lifecycle by checking the reliability and quality of code changes before integrating into the production codebase. Automatic building and testing of code during push commands and support for various languages and frameworks are some of the important factors that differentiate these CI/CD tools from the others. All of its feature ensures smooth development workflows and faster feedback, so Travis CI enables collaboration decrease integration issues, and help the developers build more high-quality software applications.To learn more, refer to - Travis CIFeatures:GitHub IntegrationBuild MatrixCaching Dependencies3. GitLabGitLab is a web-based platform that provides multiple tools and functionalities to developers to provide help in the process of the software development lifecycle. It is one of the most common CI/CD tools that is used by the developers which provide several useful functionalities like collaborative project management, continuous integration and continuous deployment pipelines, code review, and issue tracking with the help of version control through Git repositories. GitLab allows development teams to manage the collaborative project in real-time and track progress within an integrated environment. It is very flexible for various development workflows and is available in both private servers and as a cloud-hosted service.To learn more, refer to - GitLabFeaturesIntegrated DevOps PlatformContainer Registry and Kubernetes IntegrationBuilt-in Issue Tracking and Collaboration4. DockerDocker is a software platform that is used in the process of software development by providing special functionalities such as building, testing, and deploying software applications. Dockerâ€™s libraries, system tools, code, and runtime are stored in standard units called containers. The software that hosts the container is known as Docker Engine. It offers both free and premium services that completely depend on the use case. To use the resources efficiently, Docker uses OS-level virtualization. The application and its dependencies can be packaged into a portable format that can run on any system that supports Docker.To learn more, refer to - DockerFeaturesContainerization TechnologyImage-Based DeploymentIsolation and Resource Efficiency5. TeamCityOne of the widely used CI/CD server tools is TeamCity which is developed by JetBrains. Since it is a CI/CD tool then definitely is used for the automation of building, testing, and deploying software applications. And one of the most helpful parts of it is that TeamCity has a very user-friendly web interface, It can easily integrate with popular version control systems like Git and Subversion, also integrate with cloud platforms, and has the ability to trigger builds based on code commits. Projects of different sizes and complexities can easily use these tools due to their flexibility and extensibility.To learn more, refer to - TeamCityFeaturesCross-Platform CompatibilityBuild Chains and DependenciesAdvanced Build and Deployment Workflows6. SemaphoreSemaphore is one of the fastest-growing CI/CD tools for DevOps in the software industry that allows you to deploy various software updates every day on platforms like Linux, Android, and macOS with no barriers. Semaphore allow teams to deploy applications through customizable pipelines triggered by code changes. It also automates the process of build, testing, and deploying the software application process with a continuous feedback loop to improve the application continuously to make it a stable and reliable application. This CI/CD tool is an example of an amazing tool that allows an end-to-end development process.FeaturesYAML-Based ConfigurationParallel and Distributed TestingContinuous Delivery Pipelines7. Circle CIWhen it comes to using cloud-based CI/CD tools that automate and optimize the software development lifecycle, Circle CI is the very first tool that developers prioritize. CircleCI supports container-based builds for a consistent environment with parallel and distributed testing and an advanced caching mechanism to speed up build times. It also supports multiple programming languages and frameworks, allowing development teams to customize their workflows on the cloud platform itself. CircleCI helps in debugging early in the development process and ensures that the code quality is good to make reliable software products.FeaturesOrbs for Reusable ConfigurationWorkspaces for Data SharingCloud-Based and Self-Hosted Option8. BambooBamboo is a continuous integration and continuous delivery (CI/CD) tool which is developed by Atlassian. The purpose behind the Bamboo tools is to make the software development process very simple by automating the various stages such as building, testing, and deploying the code changes. Development teams can create pipelines that automatically trigger code commits when necessary and help in integration and collaboration. Bamboo helps product development teams with faster feedback loops and improves their code quality to make stable releases of software applications with the help of automated CI/CD pipelines.FeaturesIntegration with Atlassian EcosystemDocker and Container SupportJIRA Integration and Release Management9. BuddyBuddy is a CI/CD tool and is one of the modern and user-friendly platforms to automate software development workflows. To set up a complex workflow, Buddy provides us with a visual pipeline builder that makes it easy to visualize the workflow and it also has built-in Docker support for containerized builds and deployments. It is also integrated with various cloud providers. It is very suitable for every development team size due to its flexible and intuitive interface and extensive features.FeaturesPipeline as CodeDeployment AutomationServerless Actions10. Azure DevOps ServerAzure DevOps server is a CI/CD tool which is created by Microsoft that provides various functionalities such as version control, reporting, requirements management, project management, testing, and several other capabilities. It was formerly known as Team Foundation Server (TFS). It is a cloud-based service that is much more suitable for an organization that requires physical hosting due to security, compliance, or any other reasons. Since it is a product of Microsoft, it integrates well with other Microsoft products as well. It supports the entire software development lifecycle by providing tools for version control, agile planning, and CI/CD.To learn more, refer to - Azure DevOps serverFeaturesCustomizable Work Items and BoardsBuild and Release PipelinesReporting and Analytics11. BitriseBitrise is one of the top cloud-based CI/CD tool that is primarily used for the complete automation process of mobile-first software. Since it is a clud-based software tool, so there is no need to spend more on the physical infrastructure and hardware. Bitrise support all the major programming language used in mobile app development. Bitrise works very smoothly with the public, private, and ad-hoc  Git services. With it's parallel and distributed builds, developers can increase their speed of completing the process by splitting tasks across multiple agents or threads.FeaturesMobile-centric AutomationVisual Workflow EditorParallel and Distributed Builds12. CodeShipCodeShip is a CI/CD tool by CloudBees that helps the developers to automate the complete process of application development, from building to deployment. CodeShip has multiple helpful features like integration with version control systems like GitHub and Bitbucket, container support and notification alert. It has very user-friendly interface, and with its focus on simplicity, CodeShip aims to simplify the development process and increase the efficiency in software development lifecycle. It also has basic and pro paid versions, that you can use according to your specific requirements.FeaturesMulti-Environment DeploymentNotification and AlertsProject Lifecycle Management13. SpinnakerSpinnaker is a free and open-source, multi-cloud continuous delivery software platform. It was originally developed by the engineers of Netflix and further extended many features by Google. It is designed to work with other software that help in the process of software development such as Kubernetes. Since it is a tool that helps in the lifecycle of software development, it definitely provides functionalities such as automating system tests, managing rollouts, and triggering pipelines.FeaturesMulti-Cloud DeploymentBuilt-in Rollback and RollforwardAutomated Canary Analysis14. BuildbotBuildbot is an open-source CI/CD tool that focuses on the automation of complex testing and application deployment processes. It is based on Python. It started with a lightweight alternative to the Mozilla projectâ€™s Tinderbox, and now it is used by several others like Python, WebKit, and ReactOS. Buildbot follows a more decentralized and configurable architecture that allows users to define their build pipelines using scripts that are based on Python. Buildbots are generally suitable for those who need deep customizability and have specific requirements in their CI/CD workflows.FeaturesHighly CustomizableDistributed BuildsReal-time Monitoring and Logging15. WreckerWrecker is a CI/CD platform that is based on Docker that helps software developers build and deploy their software applications and microservices. It was acquired by Oracle. Wrecker is totally based on the concepts of Pipeline that automatically executes the code by taking it from the program. It Provides programmatic access to information about applications, builds, and deploys that speed up the development process. It triggers the pipelines in case any new code is committed and can be integrated with Git and other popular notification systems.FeaturesGit Integrations with various platformsDebug and test pipelines before deployingConclusionContinuous Integration and Continuous Deployment is an integral part of the software development process and helps the development teams in building reliable and continuously evolving software with continuous feedback loops. It is necessary to debug the code and receive the feedback after better testing and at the same time deploy the updates when ready, so to automate these processes, developers have built these CI/CD tools. Each tool has its unique features and functionalities which are capable of doing different actions according to the requirements of the team and project. Also, you can customize your specific requirements with different tools but for more premium features, you have to pay extra for it.Â FAQs on Best CI/CD Tools1. What are the top CI/CD tools?These are some of the top CI/CD tools that are currently trending among developers:1. JenKins2. Docker3. GitLab4. Microsoft Azure5. Wrecker2. Who uses CI/CD Tools?DevOps engineers use CI/CD tools such as Jenkins and GitLab to automate the process of Software Development.3. What is CI/CD, and why is it important in software development?CI/CD stands for Continuous Integration and Continuous Deployment (or Continuous Delivery). It automate and streamline the process of building, testing, and deploying code changes to production environments in software development4. How to choose the right CI/CD tool for my project?Choosing the right CI/CD tool for project is depend upon various factor such as project requirement, existing tool, and end goal of project etc.\n",
      "\n",
      "        Comment\n",
      "    More info\n",
      "Advertise with us\n",
      "Next Article\n",
      "\n",
      "Understanding Deployment Automation\n",
      "H\n",
      "harshintotfv \n",
      " Follow \n",
      "Improve\n",
      "\n",
      "Article Tags : \n",
      "\n",
      "GBlog\n",
      "\n",
      "DevOps\n",
      "\n",
      "Tools\n",
      " \n",
      "Similar Reads\n",
      "\n",
      "DevOps Tutorial\n",
      "                    \n",
      "DevOps is a collection of two words, \"Development\" and \"Operations,\" representing a cultural approach that emphasizes collaboration between development and operations teams to streamline the entire software delivery lifecycle. This DevOps tutorial is designed to help learn DevOps basics and advanced\n",
      "9 min read\n",
      "Introduction\n",
      "What is DevOps ?\n",
      "                    \n",
      "As technology keeps advancing, businesses need to deliver software faster and more reliably. DevOps helps achieve this by bringing together development and operations teams, ensuring they work as one instead of in separate silos. DevOps is more than just a set of toolsÃ¢â‚¬â€itÃ¢â‚¬â„¢s a way of working that pro\n",
      "12 min read\n",
      "\n",
      "DevOps Lifecycle\n",
      "                    \n",
      "DevOps is a practice that enables a single team to handle the whole application lifecycle, including development, testing, release, deployment, operation, display, and planning. It is a mix of the terms \"Dev\" (for development) and \"Ops\" (for operations). We can speed up the delivery of applications\n",
      "6 min read\n",
      "\n",
      "The Evolution of DevOps - 3 Major Trends for Future\n",
      "                    \n",
      "DevOps is a software engineering culture and practice that aims to unify software development and operations. It is an approach to software development that emphasizes collaboration, communication, and integration between software developers and IT operations. DevOps has come a long way since its in\n",
      "7 min read\n",
      "Version Control\n",
      "Version Control Systems\n",
      "                    \n",
      "Version Control Systems (VCS) are essential tools used in software development and collaborative projects to track and manage changes to code, documents, and other files. Whether you're working alone or as part of a team, version control helps ensure that your work is safe, organized, and easy to co\n",
      "7 min read\n",
      "\n",
      "Merge Strategies in Git\n",
      "                    \n",
      "Understanding merge strategies in Git can simplify your workflow, resolve conflicts efficiently, and ensure seamless collaboration among team members. In this article, we'll explore various merge strategies, their use cases, and best practices for effective branch management. What is a Merge in Git?\n",
      "4 min read\n",
      "\n",
      "Which Version Control System Should I Choose?\n",
      "                    \n",
      "While building a project, you need a system wherein you can track the modifications made. That's where Version Control System comes into the picture. It came into existence in 1972 at Bell Labs. The very first VCS made was SCCS (Source Code Control System) and was available only for UNIX. When any p\n",
      "5 min read\n",
      "Continuous Integration (CI) & Continuous Deployment (CD)\n",
      "What is CI/CD?\n",
      "                    \n",
      "CI/CD is the practice of automating the integration of code changes from multiple developers into a single codebase. It is a software development practice where the developers commit their work frequently to the central code repository (Github or Stash). Then there are automated tools that build the\n",
      "8 min read\n",
      "\n",
      "15 Best CI/CD Tools That You Should Know\n",
      "                    \n",
      "Continuous Integration and Continuous Delivery (CI/CD) is modern-day practices to continuously improve the software by adding new feature and for that we have to change the existing files and deploy them. Doing it manually every time may consume a lot of developer's time, so to make the process more\n",
      "11 min read\n",
      "\n",
      "Understanding Deployment Automation\n",
      "                    \n",
      "In this article we will discuss deployment automation, categories in Automated Deployment, how automation can be implemented in deployment, how it is assisting DevOps and finally the benefits and drawbacks of Deployment Automation. So, let's start exploring the topic in detail. Deployment Automation\n",
      "4 min read\n",
      "Containerization\n",
      "What is Docker?\n",
      "                    \n",
      "Docker is a set of Platforms as a service (PaaS) products that use Operating system-level virtualization to deliver software in packages called containers. Containers are isolated from one another and bundle their own software, libraries, and configuration files; they can communicate with each other\n",
      "15+ min read\n",
      "\n",
      "What is Dockerfile Syntax?\n",
      "                    \n",
      "Pre-requsites: Docker,Dockerfile A Dockerfile is a script that uses the Docker platform to generate containers automatically. It is essentially a text document that contains all the instructions that a user may use to create an image from the command line. The Docker platform is a Linux-based platfo\n",
      "5 min read\n",
      "\n",
      "Kubernetes - Introduction to Container Orchestration\n",
      "                    \n",
      "In this article, we will look into Container Orchestration in Kubernetes. But first, let's explore the trends that gave rise to containers, the need for container orchestration, and how that it has created the space for Kubernetes to rise to dominance and growth. The growth of technology into every\n",
      "4 min read\n",
      "Orchestration\n",
      "Kubernetes - Introduction to Container Orchestration\n",
      "                    \n",
      "In this article, we will look into Container Orchestration in Kubernetes. But first, let's explore the trends that gave rise to containers, the need for container orchestration, and how that it has created the space for Kubernetes to rise to dominance and growth. The growth of technology into every\n",
      "4 min read\n",
      "\n",
      "Fundamental Kubernetes Components and their role in Container Orchestration\n",
      "                    \n",
      "Kubernetes or K8s is an open-sourced container orchestration technology that is used for automating the manual processes of deploying, managing and scaling applications by the help of containers. Kubernetes was originally developed by engineers at Google and In 2015, it was donated to CNCF (Cloud Na\n",
      "12 min read\n",
      "\n",
      "How to Use AWS ECS to Deploy and Manage Containerized Applications?\n",
      "                    \n",
      "Containers can be deployed for applications on the AWS cloud platform. AWS has a special application for managing containerized applications. Elastic Container Service (ECS) serves this purpose. ECS is AWS's container orchestration tool which simplifies the management of containers. All the containe\n",
      "4 min read\n",
      "Infrastructure as Code (IaC)\n",
      "What is Infrastructure as Code (IaC)?\n",
      "                    \n",
      "Infrastructure as Code (IaC) is a method of managing and provisioning IT infrastructure using code rather than manual configuration. It allows teams to automate the setup and management of their infrastructure, making it more efficient and consistent. This is particularly useful in the DevOps enviro\n",
      "7 min read\n",
      "\n",
      "Introduction to Terraform\n",
      "                    \n",
      "Terraform is an open-source infrastructure as code (IaC) software tool which can be used to provision the infrastructure of a cloud platform. The HCL scripts which have been used to provision infrastructure can be human-readable configuration files that can be versioned, reused, and shared. You can\n",
      "14 min read\n",
      "\n",
      "What is AWS Cloudformation?\n",
      "                    \n",
      "Amazon Web Services(AWS) offers cloud formation as a service by which you can provision and manage complicated services offered by AWS by using the code. CloudFormation will help you to manage the infrastructure and the services in the form of a declarative way. Table of Content How Does AWS Cloudfo\n",
      "13 min read\n",
      "Monitoring and Logging\n",
      "Working with Prometheus and Grafana Using Helm\n",
      "                    \n",
      "Pre-requisite: HELM Package Manager Helm is a package manager for Kubernetes that allows you to install, upgrade, and manage applications on your Kubernetes cluster. With Helm, you can define, install, and upgrade your application using a single configuration file, called a Chart. Charts are easy to\n",
      "5 min read\n",
      "\n",
      "Working with Monitoring and Logging Services\n",
      "                    \n",
      "Pre-requisite: Google Cloud Platform Monitoring and Logging services are essential tools for any organization that wants to ensure the reliability, performance, and security of its systems. These services allow organizations to collect and analyze data about the health and behavior of their systems,\n",
      "5 min read\n",
      "\n",
      "Microsoft Teams vs Slack\n",
      "                    \n",
      "Both Microsoft Teams and Slack are the communication channels used by organizations to communicate with their employees. Microsoft Teams was developed in 2017 whereas Slack was created in 2013. Microsoft Teams is mainly used in large organizations and is integrated with Office 365 enhancing the feat\n",
      "4 min read\n",
      "Security in DevOps\n",
      "What is DevSecOps: Overview and Tools\n",
      "                    \n",
      "DevSecOps methodology is an extension of the DevOps model that helps development teams to integrate security objectives very early into the lifecycle of the software development process, giving developers the team confidence to carry out several security tasks independently to protect code from adva\n",
      "10 min read\n",
      "\n",
      "DevOps Best Practices for Kubernetes\n",
      "                    \n",
      "DevOps is the hot topic in the market these days. DevOps is a vague term used for wide number of operations, most agreeable defination of DevOps would be that DevOps is an intersection of development and operations. Certain practices need to be followed during the application release process in DevO\n",
      "11 min read\n",
      "\n",
      "Like\n",
      "\n",
      "Corporate & Communications Address:\n",
      "\n",
      "                      A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)                    \n",
      "Registered Address:\n",
      "                        K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305                      \n",
      "Advertise with us\n",
      "CompanyAbout UsLegalPrivacy PolicyIn MediaContact UsAdvertise with usGFG Corporate SolutionPlacement Training ProgramGeeksforGeeks CommunityLanguagesPythonJavaC++PHPGoLangSQLR LanguageAndroid TutorialTutorials ArchiveDSAData StructuresAlgorithmsDSA for BeginnersBasic DSA ProblemsDSA RoadmapTop 100 DSA Interview ProblemsDSA Roadmap by Sandeep JainAll Cheat SheetsData Science & MLData Science With PythonData Science For BeginnerMachine LearningML MathsData VisualisationPandasNumPyNLPDeep LearningWeb TechnologiesHTMLCSSJavaScriptTypeScriptReactJSNextJSBootstrapWeb DesignPython TutorialPython Programming ExamplesPython ProjectsPython TkinterWeb ScrapingOpenCV TutorialPython Interview QuestionDjangoComputer ScienceOperating SystemsComputer NetworkDatabase Management SystemSoftware EngineeringDigital Logic DesignEngineering MathsSoftware DevelopmentSoftware TestingDevOpsGitLinuxAWSDockerKubernetesAzureGCPDevOps RoadmapSystem DesignHigh Level DesignLow Level DesignUML DiagramsInterview GuideDesign PatternsOOADSystem Design BootcampInterview QuestionsInteview PreparationCompetitive ProgrammingTop DS or Algo for CPCompany-Wise Recruitment ProcessCompany-Wise PreparationAptitude PreparationPuzzlesSchool SubjectsMathematicsPhysicsChemistryBiologySocial ScienceEnglish GrammarCommerceWorld GKGeeksforGeeks VideosDSAPythonJavaC++Web DevelopmentData ScienceCS Subjects \n",
      "\n",
      "@GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved\n",
      "\n",
      "        We use cookies to ensure you have the best browsing experience on our website. By using our site, you\n",
      "        acknowledge that you have read and understood our\n",
      "        Cookie Policy &\n",
      "        Privacy Policy\n",
      "\n",
      "        Got It !\n",
      "    \n",
      "\n",
      "Improvement\n",
      "Suggest changes\n",
      "Suggest Changes\n",
      "Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.\n",
      "Create Improvement\n",
      "Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.\n",
      "Suggest Changes\n",
      "\n",
      "min 4 words, max Words Limit:1000\n",
      "\n",
      "Thank You!\n",
      "Your suggestions are valuable to us.\n",
      "\n",
      "What kind of Experience do you want to share?\n",
      "Interview Experiences\n",
      "Admission Experiences\n",
      "Career Journeys\n",
      "Work Experiences\n",
      "Campus Experiences\n",
      "Competitive Exam Experiences\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install BeautifulSoup and requests\n",
    "# Open your terminal or command prompt and run the following commands:\n",
    "# pip install beautifulsoup4\n",
    "# pip install requests\n",
    "\n",
    "# Step 2: Import BeautifulSoup and requests\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Step 3: Load the HTML content\n",
    "url = 'https://www.geeksforgeeks.org/best-ci-cd-tools/'\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Step 4: Create a BeautifulSoup object\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Step 5: Extract text from HTML\n",
    "# Example: Extract the text from a specific element\n",
    "# element = soup.find('div',) #class_='example')\n",
    "text_content = soup.get_text()\n",
    "\n",
    "text_content = '\\n'.join(filter(lambda x: len(x.strip()) > 0, text_content.split('\\n\\n')))\n",
    "\n",
    "# Step 6: Print the extracted text\n",
    "print(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 Best CI/CD Tools That You Should Know\n",
      "(CI/CD) is modern-day practices to continuously improve the software by adding new feature and for that we have to change the existing files and deploy them. Doing it manually every time may consume a lot of developer's time, so to make the process more simple and reliable developers use\n",
      "that are much more efficient and make the whole process automated. As a software Engineer or beginner in development,\n",
      "you should know the best CI/CD tools\n",
      "As you go deep into software development, you will ultimately need these tools to save time and release a more reliable and stable version of your software application with proper automated testing and deploying processes. But before knowing the tools letâ€™s first under what exactly is CI and CD.\n",
      "CI and CD stand for continuous Integration and are continuous Deployment/Delivery which is\n",
      "used in the process of building efficient software\n",
      ". These are the approaches that are used to integrate the code changes into a shared repository (Continuous Integration) while automating the testing and deployment process to the staging and production environment (Continuous Delivery). These approaches are used to provide a more reliable and stable version of a software application by testing it before release to end-users with the help of CI/CD Tools.\n",
      "To learn more about CI/CD, refer to this article-\n",
      "15 Best CI/CD Tools For Developers\n",
      "Continuous Integration and Continuous Delivery are not only necessary to build a great application but also help the business in meeting its various requirements, from automating tasks to receiving quick feedback, so that developers can improve the application accordingly. They are both combined known as continuous software development. In this process of developing efficient applications, developers have created some CI/CS Tools that help the software engineers test the software application effectively. Here are some of the best CI/CD tools that you should know\n",
      "Jenkins is one of the most popular and effective CI/CD tools which is an\n",
      ". It provides several functionalities like automation testing, deploying code changes for smooth collaboration among the teams of product development, and faster identification of issues. It has a feature â€œ\n",
      "â€ which allows developers to manage their deployment pipelines programmatically. It has a\n",
      "which is very useful in their efficient resource usage. It also has a large community support to help new developers. To enhance the quality of software and increase the speed of delivery of applications, Jenkins has played a very important role.\n",
      "For the automation process of building, testing, and deploying software applications there are various CI/CD tools in the market but among those Travis CI is one of the most popular and useful tools that software developers prefer over other tools due to its crucial role in the software development lifecycle by\n",
      "checking the reliability and quality of code\n",
      "changes before integrating into the production codebase. Automatic building and testing of code during push commands and support for various languages and frameworks are some of the important factors that differentiate these CI/CD tools from the others. All of its feature ensures smooth development workflows and faster feedback, so Travis CI enables collaboration decrease integration issues, and help the developers build more high-quality software applications.\n",
      "GitLab is a web-based platform that provides multiple tools and functionalities to developers to provide help in the process of the software development lifecycle. It is one of the most common CI/CD tools that is used by the developers which provide several useful functionalities like\n",
      "pipelines, code review, and issue tracking with the help of version control through Git repositories. GitLab allows development teams to manage the collaborative project in real-time and track progress within an integrated environment. It is very flexible for various development workflows and is available in both private servers and as a cloud-hosted service.\n",
      "Container Registry and Kubernetes Integration\n",
      "Built-in Issue Tracking and Collaboration\n",
      "Docker is a software platform that is used in the process of software development by providing special functionalities such as\n",
      ". Dockerâ€™s libraries, system tools, code, and runtime are stored in standard units called containers. The software that hosts the container is known as Docker Engine. It offers both free and premium services that completely depend on the use case. To use the resources efficiently, Docker uses OS-level virtualization. The application and its dependencies can be packaged into a portable format that can run on any system that supports Docker.\n",
      "Isolation and Resource Efficiency\n",
      "One of the widely used CI/CD server tools is TeamCity which is developed by JetBrains. Since it is a CI/CD tool then definitely is used for the automation of building, testing, and deploying software applications. And one of the most helpful parts of it is that TeamCity has a very\n",
      ", It can easily integrate with popular version control systems like Git and Subversion, also integrate with cloud platforms, and has the ability to trigger builds based on code commits. Projects of different sizes and complexities can easily use these tools due to their flexibility and extensibility.\n",
      "Advanced Build and Deployment Workflows\n",
      "Semaphore is one of the fastest-growing CI/CD tools for DevOps in the software industry that allows you to deploy various software updates every day on platforms like\n",
      ", Android, and macOS with no barriers. Semaphore allow teams to deploy applications through\n",
      "triggered by code changes. It also automates the process of build, testing, and deploying the software application process with a continuous feedback loop to improve the application continuously to make it a stable and reliable application. This CI/CD tool is an example of an amazing tool that allows an end-to-end development process.\n",
      "When it comes to using cloud-based CI/CD tools that automate and optimize the software development lifecycle, Circle CI is the very first tool that developers prioritize. CircleCI\n",
      "supports container-based builds for a consistent environment\n",
      "with parallel and distributed testing and an advanced caching mechanism to speed up build times. It also supports multiple programming languages and frameworks, allowing development teams to customize their workflows on the cloud platform itself. CircleCI helps in debugging early in the development process and ensures that the code quality is good to make reliable software products.\n",
      "Cloud-Based and Self-Hosted Option\n",
      "Bamboo is a continuous integration and continuous delivery (CI/CD) tool which is\n",
      ". The purpose behind the Bamboo tools is to make the software development process very simple by automating the various stages such as building, testing, and deploying the code changes. Development teams can create pipelines that automatically trigger code commits when necessary and help in integration and collaboration. Bamboo\n",
      "helps product development teams with faster feedback loops\n",
      "and improves their code quality to make stable releases of software applications with the help of automated CI/CD pipelines.\n",
      "Integration with Atlassian Ecosystem\n",
      "Integration and Release Management\n",
      "Buddy is a CI/CD tool and is one of the\n",
      "modern and user-friendly platforms\n",
      "automate software development workflows\n",
      ". To set up a complex workflow, Buddy provides us with a visual pipeline builder that makes it easy to visualize the workflow and it also has built-in Docker support for containerized builds and deployments. It is also integrated with various cloud providers. It is very suitable for every development team size due to its flexible and intuitive interface and extensive features.\n",
      "Azure DevOps server is a CI/CD tool which is created by\n",
      "that provides various functionalities such as version control, reporting, requirements management, project management, testing, and several other capabilities. It was formerly known as\n",
      "(TFS). It is a cloud-based service that is much more suitable for an organization that requires physical hosting due to security, compliance, or any other reasons. Since it is a product of Microsoft, it integrates well with other Microsoft products as well. It supports the entire software development lifecycle by providing tools for version control, agile planning, and CI/CD.\n",
      "Customizable Work Items and Boards\n",
      "Bitrise is one of the top cloud-based CI/CD tool that is primarily\n",
      "used for the complete automation process of mobile-first software\n",
      ". Since it is a clud-based software tool, so there is no need to spend more on the physical infrastructure and hardware. Bitrise support all the major programming language used in mobile app development. Bitrise works very smoothly with the public, private, and ad-hoc  Git services. With it's parallel and distributed builds, developers can increase their speed of completing the process by splitting tasks across multiple agents or threads.\n",
      "CodeShip is a CI/CD tool by CloudBees that helps the developers to\n",
      "automate the complete process of application development\n",
      ", from building to deployment. CodeShip has multiple helpful features like integration with version control systems like GitHub and Bitbucket, container support and notification alert. It has very user-friendly interface, and with its focus on simplicity, CodeShip aims to simplify the development process and increase the efficiency in software development lifecycle. It also has basic and pro paid versions, that you can use according to your specific requirements.\n",
      "Spinnaker is a free and open-source, multi-cloud continuous delivery software platform. It was originally\n",
      "developed by the engineers of Netflix\n",
      "and further extended many features by Google. It is designed to work with other software that help in the process of software development such as Kubernetes. Since it is a tool that\n",
      "helps in the lifecycle of software development\n",
      ", it definitely provides functionalities such as automating system tests, managing rollouts, and triggering pipelines.\n",
      "Built-in Rollback and Rollforward\n",
      "Buildbot is an open-source CI/CD tool that focuses on the\n",
      "automation of complex testing and application deployment processes\n",
      ". It started with a lightweight alternative to the Mozilla projectâ€™s Tinderbox, and now it is used by several others like Python, WebKit, and ReactOS. Buildbot follows a more decentralized and configurable architecture that allows users to define their build pipelines using scripts that are based on Python. Buildbots are generally suitable for those who need deep customizability and have specific requirements in their CI/CD workflows.\n",
      "Wrecker is a CI/CD platform that is\n",
      "that helps software developers build and deploy their software applications and microservices. It was\n",
      ". Wrecker is totally based on the concepts of Pipeline that automatically executes the code by taking it from the program. It Provides programmatic access to information about applications, builds, and deploys that speed up the development process. It\n",
      "triggers the pipelines in case any new code is committed\n",
      "and can be integrated with Git and other popular notification systems.\n",
      "Git Integrations with various platforms\n",
      "Debug and test pipelines before deploying\n",
      "Continuous Integration and Continuous Deployment is an integral part of the software development process and helps the development teams in building reliable and continuously evolving software with continuous feedback loops. It is necessary to debug the code and receive the feedback after better testing and at the same time deploy the updates when ready, so to automate these processes, developers have built these CI/CD tools. Each tool has its unique features and functionalities which are capable of doing different actions according to the requirements of the team and project. Also, you can customize your specific requirements with different tools but for more premium features, you have to pay extra for it.\n",
      "These are some of the top CI/CD tools that are currently trending among developers:\n",
      "DevOps engineers use CI/CD tools such as Jenkins and GitLab to automate the process of Software Development.\n",
      "3. What is CI/CD, and why is it important in software development?\n",
      "CI/CD stands for Continuous Integration and Continuous Deployment (or Continuous Delivery). It automate and streamline the process of building, testing, and deploying code changes to production environments in software development\n",
      "4. How to choose the right CI/CD tool for my project?\n",
      "Choosing the right CI/CD tool for project is depend upon various factor such as project requirement, existing tool, and end goal of project etc.\n",
      "Continuous Integration (CI) & Continuous Deployment (CD)\n",
      "We use cookies to ensure you have the best browsing experience on our website. By using our site, you\n",
      "acknowledge that you have read and understood our\n",
      "Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal.\n",
      "Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all.\n",
      "min 4 words, max Words Limit:1000\n",
      "Your suggestions are valuable to us.\n",
      "What kind of Experience do you want to share?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_main_text(url):\n",
    "    # Fetch the page content\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Parse with BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Remove unwanted tags: scripts, styles, navs, headers, footers, etc.\n",
    "    for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'form', 'noscript', 'iframe']):\n",
    "        tag.decompose()\n",
    "\n",
    "    # Remove ad/promo/banner-related classes or IDs\n",
    "    ad_classes = ['advertisement', 'ad', 'adsbygoogle', 'promo', 'banner', 'cookie-banner', 'subscribe']\n",
    "    for class_name in ad_classes:\n",
    "        for tag in soup.select(f'.{class_name}, #{class_name}'):\n",
    "            tag.decompose()\n",
    "\n",
    "    # Remove all anchor tags including their text\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        a_tag.decompose()\n",
    "\n",
    "    # Extract visible text from the body or the entire soup if body missing\n",
    "    body = soup.body if soup.body else soup\n",
    "    text = body.get_text(separator='\\n', strip=True)\n",
    "\n",
    "    # Clean up excessive empty lines and whitespace\n",
    "    lines = [line.strip() for line in text.splitlines() if line.strip()]\n",
    "    lines = list(filter(lambda x: len(x) > 32, lines))\n",
    "    clean_text = '\\n'.join(lines)\n",
    "\n",
    "    return clean_text\n",
    "\n",
    "# Example usage\n",
    "url = \"https://www.geeksforgeeks.org/best-ci-cd-tools/\"\n",
    "print(extract_main_text(url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 15 Best CI/CD Tools That You Should Know\n",
      "\n",
      "Continuous IntegrationandContinuous Delivery(CI/CD) is modern-day practices to continuously improve the software by adding new feature and for that we have to change the existing files and deploy them. Doing it manually every time may consume a lot of developer's time, so to make the process more simple and reliable developers useCI/CD toolsthat are much more efficient and make the whole process automated. As a software Engineer or beginner in development,you should know the best CI/CD tools.\n",
      "\n",
      "As you go deep into software development, you will ultimately need these tools to save time and release a more reliable and stable version of your software application with proper automated testing and deploying processes. But before knowing the tools letâ€™s first under what exactly is CI and CD.\n",
      "\n",
      "## What is CI/CD?\n",
      "\n",
      "CI and CD stand for continuous Integration and are continuous Deployment/Delivery which isused in the process of building efficient software. These are the approaches that are used to integrate the code changes into a shared repository (Continuous Integration) while automating the testing and deployment process to the staging and production environment (Continuous Delivery). These approaches are used to provide a more reliable and stable version of a software application by testing it before release to end-users with the help of CI/CD Tools.\n",
      "\n",
      "To learn more about CI/CD, refer to this article-\n",
      "\n",
      "## 15 Best CI/CD Tools For Developers\n",
      "\n",
      "Continuous Integration and Continuous Delivery are not only necessary to build a great application but also help the business in meeting its various requirements, from automating tasks to receiving quick feedback, so that developers can improve the application accordingly. They are both combined known as continuous software development. In this process of developing efficient applications, developers have created some CI/CS Tools that help the software engineers test the software application effectively. Here are some of the best CI/CD tools that you should know\n",
      "\n",
      "### 1. Jenkins\n",
      "\n",
      "Jenkins is one of the most popular and effective CI/CD tools which is anopen-source automation server. It provides several functionalities like automation testing, deploying code changes for smooth collaboration among the teams of product development, and faster identification of issues. It has a feature â€œPipeline as Codeâ€ which allows developers to manage their deployment pipelines programmatically. It has awhich is very useful in their efficient resource usage. It also has a large community support to help new developers. To enhance the quality of software and increase the speed of delivery of applications, Jenkins has played a very important role.\n",
      "\n",
      "To learn more, refer to -\n",
      "\n",
      "Features:\n",
      "\n",
      "- Extensibility with Plugins\n",
      "- Pipeline as Code\n",
      "- Distributed Builds\n",
      "### 2. Travis CI\n",
      "\n",
      "For the automation process of building, testing, and deploying software applications there are various CI/CD tools in the market but among those Travis CI is one of the most popular and useful tools that software developers prefer over other tools due to its crucial role in the software development lifecycle bychecking the reliability and quality of codechanges before integrating into the production codebase. Automatic building and testing of code during push commands and support for various languages and frameworks are some of the important factors that differentiate these CI/CD tools from the others. All of its feature ensures smooth development workflows and faster feedback, so Travis CI enables collaboration decrease integration issues, and help the developers build more high-quality software applications.\n",
      "\n",
      "To learn more, refer to -\n",
      "\n",
      "Features:\n",
      "\n",
      "- GitHub Integration\n",
      "- Build Matrix\n",
      "- Caching Dependencies\n",
      "### 3. GitLab\n",
      "\n",
      "GitLab is a web-based platform that provides multiple tools and functionalities to developers to provide help in the process of the software development lifecycle. It is one of the most common CI/CD tools that is used by the developers which provide several useful functionalities likecollaborative project management,continuous integrationandcontinuous deploymentpipelines, code review, and issue tracking with the help of version control through Git repositories. GitLab allows development teams to manage the collaborative project in real-time and track progress within an integrated environment. It is very flexible for various development workflows and is available in both private servers and as a cloud-hosted service.\n",
      "\n",
      "To learn more, refer to -\n",
      "\n",
      "Features\n",
      "\n",
      "- Integrated DevOps Platform\n",
      "- Container Registry and Kubernetes Integration\n",
      "- Built-in Issue Tracking and Collaboration\n",
      "### 4. Docker\n",
      "\n",
      "Docker is a software platform that is used in the process of software development by providing special functionalities such asbuilding,testing, anddeploying software applications. Dockerâ€™s libraries, system tools, code, and runtime are stored in standard units called containers. The software that hosts the container is known as Docker Engine. It offers both free and premium services that completely depend on the use case. To use the resources efficiently, Docker uses OS-level virtualization. The application and its dependencies can be packaged into a portable format that can run on any system that supports Docker.\n",
      "\n",
      "To learn more, refer to -\n",
      "\n",
      "Features\n",
      "\n",
      "- Containerization Technology\n",
      "- Image-Based Deployment\n",
      "- Isolation and Resource Efficiency\n",
      "### 5. TeamCity\n",
      "\n",
      "One of the widely used CI/CD server tools is TeamCity which is developed by JetBrains. Since it is a CI/CD tool then definitely is used for the automation of building, testing, and deploying software applications. And one of the most helpful parts of it is that TeamCity has a veryuser-friendly web interface, It can easily integrate with popular version control systems like Git and Subversion, also integrate with cloud platforms, and has the ability to trigger builds based on code commits. Projects of different sizes and complexities can easily use these tools due to their flexibility and extensibility.\n",
      "\n",
      "To learn more, refer to -\n",
      "\n",
      "Features\n",
      "\n",
      "- Cross-Platform Compatibility\n",
      "- Build Chains and Dependencies\n",
      "- Advanced Build and Deployment Workflows\n",
      "### 6. Semaphore\n",
      "\n",
      "Semaphore is one of the fastest-growing CI/CD tools for DevOps in the software industry that allows you to deploy various software updates every day on platforms like, Android, and macOS with no barriers. Semaphore allow teams to deploy applications throughcustomizable pipelinestriggered by code changes. It also automates the process of build, testing, and deploying the software application process with a continuous feedback loop to improve the application continuously to make it a stable and reliable application. This CI/CD tool is an example of an amazing tool that allows an end-to-end development process.\n",
      "\n",
      "Features\n",
      "\n",
      "- YAML-Based Configuration\n",
      "- Parallel and Distributed Testing\n",
      "- Continuous Delivery Pipelines\n",
      "### 7. Circle CI\n",
      "\n",
      "When it comes to using cloud-based CI/CD tools that automate and optimize the software development lifecycle, Circle CI is the very first tool that developers prioritize. CircleCIsupports container-based builds for a consistent environmentwith parallel and distributed testing and an advanced caching mechanism to speed up build times. It also supports multiple programming languages and frameworks, allowing development teams to customize their workflows on the cloud platform itself. CircleCI helps in debugging early in the development process and ensures that the code quality is good to make reliable software products.\n",
      "\n",
      "Features\n",
      "\n",
      "- Orbs for Reusable Configuration\n",
      "- Workspaces for Data Sharing\n",
      "- Cloud-Based and Self-Hosted Option\n",
      "### 8. Bamboo\n",
      "\n",
      "Bamboo is a continuous integration and continuous delivery (CI/CD) tool which isdeveloped by Atlassian. The purpose behind the Bamboo tools is to make the software development process very simple by automating the various stages such as building, testing, and deploying the code changes. Development teams can create pipelines that automatically trigger code commits when necessary and help in integration and collaboration. Bamboohelps product development teams with faster feedback loopsand improves their code quality to make stable releases of software applications with the help of automated CI/CD pipelines.\n",
      "\n",
      "Features\n",
      "\n",
      "- Integration with Atlassian Ecosystem\n",
      "- Docker and Container Support\n",
      "- Integration and Release Management\n",
      "### 9. Buddy\n",
      "\n",
      "Buddy is a CI/CD tool and is one of themodern and user-friendly platformstoautomate software development workflows. To set up a complex workflow, Buddy provides us with a visual pipeline builder that makes it easy to visualize the workflow and it also has built-in Docker support for containerized builds and deployments. It is also integrated with various cloud providers. It is very suitable for every development team size due to its flexible and intuitive interface and extensive features.\n",
      "\n",
      "Features\n",
      "\n",
      "- Pipeline as Code\n",
      "- Deployment Automation\n",
      "- Serverless Actions\n",
      "### 10. Azure DevOps Server\n",
      "\n",
      "Azure DevOps server is a CI/CD tool which is created byMicrosoftthat provides various functionalities such as version control, reporting, requirements management, project management, testing, and several other capabilities. It was formerly known asTeam Foundation Server(TFS). It is a cloud-based service that is much more suitable for an organization that requires physical hosting due to security, compliance, or any other reasons. Since it is a product of Microsoft, it integrates well with other Microsoft products as well. It supports the entire software development lifecycle by providing tools for version control, agile planning, and CI/CD.\n",
      "\n",
      "To learn more, refer to -\n",
      "\n",
      "Features\n",
      "\n",
      "- Customizable Work Items and Boards\n",
      "- Build and Release Pipelines\n",
      "- Reporting and Analytics\n",
      "### 11. Bitrise\n",
      "\n",
      "Bitrise is one of the top cloud-based CI/CD tool that is primarilyused for the complete automation process of mobile-first software. Since it is a clud-based software tool, so there is no need to spend more on the physical infrastructure and hardware. Bitrise support all the major programming language used in mobile app development. Bitrise works very smoothly with the public, private, and ad-hoc  Git services. With it's parallel and distributed builds, developers can increase their speed of completing the process by splitting tasks across multiple agents or threads.\n",
      "\n",
      "Features\n",
      "\n",
      "- Mobile-centric Automation\n",
      "- Visual Workflow Editor\n",
      "- Parallel and Distributed Builds\n",
      "### 12. CodeShip\n",
      "\n",
      "CodeShip is a CI/CD tool by CloudBees that helps the developers toautomate the complete process of application development, from building to deployment. CodeShip has multiple helpful features like integration with version control systems like GitHub and Bitbucket, container support and notification alert. It has very user-friendly interface, and with its focus on simplicity, CodeShip aims to simplify the development process and increase the efficiency in software development lifecycle. It also has basic and pro paid versions, that you can use according to your specific requirements.\n",
      "\n",
      "Features\n",
      "\n",
      "- Multi-Environment Deployment\n",
      "- Notification and Alerts\n",
      "- Project Lifecycle Management\n",
      "### 13. Spinnaker\n",
      "\n",
      "Spinnaker is a free and open-source, multi-cloud continuous delivery software platform. It was originallydeveloped by the engineers of Netflixand further extended many features by Google. It is designed to work with other software that help in the process of software development such as Kubernetes. Since it is a tool thathelps in the lifecycle of software development, it definitely provides functionalities such as automating system tests, managing rollouts, and triggering pipelines.\n",
      "\n",
      "Features\n",
      "\n",
      "- Multi-Cloud Deployment\n",
      "- Built-in Rollback and Rollforward\n",
      "- Automated Canary Analysis\n",
      "### 14. Buildbot\n",
      "\n",
      "Buildbot is an open-source CI/CD tool that focuses on theautomation of complex testing and application deployment processes. It is based on. It started with a lightweight alternative to the Mozilla projectâ€™s Tinderbox, and now it is used by several others like Python, WebKit, and ReactOS. Buildbot follows a more decentralized and configurable architecture that allows users to define their build pipelines using scripts that are based on Python. Buildbots are generally suitable for those who need deep customizability and have specific requirements in their CI/CD workflows.\n",
      "\n",
      "Features\n",
      "\n",
      "- Highly Customizable\n",
      "- Distributed Builds\n",
      "- Real-time Monitoring and Logging\n",
      "### 15. Wrecker\n",
      "\n",
      "Wrecker is a CI/CD platform that isbased on Dockerthat helps software developers build and deploy their software applications and microservices. It wasacquired by Oracle. Wrecker is totally based on the concepts of Pipeline that automatically executes the code by taking it from the program. It Provides programmatic access to information about applications, builds, and deploys that speed up the development process. Ittriggers the pipelines in case any new code is committedand can be integrated with Git and other popular notification systems.\n",
      "\n",
      "Features\n",
      "\n",
      "- Git Integrations with various platforms\n",
      "- Debug and test pipelines before deploying\n",
      "## Conclusion\n",
      "\n",
      "Continuous Integration and Continuous Deployment is an integral part of the software development process and helps the development teams in building reliable and continuously evolving software with continuous feedback loops. It is necessary to debug the code and receive the feedback after better testing and at the same time deploy the updates when ready, so to automate these processes, developers have built these CI/CD tools. Each tool has its unique features and functionalities which are capable of doing different actions according to the requirements of the team and project. Also, you can customize your specific requirements with different tools but for more premium features, you have to pay extra for it.\n",
      "\n",
      "## FAQs on Best CI/CD Tools\n",
      "\n",
      "### 1. What are the top CI/CD tools?\n",
      "\n",
      "These are some of the top CI/CD tools that are currently trending among developers:\n",
      "\n",
      "1. JenKins2. Docker3. GitLab4. Microsoft Azure5. Wrecker\n",
      "\n",
      "### 2. Who uses CI/CD Tools?\n",
      "\n",
      "DevOps engineers use CI/CD tools such as Jenkins and GitLab to automate the process of Software Development.\n",
      "\n",
      "### 3. What is CI/CD, and why is it important in software development?\n",
      "\n",
      "CI/CD stands for Continuous Integration and Continuous Deployment (or Continuous Delivery). It automate and streamline the process of building, testing, and deploying code changes to production environments in software development\n",
      "\n",
      "### 4. How to choose the right CI/CD tool for my project?\n",
      "\n",
      "Choosing the right CI/CD tool for project is depend upon various factor such as project requirement, existing tool, and end goal of project etc.\n",
      "\n",
      "### Similar Reads\n",
      "\n",
      "## Introduction\n",
      "\n",
      "## Version Control\n",
      "\n",
      "## Continuous Integration (CI) & Continuous Deployment (CD)\n",
      "\n",
      "## Containerization\n",
      "\n",
      "## Orchestration\n",
      "\n",
      "## Infrastructure as Code (IaC)\n",
      "\n",
      "## Monitoring and Logging\n",
      "\n",
      "## Security in DevOps\n",
      "\n",
      "## Thank You!\n",
      "\n",
      "## What kind of Experience do you want to share?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_markdown_text(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Remove scripts, styles, navs, headers, footers, and typical ad elements\n",
    "    for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'form', 'noscript', 'iframe']):\n",
    "        tag.decompose()\n",
    "\n",
    "    ad_classes = ['advertisement', 'ad', 'adsbygoogle', 'promo', 'banner', 'cookie-banner', 'subscribe']\n",
    "    for class_name in ad_classes:\n",
    "        for tag in soup.select(f'.{class_name}, #{class_name}'):\n",
    "            tag.decompose()\n",
    "\n",
    "    # Remove all links and their content\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        a_tag.decompose()\n",
    "\n",
    "    # Markdown content building\n",
    "    markdown_lines = []\n",
    "\n",
    "    # Process headings and paragraphs\n",
    "    for element in soup.body.descendants if soup.body else soup.descendants:\n",
    "        if element.name:\n",
    "            if element.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "                level = int(element.name[1])\n",
    "                markdown_lines.append(f\"{'#' * level} {element.get_text(strip=True)}\\n\")\n",
    "            elif element.name in ['ul', 'ol']:\n",
    "                for li in element.find_all('li'):\n",
    "                    markdown_lines.append(f\"- {li.get_text(strip=True)}\")\n",
    "            elif element.name == 'p':\n",
    "                text = element.get_text(strip=True)\n",
    "                if text:\n",
    "                    markdown_lines.append(f\"{text}\\n\")\n",
    "\n",
    "    # Final cleanup: remove empty lines\n",
    "    markdown_lines = list(filter(lambda x: len(x) > 2, markdown_lines))\n",
    "    markdown_content = '\\n'.join([line for line in markdown_lines if line.strip()])\n",
    "    \n",
    "    return markdown_content\n",
    "\n",
    "# Example usage\n",
    "url = \"https://www.geeksforgeeks.org/best-ci-cd-tools/\"\n",
    "print(extract_markdown_text(url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "  \"/Users/ohi/Documents/GitHub/PersonalAssistant/weights/SmolThink-360M-sft/checkpoint-45807\",\n",
    "#   revision=\"v2.0.1\" # tag name, or branch name, or commit hash\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/Users/ohi/Documents/GitHub/PersonalAssistant/weights/SmolThink-360M-sft/checkpoint-45807\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-67e5c3bf-08a9130203aef20f66ccf6d7;92755505-03bd-4d73-a65e-0a459a938b89)\n\nInvalid username or password.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:409\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSmolThink\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3085\u001b[0m, in \u001b[0;36mPreTrainedModel.push_to_hub\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3083\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags:\n\u001b[1;32m   3084\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tags\n\u001b[0;32m-> 3085\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:872\u001b[0m, in \u001b[0;36mPushToHubMixin.push_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, commit_description, tags, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m repo_url \u001b[38;5;241m=\u001b[39m deprecated_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    870\u001b[0m organization \u001b[38;5;241m=\u001b[39m deprecated_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morganization\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 872\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_repo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# Create a new empty model card and eventually tag it\u001b[39;00m\n\u001b[1;32m    877\u001b[0m model_card \u001b[38;5;241m=\u001b[39m create_and_tag_model_card(\n\u001b[1;32m    878\u001b[0m     repo_id, tags, token\u001b[38;5;241m=\u001b[39mtoken, ignore_metadata_errors\u001b[38;5;241m=\u001b[39mignore_metadata_errors\n\u001b[1;32m    879\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:679\u001b[0m, in \u001b[0;36mPushToHubMixin._create_repo\u001b[0;34m(self, repo_id, private, token, repo_url, organization)\u001b[0m\n\u001b[1;32m    676\u001b[0m             repo_id \u001b[38;5;241m=\u001b[39m repo_id\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    677\u001b[0m         repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morganization\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 679\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m url\u001b[38;5;241m.\u001b[39mrepo_id\n",
      "File \u001b[0;32m~/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/huggingface_hub/hf_api.py:3511\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, resource_group_id, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3508\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   3510\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3511\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3512\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   3513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exist_ok \u001b[38;5;129;01mand\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m409\u001b[39m:\n\u001b[1;32m   3514\u001b[0m         \u001b[38;5;66;03m# Repo already exists and `exist_ok=True`\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:481\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/repos/create (Request ID: Root=1-67e5c3bf-08a9130203aef20f66ccf6d7;92755505-03bd-4d73-a65e-0a459a938b89)\n\nInvalid username or password."
     ]
    }
   ],
   "source": [
    "model.push_to_hub(\"SmolThink\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: transformers-cli <command> [<args>]\n",
      "Transformers CLI tool: error: argument {chat,convert,download,env,run,serve,add-new-model-like,add-fast-image-processor}: invalid choice: 'login' (choose from 'chat', 'convert', 'download', 'env', 'run', 'serve', 'add-new-model-like', 'add-fast-image-processor')\n"
     ]
    }
   ],
   "source": [
    "!transformers-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {\"role\": \"user\", \"content\": \"Hi, can you tell me the current stock price of Apple?\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"<think>\\nAlright, the user asked for the current stock price of Apple. Looking at the tools available, there's a function called get_stock_price which exactly fits this request. I'll need to call this function with the parameter company set to 'Apple' to retrieve the information the user is asking for. This seems like the most straightforward and appropriate action to take.\\n</think>\\n<tool_call>\\n[{'name': 'get_stock_price', 'arguments': {'company': 'Apple'}}]\\n</tool_call>\"}, \n",
    "    {\"role\": \"tool\", \"content\": \"{'stock_price': '$150.75'}\"}, \n",
    "    {\"role\": \"assistant\", \"content\": \"The current stock price of Apple is $150.75.\"}, \n",
    "    {'role': 'user', 'content': \"That's great. Can you also tell me the stock price for Microsoft?\"}, \n",
    "    {'role': 'assistant', 'content': \"<think>\\nAlright, let me try to figure out how to handle this user's request. The user first asked about Apple's stock price, and I responded by calling the get_stock_price function with 'Apple' as the argument. The tool provided the price, and I passed that information back to the user.\\n\\nNow, the user is asking for the stock price of Microsoft. I need to determine the appropriate action here. Looking at the tools available, there's still the get_stock_price function, which is designed to fetch current stock prices. Since the user is requesting another company's stock price, it makes sense to use the same function again but with the company name changed to Microsoft. \\n\\nI shouldn't assume any other tools are needed because the available functions are specifically tailored for stock prices and movie details. In this case, the relevant function is get_stock_price. I should ensure that the function is called with the correct parameter, 'Microsoft' in this case, to retrieve the accurate information the user is seeking. This approach is efficient and aligns directly with the user's request without making unnecessary assumptions or using unrelated tools.\\n</think>\\n<tool_call>\\n[{'name': 'get_stock_price', 'arguments': {'company': 'Microsoft'}}]\\n</tool_call>\"}, {'role': 'tool', 'content': \"{'stock_price': '$210.22'}\"}, {'role': 'assistant', 'content': 'The current stock price of Microsoft is $210.22.'}, {'role': 'user', 'content': 'Thank you for the information.'}, {'role': 'assistant', 'content': \"You're welcome! If you have any other questions, feel free to ask.\"}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"You are a helpful assistant.\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"Hello, how are you?\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\": \"I'm doing great. How can I help you today?\"\n",
    "  },\n",
    "  {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"I'd like to show off how chat templating works!\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{{- if .Messages }}\n",
    "{{- if .Tools }}<|im_start|>system\n",
    "You are a helpful AI assistant named SmolThink.\n",
    "\n",
    "# Tools\n",
    " \n",
    "You may call one or more functions to assist with the user query.\n",
    "\n",
    "You are provided with function signatures within <tools></tools> tags:\n",
    "<tools>\n",
    "{{ .Tools }}\n",
    "</tools>\n",
    "\n",
    "You first think/plan inside <think></think> tags.\n",
    "Then for each function call, return a json object with function name and arguments within <tool_call></tool_call> tags.<|im_end|>\n",
    "{{ else if .System }}<|im_start|>system\n",
    "{{ .System }}<|im_end|>\n",
    "{{- else if not .Tools }}\n",
    "<|im_start|>system\n",
    "You are a helpful AI assistant named SmolThink. First plan/reason/code/validate inside <think></think> tag and provide final answer to user query inside <answer></answer> tag.<|im_end|>\n",
    "{{ end }}\n",
    "{{- range $i, $_ := .Messages }}\n",
    "{{- $last := eq (len (slice $.Messages $i)) 1 -}}\n",
    "{{- if eq .Role \"user\" }}<|im_start|>user\n",
    "{{ .Content }}<|im_end|>\n",
    "{{ else if eq .Role \"assistant\" }}<|im_start|>assistant\n",
    "{{ if .Content }}{{ .Content }}\n",
    "{{- else if .ToolCalls }}<tool_call>[\n",
    "{{ range .ToolCalls }}{\"name\": \"{{ .Function.Name }}\", \"arguments\": {{ .Function.Arguments }}}{{ end }}\n",
    "]</tool_call>\n",
    "{{- end }}{{ if not $last }}<|im_end|>\n",
    "{{ end }}\n",
    "{{- else if eq .Role \"tool\" }}<|im_start|>user\n",
    "<tool_response>\n",
    "{{ .Content }}\n",
    "</tool_response><|im_end|>\n",
    "{{ end }}\n",
    "{{- if and (ne .Role \"assistant\") $last }}<|im_start|>assistant\n",
    "{{ end }}\n",
    "{{- end }} \n",
    "{{- else }}\n",
    "{{- if .System }}<|im_start|>system\n",
    "{{ .System }}<|im_end|>\n",
    "{{ end }}{{ if .Prompt }}<|im_start|>user\n",
    "{{ .Prompt }}<|im_end|>\n",
    "{{ end }}<|im_start|>assistant\n",
    "{{ end }}{{ .Response }}{{ if .Response }}<|im_end|>{{ end }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|><|im_start|>system\n",
      "You are a helpful AI assistant named SmolThink. First plan/reason/code/validate inside <think></think> tag and provide final answer to user query inside <answer></answer> tag.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is 12+9?.<|im_end|>\n",
      "\n",
      "<|endoftext|><|im_start|>system\n",
      "You are a helpful AI assistant named SmolThink. First plan/reason/code/validate inside <think></think> tag and provide final answer to user query inside <answer></answer> tag.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is 12+9?.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "<think>\n",
      "</think>\n",
      "<answer>\n",
      "12 + 9 = 21\n",
      "</answer><|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "device = 'mps'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"quwsarohi/SmolThink\"\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"quwsarohi/SmolThink\",\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    use_cache=False,\n",
    "    tie_word_embeddings=True,\n",
    ").to(device)\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 12+9?\"}]\n",
    "input_text=tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "print(input_text)\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(inputs, max_new_tokens=50, temperature=0.2, top_p=0.9, do_sample=True)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, StoppingCriteria\n",
    "from datasets import load_dataset\n",
    "import peft\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "import random\n",
    "import re\n",
    "import json\n",
    "import ast\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import Optional, List\n",
    "from jinja2 import Template\n",
    "from transformers.utils import get_json_schema\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "def url_content(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Remove scripts, styles, navs, headers, footers, and typical ad elements\n",
    "    for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'form', 'noscript', 'iframe']):\n",
    "        tag.decompose()\n",
    "\n",
    "    ad_classes = ['advertisement', 'ad', 'adsbygoogle', 'promo', 'banner', 'cookie-banner', 'subscribe']\n",
    "    for class_name in ad_classes:\n",
    "        for tag in soup.select(f'.{class_name}, #{class_name}'):\n",
    "            tag.decompose()\n",
    "\n",
    "    # Remove all links and their content\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        a_tag.decompose()\n",
    "\n",
    "    # Markdown content building\n",
    "    markdown_lines = []\n",
    "\n",
    "    # Process headings and paragraphs\n",
    "    for element in soup.body.descendants if soup.body else soup.descendants:\n",
    "        if element.name:\n",
    "            if element.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "                level = int(element.name[1])\n",
    "                markdown_lines.append(f\"{'#' * level} {element.get_text(strip=True)}\\n\")\n",
    "            elif element.name in ['ul', 'ol']:\n",
    "                for li in element.find_all('li'):\n",
    "                    markdown_lines.append(f\"- {li.get_text(strip=True)}\")\n",
    "            elif element.name == 'p':\n",
    "                text = element.get_text(strip=True)\n",
    "                if text:\n",
    "                    markdown_lines.append(f\"{text}\\n\")\n",
    "\n",
    "    # Final cleanup: remove empty lines\n",
    "    markdown_lines = list(filter(lambda x: len(x) > 2, markdown_lines))\n",
    "    markdown_content = '\\n'.join([line for line in markdown_lines if line.strip()])    \n",
    "    return markdown_content\n",
    "\n",
    "\n",
    "def search_tool(search_str, full_content=True, max_results=1):\n",
    "    rets = None\n",
    "    with DDGS() as ddg:\n",
    "        rets = list(ddg.text(keywords=search_str, region=\"wt-wt\", max_results=max_results))\n",
    "\n",
    "    str_rets = ''\n",
    "    if full_content:\n",
    "        str_rets = \"Use following information to answer user_question:\\n\\n\"\n",
    "        for i, r in enumerate(rets):\n",
    "            r = url_content(rets[i]['href'])[:1024*3]\n",
    "            str_rets += f\"# Source {i+1}:\\n\" + \"-\"*10 + f\"\\n\\n{r}\\n\\n\\n\"\n",
    "    else:\n",
    "        str_rets = \"Use following information to answer user_question:\\n\\n\"\n",
    "        for i, r in enumerate(rets):\n",
    "            str_rets += f\"# Source {i+1}:\\n\" + \"-\"*10 + f\"\\n\\n{r}\\n\\n\\n\"\n",
    "        \n",
    "    return str_rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use following information to answer user_question:\n",
      "\n",
      "# Source 1:\n",
      "----------\n",
      "\n",
      "# Math Calculator\n",
      "\n",
      "Step 1:\n",
      "\n",
      "Enter the expression you want to evaluate.\n",
      "\n",
      "The Math Calculator will evaluate your problem down to a final solution. You can also add, subtraction, multiply, and divide and complete any arithmetic you need.\n",
      "\n",
      "Step 2:\n",
      "\n",
      "Click theblue arrowto submit and see your result!\n",
      "\n",
      "Please ensure that your password is at least 8 characters and contains each of the following:\n",
      "\n",
      "- a number\n",
      "- a letter\n",
      "- a special character: @$#!%*?&\n",
      "\n",
      "\n",
      "# Source 2:\n",
      "----------\n",
      "\n",
      "# Basic Operations Calculator\n",
      "\n",
      "## Number Line\n",
      "\n",
      "- Show More\n",
      "basic-operations-calculator\n",
      "\n",
      "en\n",
      "\n",
      "Please add a message.\n",
      "\n",
      "Message received. Thanks for the feedback.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(search_tool(\"perform math operation: 32 + 64 = ?\", max_results=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'FirstURL': 'https://duckduckgo.com/c/Python_(programming_language)', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Python_(programming_language)\">Python (programming language) Category</a>', 'Text': 'Python (programming language) Category'}, {'FirstURL': 'https://duckduckgo.com/Python_syntax_and_semantics', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/Python_syntax_and_semantics\">Python syntax and semantics</a> - The syntax of the Python programming language is the set of rules that defines how a Python program will be written and interpreted. The Python language has many similarities to Perl, C, and Java. However, there are some definite differences between the languages.', 'Text': 'Python syntax and semantics - The syntax of the Python programming language is the set of rules that defines how a Python program will be written and interpreted. The Python language has many similarities to Perl, C, and Java. However, there are some definite differences between the languages.'}, {'FirstURL': 'https://duckduckgo.com/History_of_programming_languages', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/History_of_programming_languages\">History of programming languages</a> - The history of programming languages spans from documentation of early mechanical computers to modern tools for software development. Early programming languages were highly specialized, relying on mathematical notation and similarly obscure syntax.', 'Text': 'History of programming languages - The history of programming languages spans from documentation of early mechanical computers to modern tools for software development. Early programming languages were highly specialized, relying on mathematical notation and similarly obscure syntax.'}, {'FirstURL': 'https://duckduckgo.com/c/Pattern_matching_programming_languages', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Pattern_matching_programming_languages\">Pattern matching programming languages</a>', 'Text': 'Pattern matching programming languages'}, {'FirstURL': 'https://duckduckgo.com/c/Multi-paradigm_programming_languages', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Multi-paradigm_programming_languages\">Multi-paradigm programming languages</a>', 'Text': 'Multi-paradigm programming languages'}, {'FirstURL': 'https://duckduckgo.com/c/Class-based_programming_languages', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Class-based_programming_languages\">Class-based programming languages</a>', 'Text': 'Class-based programming languages'}, {'FirstURL': 'https://duckduckgo.com/c/Text-oriented_programming_languages', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Text-oriented_programming_languages\">Text-oriented programming languages</a>', 'Text': 'Text-oriented programming languages'}, {'FirstURL': 'https://duckduckgo.com/c/Concurrent_programming_languages', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Concurrent_programming_languages\">Concurrent programming languages</a>', 'Text': 'Concurrent programming languages'}, {'FirstURL': 'https://duckduckgo.com/c/Dynamically_typed_programming_languages', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Dynamically_typed_programming_languages\">Dynamically typed programming languages</a>', 'Text': 'Dynamically typed programming languages'}, {'FirstURL': 'https://duckduckgo.com/c/Educational_programming_languages', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Educational_programming_languages\">Educational programming languages</a>', 'Text': 'Educational programming languages'}, {'FirstURL': 'https://duckduckgo.com/c/High-level_programming_languages', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/High-level_programming_languages\">High-level programming languages</a>', 'Text': 'High-level programming languages'}, {'FirstURL': 'https://duckduckgo.com/c/Object-oriented_programming_languages', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Object-oriented_programming_languages\">Object-oriented programming languages</a>', 'Text': 'Object-oriented programming languages'}, {'FirstURL': 'https://duckduckgo.com/c/Scripting_languages', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Scripting_languages\">Scripting languages</a>', 'Text': 'Scripting languages'}, {'FirstURL': 'https://duckduckgo.com/c/Dutch_inventions', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Dutch_inventions\">Dutch inventions</a>', 'Text': 'Dutch inventions'}, {'FirstURL': 'https://duckduckgo.com/c/Programming_languages', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Programming_languages\">Programming languages</a>', 'Text': 'Programming languages'}, {'FirstURL': 'https://duckduckgo.com/c/Cross-platform_free_software', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Cross-platform_free_software\">Cross-platform free software</a>', 'Text': 'Cross-platform free software'}, {'FirstURL': 'https://duckduckgo.com/c/Cross-platform_software', 'Icon': {'Height': '', 'URL': '', 'Width': ''}, 'Result': '<a href=\"https://duckduckgo.com/c/Cross-platform_software\">Cross-platform software</a>', 'Text': 'Cross-platform software'}]\n",
      "Python is a high-level, general-purpose programming language. Its design philosophy emphasizes code readability with the use of significant indentation. Python is dynamically type-checked and garbage-collected. It supports multiple programming paradigms, including structured, object-oriented and functional programming. It is often described as a \"batteries included\" language due to its comprehensive standard library. Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language and first released it in 1991 as Python 0.9.0. Python 2.0 was released in 2000. Python 3.0, released in 2008, was a major revision not completely backward-compatible with earlier versions. Python 2.7.18, released in 2020, was the last release of Python 2. Python consistently ranks as one of the most popular programming languages, and has gained widespread use in the machine learning community.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "def search_ddg(query):\n",
    "    url = \"https://api.duckduckgo.com/\"\n",
    "    params = {\"q\": query, \"format\": \"json\"}\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json()\n",
    "results = search_ddg(\"Python programming\")\n",
    "print(results[\"RelatedTopics\"])\n",
    "\n",
    "\n",
    "def fetch_instant_answer(query):\n",
    "    response = search_ddg(query)\n",
    "    return response.get(\"AbstractText\", \"No instant answer available.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(fetch_instant_answer(\"How to commit in github\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: llama-index 0.12.27\n",
      "Uninstalling llama-index-0.12.27:\n",
      "  Would remove:\n",
      "    /Users/ohi/Documents/GitHub/PersonalAssistant/.venv/bin/llamaindex-cli\n",
      "    /Users/ohi/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/llama_index-0.12.27.dist-info/*\n",
      "    /Users/ohi/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/llama_index/_bundle/*\n",
      "Proceed (Y/n)? ^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip uninstall llama-index llama-index-readers-web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from io import BytesIO\n",
    "from docling.backend.html_backend import HTMLDocumentBackend\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.document import InputDocument\n",
    "\n",
    "def docling_cleanup(input_str):\n",
    "    # <!-- image --> tag cleanup\n",
    "    input_str = input_str.replace('<!-- image -->', '')\n",
    "    # Lines with empty spaces\n",
    "    lines = filter(lambda x: not x.isspace(), input_str.split('\\n'))\n",
    "    input_str = '\\n'.join(list(lines))\n",
    "    del lines\n",
    "    # clean excessive newlines\n",
    "    _cnt = 0\n",
    "    ret_str = ''\n",
    "    for c in input_str:\n",
    "        if c == '\\n':\n",
    "            _cnt += 1\n",
    "            if _cnt > 2: continue\n",
    "            else: ret_str += c\n",
    "        else:\n",
    "            _cnt = 0\n",
    "            ret_str += c\n",
    "    return ret_str\n",
    "\n",
    "import requests\n",
    "\n",
    "def url_content(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    ascii_text = response.text.encode(\"ascii\", \"ignore\")\n",
    "    in_doc = InputDocument(\n",
    "        path_or_stream=BytesIO(ascii_text),\n",
    "        format=InputFormat.HTML,\n",
    "        backend=HTMLDocumentBackend,\n",
    "        filename=\"duck.html\",\n",
    "    )\n",
    "\n",
    "    backend = HTMLDocumentBackend(in_doc=in_doc, path_or_stream=BytesIO(ascii_text))\n",
    "    dl_doc = backend.convert()\n",
    "    return docling_cleanup(dl_doc.export_to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### current community\n",
      "\n",
      "- Stack Overflow\n",
      "\n",
      "help\n",
      "chat\n",
      "- Meta Stack Overflow\n",
      "\n",
      "### your communities\n",
      "\n",
      "or  to customize your list.\n",
      "\n",
      "### more stack exchange communities\n",
      "\n",
      "Log in\n",
      "\n",
      "Sign up\n",
      "\n",
      "    1. Home\n",
      "    2. Questions\n",
      "    3. Tags\n",
      "    4. Discussions\n",
      "Labs\n",
      "    5. Chat\n",
      "    6. Users\n",
      "    7. Companies\n",
      "    8. Collectives\n",
      "    9. Communities for your favorite technologies.  Explore all Collectives\n",
      "2. Teams\n",
      "\n",
      "            Ask questions, find answers and collaborate at work with Stack Overflow for Teams.\n",
      "Try Teams for free\n",
      "Explore Teams\n",
      "3. Teams\n",
      "4. Ask questions, find answers and collaborate at work with Stack Overflow for Teams.\n",
      "            Explore Teams\n",
      "\n",
      "##### Collectives on Stack Overflow\n",
      "\n",
      "Find centralized, trusted content and collaborate around the technologies you use most.\n",
      "\n",
      "Teams\n",
      "\n",
      "Q&amp;A for work\n",
      "\n",
      "Connect and share knowledge within a single location that is structured and easy to search.\n",
      "\n",
      "# Sieve of Eratosthenes - Finding Primes Python\n",
      "\n",
      "134k times\n",
      "\n",
      "89\n",
      "\n",
      "Just to clarify, this is not a homework problem :)\n",
      "\n",
      "I wanted to find primes for a math application I am building &amp; came across Sieve of Eratosthenes approach.\n",
      "\n",
      "I have written an implementation of it in Python. But it's terribly slow. For say, if I want to find all primes less than 2 million. It takes &gt; 20 mins. (I stopped it at this point). How can I speed this up?\n",
      "\n",
      "```\n",
      "def primes_sieve(limit):\n",
      "    limitn = limit+1\n",
      "    primes = range(2, limitn)\n",
      "\n",
      "    for i in primes:\n",
      "        factors = range(i, limitn, i)\n",
      "        for f in factors[1:]:\n",
      "            if f in primes:\n",
      "                primes.remove(f)\n",
      "    return primes\n",
      "\n",
      "print primes_sieve(2000)\n",
      "```\n",
      "\n",
      "UPDATE:\n",
      "I ended up doing profiling on this code &amp; found that quite a lot of time was spent on removing an element from the list. Quite understandable considering it has to traverse the entire list (worst-case) to find the element &amp; then remove it and then readjust the list (maybe some copy goes on?). Anyway, I chucked out list for dictionary. My new implementation -\n",
      "\n",
      "```\n",
      "def primes_sieve1(limit):\n",
      "    limitn = limit+1\n",
      "    primes = dict()\n",
      "    for i in range(2, limitn): primes[i] = True\n",
      "\n",
      "    for i in primes:\n",
      "        factors = range(i,limitn, i)\n",
      "        for f in factors[1:]:\n",
      "            primes[f] = False\n",
      "    return [i for i in primes if primes[i]==True]\n",
      "\n",
      "print primes_sieve1(2000000)\n",
      "```\n",
      "\n",
      "- python\n",
      "- math\n",
      "- primes\n",
      "- sieve-of-eratosthenes\n",
      "\n",
      "asked\n",
      "\n",
      "- 1\n",
      "\n",
      "There's a similar question here stackoverflow.com/questions/2897297 that you might find useful.\n",
      "\n",
      "â€“Â Scott Griffiths\n",
      "\n",
      "Commented\n",
      "Oct 15, 2010 at 8:18\n",
      "- Check that answer.\n",
      "\n",
      "â€“Â tzot\n",
      "\n",
      "Commented\n",
      "Oct 15, 2010 at 19:57\n",
      "- stackoverflow.com/questions/2068372/â€¦\n",
      "\n",
      "â€“Â Robert William Hanks\n",
      "\n",
      "Commented\n",
      "Oct 18, 2010 at 22:57\n",
      "- 1\n",
      "\n",
      "@Srikar: Rather than iterating upto limit, you can just iterate upto the square root of limit, since any composite number in your dictionary will have one factor less than the square root of limit.\n",
      "\n",
      "â€“Â sayantankhan\n",
      "\n",
      "Commented\n",
      "Aug 17, 2013 at 1:36\n",
      "- 2\n",
      "\n",
      "Using the step parameter to range is brilliant. factors is a misnomer and should be multiples.\n",
      "\n",
      "â€“Â Tom Russell\n",
      "\n",
      "Commented\n",
      "Feb 28, 2018 at 23:50\n",
      "\n",
      "## 26 Answers\n",
      "                                    26\n",
      "\n",
      "128\n",
      "\n",
      "You're not quite implementing the correct algorithm:\n",
      "\n",
      "In your first example, primes\\_sieve doesn't maintain a list of primality flags to strike/unset (as in the algorithm), but instead resizes a list of integers continuously, which is very expensive: removing an item from a list requires shifting all subsequent items down by one.\n",
      "\n",
      "In the second example, primes\\_sieve1 maintains a dictionary of primality flags, which is a step in the right direction, but it iterates over the dictionary in undefined order, and redundantly strikes out factors of factors (instead of only factors of primes, as in the algorithm). You could fix this by sorting the keys, and skipping non-primes (which already makes it an order of magnitude faster), but it's still much more efficient to just use a list directly.\n",
      "\n",
      "The correct algorithm (with a list instead of a dictionary) looks something like:\n",
      "\n",
      "```\n",
      "def primes_sieve2(limit):\n",
      "    a = [True] * limit                          # Initialize the primality list\n",
      "    a[0] = a[1] = False\n",
      "\n",
      "    for (i, isprime) in enumerate(a):\n",
      "        if isprime:\n",
      "            yield i\n",
      "            for n in range(i*i, limit, i):     # Mark factors non-prime\n",
      "                a[n] = False\n",
      "```\n",
      "\n",
      "(Note that this also includes the algorithmic optimization of starting the non-prime marking at the prime's square (i*i) instead of its double.)\n",
      "\n",
      "answered\n",
      "\n",
      "- 9\n",
      "\n",
      "another optimization, the step size of your xrange(i*i,limit,i) can be made 2*i\n",
      "\n",
      "â€“Â st0le\n",
      "\n",
      "Commented\n",
      "Oct 21, 2010 at 12:20\n",
      "- 3\n",
      "\n",
      "I like your succinct implementation of the Sieve of Eratosthenes. : ) However, I'm having a OverflowError: Python int too large to convert to C long. I changed xrange(i*i, limit, i) to xrange(i, limit, i). Thanks for sharing this code snippet!\n",
      "\n",
      "â€“Â Annie Lagang\n",
      "\n",
      "Commented\n",
      "Apr 2, 2012 at 13:26\n",
      "- 13\n",
      "\n",
      "@st0le: No, the step-size cannot be made 2*i. Just tried it. It yields 14 as a prime.\n",
      "\n",
      "â€“Â mpen\n",
      "\n",
      "Commented\n",
      "Jul 13, 2012 at 1:33\n",
      "- 2\n",
      "\n",
      "@Mark, I'm sorry I didn't really explain it in full. Eliminate all even numbers by doing an iteration with i=2 with steps of i but for the rest you can use 2*i. In fact, in my implementation I use half the booleans since I don't store even numbers and instead use a simple mod 2. You can find my Java  implementation here which uses even less (1/8th) the memory. HERE\n",
      "\n",
      "â€“Â st0le\n",
      "\n",
      "Commented\n",
      "Jul 13, 2012 at 3:44\n",
      "- 4\n",
      "\n",
      "+1, just a small detail, if you use [False] * 2 + [True] * (limit-2) in the initialisation, you can avoid IndexError on passing number &lt; 2 as an argument\n",
      "\n",
      "â€“Â Jan Vorcak\n",
      "\n",
      "Commented\n",
      "Nov 10, 2013 at 17:57\n",
      "\n",
      "14\n",
      "\n",
      "```\n",
      "def eratosthenes(n):\n",
      "    multiples = []\n",
      "    for i in range(2, n+1):\n",
      "        if i not in multiples:\n",
      "            print (i)\n",
      "            for j in range(i*i, n+1, i):\n",
      "                multiples.append(j)\n",
      "\n",
      "eratosthenes(100)\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "- 6\n",
      "\n",
      "instead of a list, I would use a set in order to speed up the membership test\n",
      "\n",
      "â€“Â Copperfield\n",
      "\n",
      "Commented\n",
      "Sep 4, 2016 at 13:36\n",
      "- 1\n",
      "\n",
      "The last output showing 'None' , how I can remove it?\n",
      "\n",
      "â€“Â LordOfThunder\n",
      "\n",
      "Commented\n",
      "Sep 17, 2018 at 12:12\n",
      "\n",
      "8\n",
      "\n",
      "Removing from the beginning of an array (list) requires moving all of the items after it down.  That means that removing every element from a list in this way starting from the front is an O(n^2) operation.\n",
      "\n",
      "You can do this much more efficiently with sets:\n",
      "\n",
      "```\n",
      "def primes_sieve(limit):\n",
      "    limitn = limit+1\n",
      "    not_prime = set()\n",
      "    primes = []\n",
      "\n",
      "    for i in range(2, limitn):\n",
      "        if i in not_prime:\n",
      "            continue\n",
      "\n",
      "        for f in range(i*2, limitn, i):\n",
      "            not_prime.add(f)\n",
      "\n",
      "        primes.append(i)\n",
      "\n",
      "    return primes\n",
      "\n",
      "print primes_sieve(1000000)\n",
      "```\n",
      "\n",
      "... or alternatively, avoid having to rearrange the list:\n",
      "\n",
      "```\n",
      "def primes_sieve(limit):\n",
      "    limitn = limit+1\n",
      "    not_prime = [False] * limitn\n",
      "    primes = []\n",
      "\n",
      "    for i in range(2, limitn):\n",
      "        if not_prime[i]:\n",
      "            continue\n",
      "        for f in xrange(i*2, limitn, i):\n",
      "            not_prime[f] = True\n",
      "\n",
      "        primes.append(i)\n",
      "\n",
      "    return primes\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "- 2\n",
      "\n",
      "See @Piet Delport answer below for an optimization: replace i*2 above with i*i.\n",
      "\n",
      "â€“Â President James K. Polk\n",
      "\n",
      "Commented\n",
      "Oct 17, 2010 at 14:44\n",
      "\n",
      "4\n",
      "\n",
      "Much faster:\n",
      "\n",
      "```\n",
      "import time\n",
      "def get_primes(n):\n",
      "  m = n+1\n",
      "  #numbers = [True for i in range(m)]\n",
      "  numbers = [True] * m #EDIT: faster\n",
      "  for i in range(2, int(n**0.5 + 1)):\n",
      "    if numbers[i]:\n",
      "      for j in range(i*i, m, i):\n",
      "        numbers[j] = False\n",
      "  primes = []\n",
      "  for i in range(2, m):\n",
      "    if numbers[i]:\n",
      "      primes.append(i)\n",
      "  return primes\n",
      "\n",
      "start = time.time()\n",
      "primes = get_primes(10000)\n",
      "print(time.time() - start)\n",
      "print(get_primes(100))\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "3\n",
      "\n",
      "Using a bit of numpy, I could find all primes below 100 million in a little over 2 seconds.\n",
      "\n",
      "There are two key features one should note\n",
      "\n",
      "- Cut out multiples of i only for i up to root of n\n",
      "- Setting multiples of i to False using x[2*i::i] = False is much faster than an explicit python for loop.\n",
      "\n",
      "These two significantly speed up your code. For limits below one million, there is no perceptible running time.\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "\n",
      "def primes(n):\n",
      "    x = np.ones((n+1,), dtype=np.bool)\n",
      "    x[0] = False\n",
      "    x[1] = False\n",
      "    for i in range(2, int(n**0.5)+1):\n",
      "        if x[i]:\n",
      "            x[2*i::i] = False\n",
      "\n",
      "    primes = np.where(x == True)[0]\n",
      "    return primes\n",
      "\n",
      "print(len(primes(100_000_000)))\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "2\n",
      "\n",
      "By combining contributions from many enthusiasts (including Glenn Maynard and MrHIDEn from above comments), I came up with following piece of code in python 2:\n",
      "\n",
      "```\n",
      "def simpleSieve(sieveSize):\n",
      "    #creating Sieve.\n",
      "    sieve = [True] * (sieveSize+1)\n",
      "    # 0 and 1 are not considered prime.\n",
      "    sieve[0] = False\n",
      "    sieve[1] = False\n",
      "    for i in xrange(2,int(math.sqrt(sieveSize))+1):\n",
      "        if sieve[i] == False:\n",
      "            continue\n",
      "        for pointer in xrange(i**2, sieveSize+1, i):\n",
      "            sieve[pointer] = False\n",
      "    # Sieve is left with prime numbers == True\n",
      "    primes = []\n",
      "    for i in xrange(sieveSize+1):\n",
      "        if sieve[i] == True:\n",
      "            primes.append(i)\n",
      "    return primes\n",
      "\n",
      "sieveSize = input()\n",
      "primes = simpleSieve(sieveSize)\n",
      "```\n",
      "\n",
      "Time taken for computation on my machine for different inputs in power of 10 is:\n",
      "\n",
      "- 3 : 0.3 ms\n",
      "- 4 : 2.4 ms\n",
      "- 5 : 23 ms\n",
      "- 6 : 0.26 s\n",
      "- 7 : 3.1 s\n",
      "- 8 : 33 s\n",
      "\n",
      "answered\n",
      "\n",
      "- the comparison with True or False are unneeded more so as they are already Boolean,\n",
      "\n",
      "â€“Â Copperfield\n",
      "\n",
      "Commented\n",
      "Sep 4, 2016 at 13:32\n",
      "- @Copperfield Thanks! It helped in increasing speed by 10-20%.\n",
      "\n",
      "â€“Â Ajay\n",
      "\n",
      "Commented\n",
      "Sep 4, 2016 at 20:04\n",
      "- This sieve = [True] * (sieveSize+1) is faster than my solution, but sieve[0]/[1] and xrange(sieveSize+1) at primes[] does not improve anything. xrange(2, sieveSize+1) is good enouth. :). Also instead of for i in xrange(2,int(math.sqrt(sieveSize))+1): we can just use for i in xrange(2, int((sieveSize+1)**0.5): Good code. :)\n",
      "\n",
      "â€“Â MrHIDEn\n",
      "\n",
      "Commented\n",
      "Nov 28, 2016 at 8:49\n",
      "\n",
      "1\n",
      "\n",
      "I realise this isn't really answering the question of how to generate primes quickly, but perhaps some will find this alternative interesting: because python provides lazy evaluation via generators, eratosthenes' sieve can be implemented exactly as stated:\n",
      "\n",
      "```\n",
      "def intsfrom(n):\n",
      "    while True:\n",
      "        yield n\n",
      "        n += 1\n",
      "\n",
      "def sieve(ilist):\n",
      "    p = next(ilist)\n",
      "    yield p\n",
      "    for q in sieve(n for n in ilist if n%p != 0):\n",
      "        yield q\n",
      "\n",
      "try:\n",
      "    for p in sieve(intsfrom(2)):\n",
      "        print p,\n",
      "\n",
      "    print ''\n",
      "except RuntimeError as e:\n",
      "    print e\n",
      "```\n",
      "\n",
      "The try block is there because the algorithm runs until it blows the stack and without the\n",
      "try block the backtrace is displayed pushing the actual output you want to see off screen.\n",
      "\n",
      "answered\n",
      "\n",
      "- 4\n",
      "\n",
      "no, it's not the sieve of Eratosthenes, but rather a sieve of trial division. Even that is very suboptimal, because it's not postponed: any candidate number need only be tested by primes not above its square root. Implementing this along the lines of the pseudocode at the bottom of the linked above answer (the latter one) will give your code immense speedup (even before you switch to the proper sieve) and/because it'll greatly minimize the stack usage - so you mightn't need your try block after all.\n",
      "\n",
      "â€“Â Will Ness\n",
      "\n",
      "Commented\n",
      "Jul 21, 2014 at 14:11\n",
      "- ... see also: more discussion about the \"sqrt\" issue and its effects, an actual Python code for a postponed trial division, and some related Scala. --- And kudos to you, if you came up with that code on your own! :)\n",
      "\n",
      "â€“Â Will Ness\n",
      "\n",
      "Commented\n",
      "Jul 21, 2014 at 14:15\n",
      "- Interesting, although I'm not yet understanding why what I put is different from the sieve of Eratosthenes. I thought it was described as placing all the intergers from 2 in a line, then repeadly take the first in the line as a prime and strike out all multiples. the \"n for n in ilist if n%p != 0\" bit was supposed to represent striking out the multiples.  Admittedly highly suboptimal though, definitely\n",
      "\n",
      "â€“Â Paul Gardiner\n",
      "\n",
      "Commented\n",
      "Feb 18, 2015 at 14:05\n",
      "- 1\n",
      "\n",
      "n for n in ilist if n%p != 0 tests each number n in a range for divisibility by p; but range(p*p, N, p) generates the multiples directly, all by itself, without testing all these numbers.\n",
      "\n",
      "â€“Â Will Ness\n",
      "\n",
      "Commented\n",
      "Feb 25, 2015 at 4:06\n",
      "\n",
      "1\n",
      "\n",
      "A simple speed hack: when you define the variable \"primes,\" set the step to 2 to skip all even numbers automatically, and set the starting point to 1.\n",
      "\n",
      "Then you can further optimize by instead of for i in primes, use for i in primes[:round(len(primes) ** 0.5)]. That will dramatically increase performance. In addition, you can eliminate numbers ending with 5 to further increase speed.\n",
      "\n",
      "answered\n",
      "\n",
      "user3917838\n",
      "\n",
      "1\n",
      "\n",
      "Here's a version that's a bit more memory-efficient (and: a proper sieve, not trial divisions).  Basically, instead of keeping an array of all the numbers, and crossing out those that aren't prime, this keeps an array of counters - one for each prime it's discovered - and leap-frogging them ahead of the putative prime.  That way, it uses storage proportional to the number of primes, not up to to the highest prime.\n",
      "\n",
      "```\n",
      "import itertools\n",
      "\n",
      "def primes():\n",
      "\n",
      "    class counter:\n",
      "        def __init__ (this,  n): this.n, this.current,  this.isVirgin = n, n*n,  True\n",
      "            # isVirgin means it's never been incremented\n",
      "        def advancePast (this,  n): # return true if the counter advanced\n",
      "            if this.current > n:\n",
      "                if this.isVirgin: raise StopIteration # if this is virgin, then so will be all the subsequent counters.  Don't need to iterate further.\n",
      "                return False\n",
      "            this.current += this.n # pre: this.current == n; post: this.current > n.\n",
      "            this.isVirgin = False # when it's gone, it's gone\n",
      "            return True\n",
      "\n",
      "    yield 1\n",
      "    multiples = []\n",
      "    for n in itertools.count(2):\n",
      "        isPrime = True\n",
      "        for p in (m.advancePast(n) for m in multiples):\n",
      "            if p: isPrime = False\n",
      "        if isPrime:\n",
      "            yield n\n",
      "            multiples.append (counter (n))\n",
      "```\n",
      "\n",
      "You'll note that primes() is a generator, so you can keep the results in a list or you can use them directly.  Here's the first n primes:\n",
      "\n",
      "```\n",
      "import itertools\n",
      "\n",
      "for k in itertools.islice (primes(),  n):\n",
      "    print (k)\n",
      "```\n",
      "\n",
      "And, for completeness, here's a timer to measure the performance:\n",
      "\n",
      "```\n",
      "import time\n",
      "\n",
      "def timer ():\n",
      "    t,  k = time.process_time(),  10\n",
      "    for p in primes():\n",
      "        if p>k:\n",
      "            print (time.process_time()-t,  \" to \",  p,  \"\\n\")\n",
      "            k *= 10\n",
      "            if k>100000: return\n",
      "```\n",
      "\n",
      "Just in case you're wondering, I also wrote primes() as a simple iterator (using \\_\\_iter\\_\\_ and \\_\\_next\\_\\_), and it ran at almost the same speed.  Surprised me too!\n",
      "\n",
      "answered\n",
      "\n",
      "- interesting idea - it would improve performance if you store the prime counters in a min-heap though (inner loop would be O(log num\\_primes) instead of O(num\\_primes))\n",
      "\n",
      "â€“Â anthonybell\n",
      "\n",
      "Commented\n",
      "Jul 25, 2017 at 17:34\n",
      "- Why?  Even if they were in a heap, we still have to account for every one.\n",
      "\n",
      "â€“Â Jules May\n",
      "\n",
      "Commented\n",
      "Jul 26, 2017 at 10:26\n",
      "- If you store each prime in the heap keyed by it's next value you would only have to look at primes whose next value is the current value n.  the largest primes will sink to the bottom of the heap and would need to be evaluated much more rarely than the smaller primes.\n",
      "\n",
      "â€“Â anthonybell\n",
      "\n",
      "Commented\n",
      "Jul 26, 2017 at 19:30\n",
      "\n",
      "1\n",
      "\n",
      "I prefer NumPy because of speed.\n",
      "\n",
      "```\n",
      "import numpy as np\n",
      "\n",
      "# Find all prime numbers using Sieve of Eratosthenes\n",
      "def get_primes1(n):\n",
      "    m = int(np.sqrt(n))\n",
      "    is_prime = np.ones(n, dtype=bool)\n",
      "    is_prime[:2] = False  # 0 and 1 are not primes\n",
      "\n",
      "    for i in range(2, m):\n",
      "        if is_prime[i] == False:\n",
      "            continue\n",
      "        is_prime[i*i::i] = False\n",
      "\n",
      "    return np.nonzero(is_prime)[0]\n",
      "\n",
      "# Find all prime numbers using brute-force.\n",
      "def isprime(n):\n",
      "    ''' Check if integer n is a prime '''\n",
      "    n = abs(int(n))  # n is a positive integer\n",
      "    if n < 2:  # 0 and 1 are not primes\n",
      "        return False\n",
      "    if n == 2:  # 2 is the only even prime number\n",
      "        return True\n",
      "    if not n & 1:  # all other even numbers are not primes\n",
      "        return False\n",
      "    # Range starts with 3 and only needs to go up the square root\n",
      "    # of n for all odd numbers\n",
      "    for x in range(3, int(n**0.5)+1, 2):\n",
      "        if n % x == 0:\n",
      "            return False\n",
      "    return True\n",
      "\n",
      "# To apply a function to a numpy array, one have to vectorize the function\n",
      "def get_primes2(n):\n",
      "    vectorized_isprime = np.vectorize(isprime)\n",
      "    a = np.arange(n)\n",
      "    return a[vectorized_isprime(a)]\n",
      "```\n",
      "\n",
      "Check the output:\n",
      "\n",
      "```\n",
      "n = 100\n",
      "print(get_primes1(n))\n",
      "print(get_primes2(n))    \n",
      "    [ 2  3  5  7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97]\n",
      "    [ 2  3  5  7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71 73 79 83 89 97]\n",
      "```\n",
      "\n",
      "Compare the speed of Sieve of Eratosthenes and brute-force on Jupyter Notebook. Sieve of Eratosthenes in 539 times faster than brute-force for million elements.\n",
      "\n",
      "```\n",
      "%timeit get_primes1(1000000)\n",
      "%timeit get_primes2(1000000)\n",
      "4.79 ms  90.3 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n",
      "2.58 s  31.2 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "- Should your inner loop content not better be (taking previous answers and comments into account) the one line if is\\_prime[i]: is\\_prime[i*i::2*i]=False?\n",
      "\n",
      "â€“Â Lutz Lehmann\n",
      "\n",
      "Commented\n",
      "May 6, 2019 at 8:02\n",
      "\n",
      "1\n",
      "\n",
      "I figured it must be possible to simply use the empty list as the terminating condition for the loop and came up with this:\n",
      "\n",
      "```\n",
      "limit = 100\n",
      "ints = list(range(2, limit))   # Will end up empty\n",
      "\n",
      "while len(ints) > 0:\n",
      "    prime = ints[0]\n",
      "    print prime\n",
      "    ints.remove(prime)\n",
      "    i = 2\n",
      "    multiple = prime * i\n",
      "    while multiple <= limit:\n",
      "        if multiple in ints:\n",
      "            ints.remove(multiple)\n",
      "        i += 1\n",
      "        multiple = prime * i\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "1\n",
      "\n",
      "The fastest implementation I could come up with:\n",
      "\n",
      "```\n",
      "isprime = [True]*N\n",
      "isprime[0] = isprime[1] = False\n",
      "for i in range(4, N, 2):\n",
      "    isprime[i] = False\n",
      "for i in range(3, N, 2):\n",
      "    if isprime[i]:\n",
      "        for j in range(i*i, N, 2*i):\n",
      "            isprime[j] = False\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "1\n",
      "\n",
      "I just came up with this. It may not be the fastest, but I'm not using anything other than straight additions and comparisons. Of course, what stops you here is the recursion limit.\n",
      "\n",
      "```\n",
      "def nondivsby2():\n",
      "    j = 1\n",
      "    while True:\n",
      "        j += 2\n",
      "        yield j\n",
      "\n",
      "def nondivsbyk(k, nondivs):\n",
      "    j = 0\n",
      "    for i in nondivs:\n",
      "        while j < i:\n",
      "            j += k\n",
      "        if j > i:\n",
      "            yield i\n",
      "\n",
      "def primes():\n",
      "    nd = nondivsby2()\n",
      "    while True:\n",
      "        p = next(nd)\n",
      "        nd = nondivsbyk(p, nd)\n",
      "        yield p\n",
      "\n",
      "def main():\n",
      "    for p in primes():\n",
      "        print(p)\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "- very nice formulation, clean and clear and succinct! I'll bookmark it. of course, to produce the 100th prime with it, the nd chain will be 99 levels deep. but only 10 are truly needed. and it becomes worse and worse the farther we go along the primes list. can you find a way to deal with this problem? :)\n",
      "\n",
      "â€“Â Will Ness\n",
      "\n",
      "Commented\n",
      "Oct 6, 2020 at 13:30\n",
      "- also, I don't see any recursion here really, so there shouldn't be any limit to it here either. (of course I don't know Python almost at all)\n",
      "\n",
      "â€“Â Will Ness\n",
      "\n",
      "Commented\n",
      "Oct 6, 2020 at 13:33\n",
      "- I was surprised at first, when I got the RecursionError: maximum recursion depth exceeded exception. But then I thought it makes some sense. Because we can think of the generators as object with a \\_\\_next\\_\\_ function. So each nondivsbyk generator is an object of the same class (only different initialization). SUppose we call that class\\_nondivsbyk, so when one calls the other its actually class\\_nondivsbyk.\\_\\_next\\_\\_ calling another class\\_nondivsbyk.\\_\\_next\\_\\_ on another object.\n",
      "\n",
      "â€“Â tamir\n",
      "\n",
      "Commented\n",
      "Oct 8, 2020 at 6:30\n",
      "- About the 100th prime requiring only the first 10 primes, so first I can say that (as long as I don't want to give an upper limit) we need to 'collect' the primes on the way, so creating these generators seems necessary. I really don't know at the moment if I could 'skip' those irrelevant ones for the computation. Because now, I let each check if it's a divider, but if I put them aside, I would need something else to 'trigger' them when the numbers increase and I don't know how to integrate that to the recursion. I also made a \"flat\" version, I can take a look at that there. Thanks @WillNess\n",
      "\n",
      "â€“Â tamir\n",
      "\n",
      "Commented\n",
      "Oct 8, 2020 at 6:38\n",
      "- the two nds after the assignment nd = nondivsbyk(p, nd) are supposed to be two different objects. i.e., nd is a variable referring to a object, first; then new generator object is constructed by the function call, and assigned to the same variable (which forgets its old value). but inside, the new generator object refers to the older - different - object. but as I said, I don't know Python. about the 10 primes vs the 100 -- here's a hint: hopefully each call to primes() creates a separate, new, generator object. (or what's the proper terminology?)\n",
      "\n",
      "â€“Â Will Ness\n",
      "\n",
      "Commented\n",
      "Oct 8, 2020 at 18:07\n",
      "\n",
      "1\n",
      "\n",
      "I made a one liner version of the Sieve of Eratosthenes\n",
      "\n",
      "```\n",
      "sieve = lambda j: [print(x) for x in filter(lambda n: 0 not in map(lambda i: n % i, range(2, n)) and (n!=1)&(n!=0), range(j + 1))]\n",
      "```\n",
      "\n",
      "In terms of performance, I am pretty sure this isn't the fastest thing by any means, and in terms of readability / following PEP8, this is pretty terrible, but it's more the novelty of the length than anything.\n",
      "\n",
      "EDIT: Note that this simply prints the sieve &amp; does not return (if you attempt to print it you will get a list of Nones, if you want to return, change the print(x) in the list comprehension to just \"x\".\n",
      "\n",
      "answered\n",
      "\n",
      "1\n",
      "\n",
      "## Empirical Analysis and Visualization of Various Approaches to the Sieve of Eratosthenes\n",
      "\n",
      "I discovered this algorithm at the end of the 10th chapter (Maps, Hash Tables, and Skip Lists)\n",
      "of \"Data Structures &amp; Algorithms in Python\". I ended up writing three versions:\n",
      "\n",
      "- A naive implementation with a nasty cubic runtime (amongst many other issues, later resolved).\n",
      "- A suboptimal version after some thorough research, but I still wanted to get rid of the square-based multiples.\n",
      "- A fast and efficient version on par with the selected answer performance-wise, but with additive multiples (more intuitive for those less-mathematically inclined).\n",
      "\n",
      "### Naive SOE\n",
      "\n",
      "Out of all the issues, the additional space usage in the return statement takes the cake as the worst.\n",
      "\n",
      "```\n",
      "def naive_sieve(m: int):\n",
      "    BA = [True] * m\n",
      "    for i, k in zip(range(2, m + 1), range(len(BA))):\n",
      "        if BA[k] is False: continue\n",
      "        for j in range(2, i):\n",
      "            if i % j == 0:\n",
      "                BA[k] = False\n",
      "                f = k + j\n",
      "                while f < len(BA):\n",
      "                    BA[f] = False\n",
      "                    f += j\n",
      "                break\n",
      "    return [i for i,j in zip(range(2, m + 1), BA) if j is True]\n",
      "```\n",
      "\n",
      "### Suboptimal SOE\n",
      "\n",
      "A drastic improvement, but still lacking on space usage, and an unfriendly inner-loop interval progression.\n",
      "\n",
      "```\n",
      "def suboptimal_sieve(m: int):\n",
      "    BA = [True] * m\n",
      "    for i, k in zip(range(2, m + 1), range(2, len(BA))):\n",
      "        if BA[k] is False: continue\n",
      "        for j in range(i**2, m, i):\n",
      "            BA[j] = False\n",
      "    return [i for i,j in zip(range(2, m + 1), BA[2:]) if j is True]\n",
      "```\n",
      "\n",
      "### Fast SOE\n",
      "\n",
      "Easy to understand (note the usage of fractional exponent to be explicitly consistent with the mathematical definition of roots)\n",
      "and just as performant as @Pi Delport's answer.\n",
      "\n",
      "```\n",
      "def fast_sieve(m: int):\n",
      "    BA = [True] * m\n",
      "    rtm = int(m**(1/2)) + 1\n",
      "    for i in range(2, len(BA)):\n",
      "        if BA[i]:\n",
      "            yield i\n",
      "            if i < rtm:\n",
      "                f = i\n",
      "                while f < len(BA):\n",
      "                    BA[f] = False\n",
      "                    f += i\n",
      "```\n",
      "\n",
      "### Empirical Analysis\n",
      "\n",
      "To compare all three implementations, along with the selected answer from @Pi Delport,\n",
      "I ran it through 45 iterations from primes in range 100, until primes in range 4500, at intervals of 100\n",
      "(that's the sweet spot for the visualization, because despite the consistency of the shape of the graphs,\n",
      "the growth of the naive implementation dwarves the visibility of the other three).\n",
      "You can tweak the visualization code on the GitHub gist, but here's one sample output:\n",
      "\n",
      "answered\n",
      "\n",
      "1\n",
      "\n",
      "## Bitarray and 6k1 for size and speed\n",
      "\n",
      "1 billion in 5 seconds 2^24 in 3 milliseconds\n",
      "\n",
      "I used bitarray for a smaller footprint.  bitarray also allows statements like:\n",
      "\n",
      "```\n",
      "p[4::2] = False  # Clear multiples of 2\n",
      "```\n",
      "\n",
      "The sieve code will do 1 billion sized sieve in about 5 seconds on my old i7\n",
      "\n",
      "```\n",
      "$ python prime_count_test.py \n",
      "Creating new sieve of 100,000,000 primes.\n",
      " Make sieve for 100,000,000 took 0:00:00.306957 \n",
      "Count primes to: >1000000000\n",
      "Creating new sieve of 1,000,000,000 primes.\n",
      " Make sieve for 1,000,000,000 took 0:00:04.734377 \n",
      "From 1 to 1,000,000,000 there are 50,847,534  primes\n",
      " Search took 0:00:04.856540 \n",
      "\n",
      "Primes from 1,000,000 to 1,000,200 are \n",
      "1000003, 1000033, 1000037, 1000039, 1000081, 1000099, 1000117, 1000121, 1000133, 1000151, 1000159, 1000171, 1000183, 1000187, 1000193, 1000199\n",
      "\n",
      "Enter a number < 1,000,000,000  to test for prime> 10017\n",
      "10,017  is not prime\n",
      "```\n",
      "\n",
      "Here is my sieve:\n",
      "\n",
      "```\n",
      "from datetime import timedelta\n",
      "import time\n",
      "from bitarray import bitarray\n",
      "\n",
      "def get_primes(a_prime, start=0, end=100):\n",
      "    \"\"\"Return list of prime numbers in the range [start, end] using a_prime bitarray.\"\"\"\n",
      "    return [i for i in range(start, end + 1) if a_prime[i]]\n",
      "\n",
      "def make_sieve(size):\n",
      "    \"\"\"Create a sieve of Eratosthenes up to the given size.\"\"\"\n",
      "    sieve_time = time.time()\n",
      "    print(f\"Creating new sieve of {size:,} primes.\")\n",
      "    limit = int(1 + size**0.5) + 2\n",
      "    p = bitarray(size)  # One bit per value\n",
      "    p.setall(True)\n",
      "    p[0] = p[1] = False\n",
      "    p[4::2] = False  # Clear multiples of 2\n",
      "    p[9::3] = False  # Clear multiples of 3\n",
      "\n",
      "    for i in range(5, limit, 6):  # Process only numbers of the form 6k-1 and 6k+1\n",
      "        h = i + 2  # 6k+1\n",
      "        if p[i]:  # If 6k-1 is prime\n",
      "            p[3 * i::2 * i] = False  # Clear multiples of 6k-1\n",
      "        if p[h]:  # If 6k+1 is prime\n",
      "            p[3 * h::2 * h] = False  # Clear multiples of 6k+1\n",
      "    print(f\"Make sieve for {len(p):,} took {str(timedelta(seconds=time.time() - sieve_time))}\")\n",
      "    return p\n",
      "\n",
      "sieve_size = 10**8\n",
      "p = make_sieve(sieve_size)\n",
      "\n",
      "# Input for counting primes up to n\n",
      "n = int(input(\"Count primes to: >\"))\n",
      "start_time = time.time()\n",
      "\n",
      "if n <= sieve_size:\n",
      "    prime_count = p[1:n + 1].count()\n",
      "else:\n",
      "    p = make_sieve(n)\n",
      "    prime_count = p[1:n + 1].count()\n",
      "    sieve_size = len(p)\n",
      "\n",
      "print(f\"From 1 to {n:,} there are {prime_count:,} primes\")\n",
      "print(f\"Search took {str(timedelta(seconds=time.time() - start_time))}\")\n",
      "\n",
      "# Get 200 primes from the sieve starting at 1,000,000\n",
      "print(f\"\\nPrimes from 1,000,000 to 1,000,200 are:\")\n",
      "print(*get_primes(p, 10**6, 10**6 + 200), sep=', ')\n",
      "\n",
      "# Test if a specific number is prime\n",
      "test_p = int(input(f\"\\nEnter a number < {sieve_size:,} to test for prime> \"))\n",
      "print(f\"{test_p:,} {'is prime' if p[test_p] else 'is not prime'}\")\n",
      "```\n",
      "\n",
      "To just return primes:\n",
      "\n",
      "```\n",
      "from datetime import timedelta\n",
      "import time\n",
      "from bitarray import bitarray\n",
      "\n",
      "def get_primes(a_prime, start=0, end=100):\n",
      "    \"\"\"Return list of prime numbers in the range [start, end] using a_prime bitarray.\"\"\"\n",
      "    return [i for i in range(start, end + 1) if a_prime[i]]\n",
      "\n",
      "def make_sieve(size):\n",
      "    \"\"\"Create a sieve of Eratosthenes up to the given size.\"\"\"\n",
      "    sieve_time = time.time()\n",
      "    print(f\"Creating new sieve of {size:,} primes.\")\n",
      "    limit = int(1 + size**0.5) + 2\n",
      "    p = bitarray(size)  # One bit per value\n",
      "    p.setall(True)\n",
      "    p[0] = p[1] = False\n",
      "    p[4::2] = False  # Clear multiples of 2\n",
      "    p[9::3] = False  # Clear multiples of 3\n",
      "\n",
      "    for i in range(5, limit, 6):  # Process only numbers of the form 6k-1 and 6k+1\n",
      "        h = i + 2  # 6k+1\n",
      "        if p[i]:  # If 6k-1 is prime\n",
      "            p[i * i::2 * i] = False  # Clear multiples of 6k-1\n",
      "        if p[h]:  # If 6k+1 is prime\n",
      "            p[h * h::2 * h] = False  # Clear multiples of 6k+1\n",
      "    print(f\"Make sieve for {len(p):,} took {str(timedelta(seconds=time.time() - sieve_time))}\")\n",
      "    return [i for i in range(len(p)) if p[i]]\n",
      "start_time = time.time()\n",
      "n = 2**24\n",
      "p = make_sieve(n)\n",
      "print(f\"From 1 to {n:,} there are {len(p):,} primes\")\n",
      "\n",
      "print(p[0:200])\n",
      "```\n",
      "\n",
      "Output  Takes about .03 seconds for 2**24 search:\n",
      "\n",
      "```\n",
      "$ python prime_count_test.py \n",
      "Creating new sieve of 16,777,216 primes.\n",
      "Make sieve for 16,777,216 took 0:00:00.034416\n",
      "From 1 to 16,777,216 there are 1,077,871 primes\n",
      "[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311, 313, 317, 331, 337, 347, 349, 353, 359, 367, 373, 379, 383, 389, 397, 401, 409, 419, 421, 431, 433, 439, 443, 449, 457, 461, 463, 467, 479, 487, 491, 499, 503, 509, 521, 523, 541, 547, 557, 563, 569, 571, 577, 587, 593, 599, 601, 607, 613, 617, 619, 631, 641, 643, 647, 653, 659, 661, 673, 677, 683, 691, 701, 709, 719, 727, 733, 739, 743, 751, 757, 761, 769, 773, 787, 797, 809, 811, 821, 823, 827, 829, 839, 853, 857, 859, 863, 877, 881, 883, 887, 907, 911, 919, 929, 937, 941, 947, 953, 967, 971, 977, 983, 991, 997, 1009, 1013, 1019, 1021, 1031, 1033, 1039, 1049, 1051, 1061, 1063, 1069, 1087, 1091, 1093, 1097, 1103, 1109, 1117, 1123, 1129, 1151, 1153, 1163, 1171, 1181, 1187, 1193, 1201, 1213, 1217, 1223]\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "0\n",
      "\n",
      "My implementation:\n",
      "\n",
      "```\n",
      "import math\n",
      "n = 100\n",
      "marked = {}\n",
      "for i in range(2, int(math.sqrt(n))):\n",
      "    if not marked.get(i):\n",
      "        for x in range(i * i, n, i):\n",
      "            marked[x] = True\n",
      "\n",
      "for i in range(2, n):\n",
      "    if not marked.get(i):\n",
      "        print i\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "- I just testet your code and I see dict solution is 2 times slower than list solution.\n",
      "\n",
      "â€“Â MrHIDEn\n",
      "\n",
      "Commented\n",
      "Nov 28, 2016 at 8:54\n",
      "\n",
      "0\n",
      "\n",
      "```\n",
      "import math\n",
      "def sieve(n):\n",
      "    primes = [True]*n\n",
      "    primes[0] = False\n",
      "    primes[1] = False\n",
      "    for i in range(2,int(math.sqrt(n))+1):\n",
      "            j = i*i\n",
      "            while j < n:\n",
      "                    primes[j] = False\n",
      "                    j = j+i\n",
      "    return [x for x in range(n) if primes[x] == True]\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "0\n",
      "\n",
      "i think this is shortest code for finding primes with eratosthenes method\n",
      "\n",
      "```\n",
      "def prime(r):\n",
      "    n = range(2,r)\n",
      "    while len(n)>0:\n",
      "        yield n[0]\n",
      "        n = [x for x in n if x not in range(n[0],r,n[0])]\n",
      "\n",
      "print(list(prime(r)))\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "- 1\n",
      "\n",
      "The performance is absolutely horrible, though. It creates a whole new list at each iteration.\n",
      "\n",
      "â€“Â Eric Duminil\n",
      "\n",
      "Commented\n",
      "Oct 28, 2020 at 19:07\n",
      "\n",
      "0\n",
      "\n",
      "Probably the quickest way to have primary numbers is the following:\n",
      "\n",
      "```\n",
      "import sympy\n",
      "list(sympy.primerange(lower, upper+1))\n",
      "```\n",
      "\n",
      "In case you don't need to store them, just use the code above without conversion to the list. sympy.primerange is a generator, so it does not consume memory.\n",
      "\n",
      "answered\n",
      "\n",
      "- Please explain in the body of your answer why this is necessary and what improvement it brings to make it look a meaningful answer.\n",
      "\n",
      "â€“Â dmitryro\n",
      "\n",
      "Commented\n",
      "Nov 28, 2020 at 14:52\n",
      "\n",
      "0\n",
      "\n",
      "#### Basic sieve\n",
      "\n",
      "with numpy is amazing fast. May be the fastest implementation\n",
      "\n",
      "```\n",
      "# record: sieve 1_000_000_000 in 6.9s (core i7 - 2.6Ghz)\n",
      "def sieve_22max_naive(bound):\n",
      "    sieve = np.ones(bound, dtype=bool)  # default all prime\n",
      "    sieve[:2] = False  # 0, 1 is not prime\n",
      "\n",
      "    sqrt_bound = math.ceil(math.sqrt(bound))\n",
      "\n",
      "    for i in range(2, sqrt_bound):\n",
      "        if sieve[i]:\n",
      "            inc = i if i == 2 else 2 * i\n",
      "            sieve[i * i:bound:inc] = False\n",
      "\n",
      "    return np.arange(bound)[sieve]\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    start = time.time()\n",
      "    prime_list = sieve_22max_naive(1_000_000_000)\n",
      "    print(f'Count: {len(prime_list):,}\\n'\n",
      "          f'Greatest: {prime_list[-1]:,}\\n'\n",
      "          f'Elapsed: %.3f' % (time.time() - start))\n",
      "```\n",
      "\n",
      "#### Segment sieve (use less memory)\n",
      "\n",
      "```\n",
      "# find prime in range [from..N), base on primes in range [2..from)\n",
      "def sieve_era_part(primes, nfrom, n):\n",
      "    sieve_part = np.ones(n - nfrom, dtype=bool)  # default all prime\n",
      "\n",
      "    limit = math.ceil(math.sqrt(n))\n",
      "    # [2,3,5,7,11...p] can find primes < (p+2)^2\n",
      "    if primes[-1] < limit - 2:\n",
      "        print(f'Not enough base primes to find up to {n:,}')\n",
      "        return\n",
      "\n",
      "    for p in primes:\n",
      "        if p >= limit: break\n",
      "\n",
      "        mul = p * p\n",
      "        inc = p * (2 if p > 2 else 1)\n",
      "        if mul < nfrom:\n",
      "            mul = math.ceil(nfrom / p) * p\n",
      "            (mul := mul + p) if p > 2 and (mul & 1) == 0 else ...  # odd, not even\n",
      "\n",
      "        sieve_part[mul - nfrom::inc] = False\n",
      "\n",
      "    return np.arange(nfrom, n)[sieve_part]\n",
      "    # return np.where(sieve_part)[0] + nfrom\n",
      "    # return [i + nfrom for i, is_p in enumerate(sieve_part) if is_p]\n",
      "    # return [i for i in range(max(nfrom, 2), n) if sieve_part[i - nfrom]]\n",
      "\n",
      "# find nth prime number, use less memory,\n",
      "# extend bound to SEG_SIZE each loop\n",
      "# record: 50_847_534 nth prime in 6.78s, core i7 - 9850H 2.6GHhz\n",
      "def nth_prime(n):\n",
      "    # find prime up to bound\n",
      "    bound = 500_000\n",
      "    primes = sieve_22max_naive(bound)\n",
      "\n",
      "    SEG_SIZE = int(50e6)\n",
      "\n",
      "    while len(primes) < n:\n",
      "        # sieve for next segment\n",
      "        new_primes = sieve_era_part(primes, bound, bound + SEG_SIZE)\n",
      "        # extend primes\n",
      "        bound += SEG_SIZE\n",
      "        primes = np.append(primes, new_primes)\n",
      "\n",
      "    return primes[n - 1]\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    start = time.time()\n",
      "    prime = nth_prime(50_847_534)\n",
      "    print(f'{prime:,} Time %.6f' % (time.time() - start))\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "0\n",
      "\n",
      "Thanks for interesting question!\n",
      "\n",
      "Right now I wrote from scratch two versions of classical Sieve of Eratosthenes.\n",
      "\n",
      "One is single-core (CPU core), another one is multi-core (using all CPU cores).\n",
      "\n",
      "Main speedup of both (single and multi core) versions was due to using Numpy, official Python package. Install in once through command python -m pip install numpy. Another great speedup of multi-core version was due to usage of all CPU cores, which gives almost speedup N times for N cores, compared to single core version.\n",
      "\n",
      "Right now I have only two-core laptop. My program produced following timings:\n",
      "\n",
      "```\n",
      "Computing primes less than 8M\n",
      "Number of CPU cores 2\n",
      "Original time 72.57 sec\n",
      "Simple time 5.694 sec\n",
      "Simple boost (compared to original) 12.745x\n",
      "Multi core time 2.642 sec\n",
      "Multi core boost (compared to simple) 2.155x\n",
      "```\n",
      "\n",
      "Original above means your code from your question's body, the second one that you optimized already. Simple is my single core version. Multi is my multi core version.\n",
      "\n",
      "As you see above computing primes less than 8 Million took 72 seconds on your original code, my single core version took 5.7 seconds, which is 12.7x times faster than your code, and my 2-core version took 2.6 seconds, which is 2.1x times faster than my single core and 27x times faster than your original code.\n",
      "\n",
      "In other words I got 27x times speedup in my multi-core code compared to your code, really a lot! And this is only on 2-core laptop. If you have 8 cores or more then you'll get much bigger speedup. But remember that real speedup on multi core machine will be only for quite big prime number limit, try 64 Million limit or bigger, for this modify line primes\\_limit\\_M = 8 in my code to set amount of Millions.\n",
      "\n",
      "Just to dwell into details. My single core version is almost like your code, but uses Numpy which makes any array operations very fast, instead of using pure pythonic loops with lists.\n",
      "\n",
      "Multi core version also uses Numpy, but splits array with sieved range into as many pieces as there are CPU cores on your machine, each piece of array having equal size. Then every CPU core sets boolean flags in its own part of array. This technique gives speedup only till you hit speed limit of your memory (RAM), so after some point with growth of amount of CPU cores you don't get extra speedup.\n",
      "\n",
      "By default I use all CPU cores in multi core version, but you may experiment by setting less cores than you have on your machine, this may give even better speedup, because it is not guaranteed that most of cores will give exactly fastest result. Tweak amount of cores through changing line cpu\\_cores = mp.cpu\\_count() to something like cpu\\_cores = 3.\n",
      "\n",
      "Try it online!\n",
      "\n",
      "```\n",
      "def SieveOfEratosthenes_Original(end):\n",
      "    import numpy as np\n",
      "    limit = end - 1\n",
      "    limitn = limit+1\n",
      "    primes = dict()\n",
      "    for i in range(2, limitn): primes[i] = True\n",
      "\n",
      "    for i in primes:\n",
      "        factors = range(i,limitn, i)\n",
      "        for f in factors[1:]:\n",
      "            primes[f] = False\n",
      "    return np.array([i for i in primes if primes[i]==True], dtype = np.uint32)\n",
      "\n",
      "def SieveOfEratosthenes_Simple(end):\n",
      "    # https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes\n",
      "    import numpy as np\n",
      "    composites = np.zeros((end,), dtype = np.uint8)\n",
      "    composites[:2] = 1\n",
      "    for p, c in enumerate(composites):\n",
      "        if c:\n",
      "            continue\n",
      "        composites[p * p :: p] = 1\n",
      "    return np.array([p for p, c in enumerate(composites) if not c],\n",
      "        dtype = np.uint32)\n",
      "\n",
      "def SieveOfEratosthenes_Task(small_primes, begin, end):\n",
      "    import numpy as np\n",
      "    composites = np.zeros((end - begin,), dtype = np.uint8)\n",
      "    offsets = np.full((len(small_primes),), begin, dtype = np.uint32)\n",
      "    offsets = small_primes - offsets % small_primes\n",
      "    offsets[offsets == small_primes] = 0\n",
      "    for off, p in zip(offsets, small_primes):\n",
      "        composites[off :: p] = 1\n",
      "    return np.array([begin + i for i, c in enumerate(composites) if not c],\n",
      "        dtype = np.uint32)\n",
      "\n",
      "def SieveOfEratosthenes_MultiCore(end, *, nthreads = None):\n",
      "    import math, multiprocessing as mp, numpy as np\n",
      "    end_small = math.ceil(math.sqrt(end)) + 1\n",
      "    small_primes = SieveOfEratosthenes_Simple(end_small)\n",
      "    if nthreads is None:\n",
      "        nthreads = mp.cpu_count()\n",
      "    block = (end - end_small + nthreads - 1) // nthreads\n",
      "    with mp.Pool(nthreads) as pool:\n",
      "        return np.concatenate([small_primes] + pool.starmap(SieveOfEratosthenes_Task, [\n",
      "            (small_primes, min(end_small + ithr * block, end), min(end_small + (ithr + 1) * block, end))\n",
      "            for ithr in range(nthreads)]))\n",
      "\n",
      "def Test():\n",
      "    import time, numpy as np, multiprocessing as mp\n",
      "    primes_limit_M = 8\n",
      "    cpu_cores = mp.cpu_count()\n",
      "    end = primes_limit_M * 2 ** 20\n",
      "    print(f'Computing primes less than {primes_limit_M}M')\n",
      "    print('Number of CPU cores', cpu_cores, flush = True)\n",
      "    tim_orig = time.time()\n",
      "    res_orig = SieveOfEratosthenes_Original(end)\n",
      "    tim_orig = time.time() - tim_orig\n",
      "    print('Original time', round(tim_orig, 3), 'sec', flush = True)\n",
      "    tim_simple = time.time()\n",
      "    res_simple = SieveOfEratosthenes_Simple(end)\n",
      "    tim_simple = time.time() - tim_simple\n",
      "    print('Simple time', round(tim_simple, 3), 'sec', flush = True)\n",
      "    assert np.all(res_orig == res_simple)\n",
      "    print(f'Simple boost (compared to original) {tim_orig / tim_simple:.3f}x')\n",
      "    tim_multi = time.time()\n",
      "    res_multi = SieveOfEratosthenes_MultiCore(end, nthreads = cpu_cores)\n",
      "    tim_multi = time.time() - tim_multi\n",
      "    print('Multi core time', round(tim_multi, 3), 'sec', flush = True)\n",
      "    assert np.all(res_simple == res_multi)\n",
      "    print(f'Multi core boost (compared to simple) {tim_simple / tim_multi:.3f}x')\n",
      "if __name__ == '__main__':\n",
      "    Test()\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "0\n",
      "\n",
      "```\n",
      "import math\n",
      "\n",
      "def atkin_sieve(limit):\n",
      "   primes = [False] * (limit + 1)\n",
      "   square_limit = int(math.sqrt(limit))\n",
      "\n",
      "#   ,    2, 3  5\n",
      "for i in range(1, square_limit + 1):\n",
      "    for j in range(1, square_limit + 1):\n",
      "        num = 4 * i**2 + j**2\n",
      "        if num <= limit and (num % 12 == 1 or num % 12 == 5):\n",
      "            primes[num] = not primes[num]\n",
      "\n",
      "        num = 3 * i**2 + j**2\n",
      "        if num <= limit and num % 12 == 7:\n",
      "            primes[num] = not primes[num]\n",
      "\n",
      "        num = 3 * i**2 - j**2\n",
      "        if i > j and num <= limit and num % 12 == 11:\n",
      "            primes[num] = not primes[num]\n",
      "\n",
      "#     \n",
      "for i in range(5, square_limit):\n",
      "    if primes[i]:\n",
      "        for j in range(i**2, limit + 1, i**2):\n",
      "            primes[j] = False\n",
      "\n",
      "#    \n",
      "return [2, 3] + [i for i in range(5, limit) if primes[i]]\n",
      "\n",
      "#  \n",
      "print(atkin_sieve(100))\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "0\n",
      "\n",
      "If your looking for even faster, you can use numba and cuda as well if\n",
      "you have a Nvidia processor. Feel free to optimize as needed. We use 2**24 which is ~16 million numbers at 239 ms on an Nvidia 3070.\n",
      "\n",
      "```\n",
      "from numba import cuda\n",
      "import numpy as np\n",
      "\n",
      "@cuda.jit\n",
      "def findprimes(primes, sqrt_limit):\n",
      "    index = cuda.grid(1)\n",
      "    if index >= primes.size or index < 2:\n",
      "        return\n",
      "    if index <= sqrt_limit:\n",
      "        if primes[index]:\n",
      "            for multiple in range(index*index, primes.size, index):\n",
      "                primes[multiple] = False\n",
      "\n",
      "def fast_sieve_gpu(m):\n",
      "    primes = np.ones(m, dtype=bool)\n",
      "    primes[0] = primes[1] = False\n",
      "    sqrt_limit = int(np.sqrt(m))\n",
      "    d_primes = cuda.to_device(primes)\n",
      "    threads_per_block = 128\n",
      "    blocks_per_grid = (m + threads_per_block - 1) // threads_per_block\n",
      "    findprimes[blocks_per_grid, threads_per_block](d_primes, sqrt_limit)\n",
      "    primes = d_primes.copy_to_host()\n",
      "    prime_numbers = np.nonzero(primes)[0]\n",
      "    return prime_numbers\n",
      "\n",
      "m = 2**24 # 16777216\n",
      "prime_numbers = fast_sieve_gpu(m)\n",
      "print(prime_numbers)\n",
      "%timeit fast_sieve_gpu(m)\n",
      "```\n",
      "\n",
      "```\n",
      "# Output (this is 2**24 which is 16x of 2**20) : \n",
      "# [       2        3        5 ... 16777183 16777199 16777213]\n",
      "# 239 ms  2.66 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "-1\n",
      "\n",
      "not sure if my code is efficeient, anyone care to comment?\n",
      "\n",
      "```\n",
      "from math import isqrt\n",
      "\n",
      "def isPrime(n):\n",
      "    if n >= 2: # cheating the 2, is 2 even prime?\n",
      "        for i in range(3, int(n / 2 + 1),2): # dont waste time with even numbers\n",
      "            if n % i == 0:\n",
      "                return False\n",
      "    return True\n",
      "\n",
      "def primesTo(n): \n",
      "    x = [2] if n >= 2 else [] # cheat the only even prime\n",
      "    if n >= 2:\n",
      "        for i in range(3, n + 1,2): # dont waste time with even numbers\n",
      "            if isPrime(i):\n",
      "                x.append(i)  \n",
      "    return x\n",
      "\n",
      "def primes2(n): # trying to do this using set methods and the \"Sieve of Eratosthenes\"\n",
      "    base = {2} # again cheating the 2\n",
      "    base.update(set(range(3, n + 1, 2))) # build the base of odd numbers\n",
      "    for i in range(3, isqrt(n) + 1, 2): # apply the sieve\n",
      "        base.difference_update(set(range(2 * i, n + 1 , i)))\n",
      "    return list(base)\n",
      "\n",
      "print(primesTo(10000)) # 2 different methods for comparison\n",
      "print(primes2(10000))\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "-1\n",
      "\n",
      "Using recursion and walrus operator:\n",
      "\n",
      "```\n",
      "def prime_factors(n):\n",
      "    for i in range(2, int(n ** 0.5) + 1):\n",
      "        if (q_r := divmod(n, i))[1] == 0:\n",
      "            return [i] + factor_list(q_r[0])\n",
      "    return [n]\n",
      "```\n",
      "\n",
      "answered\n",
      "\n",
      "## Your Answer\n",
      "\n",
      "Thanks for contributing an answer to Stack Overflow!\n",
      "\n",
      "- Please be sure to answer the question. Provide details and share your research!\n",
      "\n",
      "But avoid\n",
      "\n",
      "- Asking for help, clarification, or responding to other answers.\n",
      "- Making statements based on opinion; back them up with references or personal experience.\n",
      "\n",
      "To learn more, see our tips on writing great answers.\n",
      "\n",
      "Draft saved\n",
      "\n",
      "Draft discarded\n",
      "\n",
      "### Sign up or log in\n",
      "\n",
      "Sign up using Google\n",
      "\n",
      "Sign up using Email and Password\n",
      "\n",
      "### Post as a guest\n",
      "\n",
      "Required, but never shown\n",
      "\n",
      "### Post as a guest\n",
      "\n",
      "Required, but never shown\n",
      "\n",
      "By clicking Post Your Answer, you agree to our terms of service and acknowledge you have read our privacy policy.\n",
      "\n",
      "Start asking to get answers\n",
      "\n",
      "Find the answer to your question by asking.\n",
      "\n",
      "Explore related questions\n",
      "\n",
      "- python\n",
      "- math\n",
      "- primes\n",
      "- sieve-of-eratosthenes\n",
      "\n",
      "See similar questions with these tags.\n",
      "\n",
      "- The Overflow Blog\n",
      "- Boots on the ground: Holistic AI and Audioshake at HumanX\n",
      "- Featured on Meta\n",
      "- Experimenting with a new experiment opt-out option\n",
      "- Changes to reporting for the [status-review] escalation process\n",
      "- Policy: Generative AI (e.g., ChatGPT) is banned\n",
      "\n",
      "#### Linked\n",
      "\n",
      "8\n",
      "\n",
      "3\n",
      "\n",
      "-2\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "0\n",
      "\n",
      "402\n",
      "\n",
      "72\n",
      "\n",
      "44\n",
      "\n",
      "21\n",
      "\n",
      "#### Related\n",
      "\n",
      "0\n",
      "\n",
      "2\n",
      "\n",
      "0\n",
      "\n",
      "8\n",
      "\n",
      "1\n",
      "\n",
      "0\n",
      "\n",
      "3\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "1\n",
      "\n",
      "#### Hot Network Questions\n",
      "\n",
      "- What does the word TrÃ¤ge mean in the English language?\n",
      "- I accidentally plugged headphones in the AUX IN of a digital piano\n",
      "- Is there a good reason why meat cooking times are generally quoted as linear with respect to weight?\n",
      "- Employer wants something unethical, can you refuse even during the notice period?\n",
      "- Conflicting notation for periods of elliptic functions\n",
      "- Why shred before LUKS disk encryption?\n",
      "- How different do we ever find ordinal numbers from cardinals?\n",
      "- Help identify this very early airplane\n",
      "- Do any parties in Denmark support preventing Greenland from becoming independent?\n",
      "- A Poundless Brit\n",
      "- Is pseudonymization using LLM considered as hashing?\n",
      "- What instruments did the first dashboard include?\n",
      "- Do referees know each other's identities in single-blind reviews?\n",
      "- Extracting model coefficients for formula terms\n",
      "- Can I raise the collar ties in my 1700s house roof?\n",
      "- Calculating the mean, not variance, reduces the degrees of freedom?\n",
      "- Convert from 50 Hz to 60 Hz vintage digital alarm clock\n",
      "- Only 1 of 2 solutions returned by DSolve\n",
      "- Help the inspector by finding a route of minimum total length\n",
      "- How would I create a paper wrapped bottle effect\n",
      "- How does PCIe know which card to use for legacy ISA I/O ports?\n",
      "- Repeating Textures\n",
      "- On what ground did Wisconsin courts dismiss the legal challenge to Elon Musk's million-dollar giveaways?\n",
      "- If a metric conserves open spaces, then sequences maintain their limits.\n",
      "\n",
      "# Subscribe to RSS\n",
      "\n",
      "To subscribe to this RSS feed, copy and paste this URL into your RSS reader.\n",
      "\n",
      "lang-py\n",
      "\n",
      "##### Stack Overflow\n",
      "\n",
      "- Questions\n",
      "- Help\n",
      "- Chat\n",
      "\n",
      "##### Products\n",
      "\n",
      "- Teams\n",
      "- Advertising\n",
      "- Talent\n",
      "\n",
      "##### Company\n",
      "\n",
      "- About\n",
      "- Press\n",
      "- Work Here\n",
      "- Legal\n",
      "- Privacy Policy\n",
      "- Terms of Service\n",
      "- Contact Us\n",
      "- Cookie Settings\n",
      "- Cookie Policy\n",
      "\n",
      "##### Stack Exchange Network\n",
      "\n",
      "- Technology\n",
      "- Culture &amp; recreation\n",
      "- Life &amp; arts\n",
      "- Science\n",
      "- Professional\n",
      "- Business\n",
      "- API\n",
      "- Data\n",
      "\n",
      "- Blog\n",
      "- Facebook\n",
      "- Twitter\n",
      "- LinkedIn\n",
      "- Instagram\n",
      "\n",
      "Site design / logo  2025 Stack Exchange Inc; \n",
      "user contributions licensed under \n",
      "CC BY-SA\n",
      ". \n",
      "revÂ 2025.4.1.24628\n"
     ]
    }
   ],
   "source": [
    "print(url_content('https://stackoverflow.com/questions/3939660/sieve-of-eratosthenes-finding-primes-python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
