{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ohi/Documents/GitHub/PersonalAssistant/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import ollama\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from duckduckgo_search import DDGS\n",
    "\n",
    "# ds = load_dataset(\"neural-bridge/rag-dataset-12000\")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phi3 templates\n",
    "\n",
    "search_query_template = \\\n",
    "\"\"\"<|system|>\n",
    "You are a helpful assistant. You will be asked a question. Imagine you do not know the answer of the question. As a result, you want to search the web to find the answer. For the given user question, write a search question that could be used in search engine to find the answer to the question. The search string that you would produce should be inside <search tag>. \n",
    "For example: <search> your search string </search><|end|>\n",
    "<|user|>\n",
    "{query}<|end|>\n",
    "<|assistant|>\n",
    "Sure! Here is the one short search string that I would use to search on the web:\n",
    "<search>\"\"\"\n",
    "\n",
    "\n",
    "question_gen_template = \\\n",
    "\"\"\"<|system|>\n",
    "You are a helpful assistant who is very good at generating question. The user would give you a topic, you have to come up with a question so that the question can be used to train a good quality LLM.<|end|>\n",
    "<|user|>\n",
    "Generate question in topic of: {topic_name}\n",
    "\n",
    "Produce the question inside \"question\" tag. Example: <question> your generated question </question><|end|>\n",
    "<|assistant|>\n",
    "Sure! Here is the question on topic {topic_name}:\n",
    "<question>\"\"\"\n",
    "\n",
    "# Ref: https://huggingface.co/learn/cookbook/en/llm_judge\n",
    "llm_judge_search_prompt = \\\n",
    "\"\"\"<|system|>\n",
    "You will be given a topic, user_question, and search_string triplet.\n",
    "Your task is to provide a 'total rating' scoring how well the search_string alings the user concerns expressed in the user_question.\n",
    "Give your answer on a scale of 1 to 4, where 1 means that the system_answer is not helpful at all, and 4 means that the system_answer completely and helpfully addresses the user_question.\n",
    "\n",
    "Here is the scale you should use to build your answer:\n",
    "1: The system_question is not on topic: completely irrelevant to the topic, or very partial\n",
    "2: The system_question is mostly not helpful: has grammatical error or seems to be incomplete\n",
    "3: The search_string is mostly helpful: provides concise prompt that can be used in web search engine\n",
    "4: The search_string is excellent: relevant, direct, and addresses important concerns raised in the system_question\n",
    "\n",
    "Use the following rubrics to award the points:\n",
    "- Award 1 point if the user_question is related to the topic.\n",
    "- Give 1 additional point if the system_question is clear and precise.\n",
    "- Provide 1 further point if the search_str is concise.\n",
    "- One final point should be awarded if the search_str is direct and addresses important concerns raised in system_question.\n",
    "\n",
    "Provide your feedback as follows:\n",
    "\n",
    "Feedback:::\n",
    "Evaluation: <eval> (your rationale for the rating, as a text) </eval>\n",
    "Total rating: <rating> (your rating, as a number between 1 and 4) </rating>\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.<|end|>\n",
    "<|user|>\n",
    "Now here are the question and answer.\n",
    "\n",
    "Topic: {topic}\n",
    "Question: {question}\n",
    "Search string: {search_str}\n",
    "\n",
    "Provide your feedback. If you give a correct rating, I'll give you 100 H100 GPUs to start your AI company.<|end|>\n",
    "<|assistant|>\n",
    "Feedback:::\n",
    "Evaluation: <eval>\"\"\"\n",
    "\n",
    "\n",
    "llm_judge_prompt = \\\n",
    "\"\"\"<|system|>\n",
    "You will be given a user_question and system_answer couple.\n",
    "Your task is to provide a 'total rating' scoring how well the system_answer answers the user concerns expressed in the user_question.\n",
    "Give your answer on a scale of 1 to 4, where 1 means that the system_answer is not helpful at all, and 4 means that the system_answer completely and helpfully addresses the user_question.\n",
    "\n",
    "Here is the scale you should use to build your answer:\n",
    "1: The system_answer is terrible: completely irrelevant to the question asked, or very partial\n",
    "2: The system_answer is mostly not helpful: misses some key aspects of the question\n",
    "3: The system_answer is mostly helpful: provides support, but still could be improved\n",
    "4: The system_answer is excellent: relevant, direct, detailed, and addresses all the concerns raised in the question\n",
    "\n",
    "Use the following rubrics to award the points:\n",
    "- Award 1 point if the answer is related to the question.\n",
    "- Give 1 additional point if the answer is clear and precise.\n",
    "- Provide 1 further point if the answer is true.\n",
    "- One final point should be awarded if the answer provides additional resources to support the user.\n",
    "\n",
    "\n",
    "Provide your feedback as follows:\n",
    "\n",
    "Feedback:::\n",
    "Evaluation: <eval> (your rationale for the rating, as a text) </eval>\n",
    "Total rating: <rating> (your rating, as a number between 1 and 4) </rating>\n",
    "\n",
    "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.<|end|>\n",
    "<|user|>\n",
    "Now here are the question and answer.\n",
    "\n",
    "Question: {question}\n",
    "Answer: {answer}\n",
    "\n",
    "Provide your feedback. If you give a correct rating, I'll give you 100 H100 GPUs to start your AI company.<|end|>\n",
    "<|assistant|>\n",
    "Feedback:::\n",
    "Evaluation: <eval>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ollama/ollama-python/blob/main/examples/async-chat-stream/main.py\n",
    "def ollama_infr(prompt, extra_stops=[], model='phi3.5:latest', temperature=0.7):\n",
    "    # https://github.com/ollama/ollama-python/blob/00eafed0faa5dea6879a8eb3229c7a8f2439abb4/ollama/_types.py#L93\n",
    "    return ollama.generate(\n",
    "        model = model,\n",
    "        # system = system,\n",
    "        # Raw is set to true to feed the question as needed\n",
    "        raw=True,\n",
    "        prompt = prompt,\n",
    "        stream = True,\n",
    "        # Number of seconds to keep the connection alive\n",
    "        keep_alive=60*60,\n",
    "        options = {\n",
    "            'stop': [\n",
    "                \"<|start_header_id|>\",\n",
    "                \"<|end_header_id|>\",\n",
    "                \"<|eot_id|>\",\n",
    "            ] + extra_stops,\n",
    "            'temperature': temperature,\n",
    "            # 'top_k': 1,\n",
    "            'cache': False,\n",
    "            # 'tfs_z': 2.0,\n",
    "            'num_ctx': 6000,\n",
    "            # 'temperature': 0.0,\n",
    "            # 'top_p': 0.0\n",
    "        },\n",
    "    )\n",
    "\n",
    "DATA_PATH = \"datasets/search_data.jsonl\"\n",
    "def write_jsonl(data: dict):\n",
    "    with open(DATA_PATH, \"a\") as f:\n",
    "        f.write(json.dumps(data) + \"\\n\")\n",
    "\n",
    "\n",
    "def extract_rating(input_str:str):\n",
    "    data = input_str.split('<rating>')[1]\n",
    "    data = data.strip()\n",
    "\n",
    "    try:\n",
    "        return float(data)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek_r1 = '''You are a helpful AI. You will be given a question and a context. You have to first think (in 150 words) and then come up with the final answer based on the question and user-provided context\n",
    "\n",
    "<｜User｜>User question: {question}\n",
    "\n",
    "Use the following content to answer user question:\n",
    "{context}\n",
    "\n",
    "<｜end▁of▁sentence｜>\n",
    "<｜Assistant｜>\n",
    "<think>\n",
    "I will finish thinking in at most 150 words. Now let's think. '''\n",
    "\n",
    "def r1_response(question, context):    \n",
    "    prompt = deepseek_r1.format(question=question, context=context)\n",
    "    # print(\"Question:\", data['question'], flush=True)\n",
    "\n",
    "    stream = ollama_infr(prompt=prompt, model='deepseek-r1:7b', temperature=0.5)\n",
    "    model_res = '<think>\\n'\n",
    "    n_think_tokens = 0\n",
    "    think_finished = False\n",
    "\n",
    "    for part in stream:\n",
    "        print(part['response'], sep='', end='', flush=True)\n",
    "        model_res += part['response']\n",
    "\n",
    "        if not think_finished and '</think>' in model_res:\n",
    "            think_finished = True\n",
    "        if not think_finished:\n",
    "            n_think_tokens += 1\n",
    "\n",
    "        if n_think_tokens > 256:\n",
    "            print(\"Generation limit exceeded\", flush=True)\n",
    "            return None, None\n",
    "\n",
    "    think = re.findall(r\"<think>(.*?)</think>\", model_res, re.DOTALL)[0].strip()\n",
    "    answer = model_res[model_res.find(\"</think>\")+len(\"</think>\"):].strip()\n",
    "\n",
    "    if not answer:\n",
    "        return None, None\n",
    "    \n",
    "    return think, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_template = \\\n",
    "\"\"\"<|system|>\n",
    "You are a helpful assistant. You will be given a web content in markdown format. You have to provide a summary of the web content.\n",
    "You have to summarize the web content inside 'summary' tag.\n",
    "For example: <summary> your summarization content in markdown </summary><|end|>\n",
    "<|user|>\n",
    "{web_content}<|end|>\n",
    "<|assistant|>\n",
    "Sure! Here is the summarized version of the provided content:\n",
    "<summary>\"\"\"\n",
    "\n",
    "def web_content_summarize(web_content):\n",
    "    prompt = summarize_template.format(web_content=web_content)\n",
    "    # print(\"Question:\", data['question'], flush=True)\n",
    "\n",
    "    stream = ollama_infr(prompt=prompt, model='phi3.5:latest', temperature=0.5)\n",
    "    model_res = '<summary>\\n'\n",
    "    n_tokens = 0\n",
    "\n",
    "    for part in stream:\n",
    "        print(part['response'], sep='', end='', flush=True)\n",
    "        model_res += part['response']\n",
    "        n_tokens += 1\n",
    "\n",
    "        if n_tokens > 4000:\n",
    "            break\n",
    "\n",
    "    summary = re.findall(r\"<summary>(.*?)</summary>\", model_res, re.DOTALL)#[0].strip()    \n",
    "    if summary:\n",
    "        return summary[0].strip()\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_content(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Remove scripts, styles, navs, headers, footers, and typical ad elements\n",
    "    for tag in soup(['script', 'style', 'nav', 'header', 'footer', 'aside', 'form', 'noscript', 'iframe']):\n",
    "        tag.decompose()\n",
    "\n",
    "    ad_classes = ['advertisement', 'ad', 'adsbygoogle', 'promo', 'banner', 'cookie-banner', 'subscribe']\n",
    "    for class_name in ad_classes:\n",
    "        for tag in soup.select(f'.{class_name}, #{class_name}'):\n",
    "            tag.decompose()\n",
    "\n",
    "    # Remove all links and their content\n",
    "    for a_tag in soup.find_all('a'):\n",
    "        a_tag.decompose()\n",
    "\n",
    "    # Markdown content building\n",
    "    markdown_lines = []\n",
    "\n",
    "    # Process headings and paragraphs\n",
    "    for element in soup.body.descendants if soup.body else soup.descendants:\n",
    "        if element.name:\n",
    "            if element.name in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:\n",
    "                level = int(element.name[1])\n",
    "                markdown_lines.append(f\"{'#' * level} {element.get_text(strip=True)}\\n\")\n",
    "            elif element.name in ['ul', 'ol']:\n",
    "                for li in element.find_all('li'):\n",
    "                    markdown_lines.append(f\"- {li.get_text(strip=True)}\")\n",
    "            elif element.name == 'p':\n",
    "                text = element.get_text(strip=True)\n",
    "                if text:\n",
    "                    markdown_lines.append(f\"{text}\\n\")\n",
    "\n",
    "    # Final cleanup: remove empty lines\n",
    "    markdown_lines = list(filter(lambda x: len(x) > 2, markdown_lines))\n",
    "    markdown_content = '\\n'.join([line for line in markdown_lines if line.strip()])    \n",
    "    # print(\"URL EXTRACTED:\", markdown_lines, flush=True)\n",
    "    return markdown_content\n",
    "\n",
    "\n",
    "def search_tool(search_str, max_results=1):\n",
    "    rets = None\n",
    "    with DDGS() as ddg:\n",
    "        rets = list(ddg.text(keywords=search_str, region=\"wt-wt\", max_results=7))\n",
    "\n",
    "    str_rets = ''\n",
    "    web_source = []\n",
    "    n_results, i = 0, -1\n",
    "    while len(web_source) < max_results and i+1 < len(rets):\n",
    "        i += 1\n",
    "        try:\n",
    "            print(\"Parsing url:\", rets[i]['href'], flush=True)\n",
    "            web_content = url_content(rets[i]['href'])[:1024*4] + \" ...\"\n",
    "            web_content = web_content.strip()\n",
    "            if web_content == '':\n",
    "                continue\n",
    "\n",
    "            # web_content = web_content_summarize(web_content=web_content)\n",
    "            content = f\"\\n# Source {n_results+1}:\"\n",
    "            content += \"\\n\" + \"-\" * len(content) + f\"\\n\\n{web_content}\\n\\n\"\n",
    "            str_rets += content\n",
    "            web_source.append(rets[i]['href'])\n",
    "        except Exception as E:\n",
    "            continue\n",
    "        \n",
    "    return str_rets, web_source\n",
    "\n",
    "# print(search_tool('current methods used by scientists to improve predictions of climate change and its environmental impact', max_results=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing url: https://codezup.com/mastering-dynamic-memory-allocation-cpp/\n",
      "Parsing url: https://stackoverflow.com/questions/76608458/best-practice-for-managing-dynamic-allocated-memory-in-c\n",
      "Parsing url: https://techgeekspro.com/technology/c-memory-management-best-practices-techniques-and-tips/\n",
      "Parsing url: https://codezup.com/c-memory-management-practical-guide/\n",
      "Parsing url: https://arbisoft.com/blogs/efficient-memory-management-in-c-techniques-tools-and-best-practices\n",
      "('\\n# Source 1:\\n------------\\n\\n##### Collectives™ on Stack Overflow\\n\\nFind centralized, trusted content and collaborate around the technologies you use most.\\n\\nTeams\\n\\nQ&A for work\\n\\nConnect and share knowledge within a single location that is structured and easy to search.\\n\\n# \\n\\nI\\'m playing around with the Qt library to get a better understanding for OOP.\\nOne thing I implemented is a QGraphicsView, which display\\'s an image. Therefore, the data has to outlive the scope of the funtion it is \"created\" in, so I called it with the \"new\" operator. I know that the memory once allocated with \"new\" has to be deallocated with \"delete\", but that\\'s not possible out of scope. So I figured (and this is where I did not find a clear answer unfortunately) I\\'ll use a map to store the address of the memory to delete it when I load a new image. But is that good practice or even correct?\\n\\n- Smart pointers for when such thing is truly needed. Here a better design is to make it so that the value doesn\\'t fall out of scope just useQGraphicsScene scene;Why recreate the scene here? You canclear()it and add the new pixmap, so you can for example set up the scene where you create the view.  (Also, scale the view to the image pixmap instead?)–CommentedJul 3, 2023 at 22:56\\n- 1The problem here is that if you ask ten C++ developers if <X>  is \"good practice\" you\\'re guaranteed to receive at least eleven different answers...–CommentedJul 3, 2023 at 22:58\\n- Qt is a mature and powerful framework, by all means go explore it, it lets you build terrific stuff. It might not be the first place to learn about \"classic\" OOP though, there\\'s too much happening behind the scenes for that.–CommentedJul 4, 2023 at 5:34\\n## 1 Answer1\\n\\nQt has its own way of dealing with memory with QObjects, (QGraphicsScene inherits QObject). You passedthisas a parent, and we don\\'t know which parent is referred to withthis, but if the parent (this) outlives the QGraphicsScene you created you are fine. Because Qt will properly delete your QGraphicsScene whenthisgets deleted. Qt world is a bit more complex than C++ world and allocating new objects on the heap there is the way to go without dealing with their deletion. However don\\'t forget to delete any memory you allocated outside of Qt\\'s world. Happy coding :)\\n\\nSee :\\n\\nEdit: To go further and as a more general C++ advice, I\\'ll add that your function is definitely a class method as you are allowed to usethis. If you want to manage the memory by yourself within this class, then you should store this pointer as a class attribute. Then in any other method could you delete this pointer. Even better, if the object you allocate is supposed to live exactly the same amount of time as your class referenced to asthismake it a non-pointer (plainQGraphicsSceneinstead ofQGraphicsScene*) and initialize it as your class gets constructed and let the destruction automatically be handled by the compiler. But that\\'s not always what you want with QObject-derived classes. Another powerfull C++ tool is to make use ofand allocate your pointer in the class constructor and delete it in the class destructor so that you still allocate it on the heap (if it\\'s a large object or a large array for example - but for large arrays usestd::vectorreally) and make sure you delete it properly no matter what.\\n\\n- Thank you very much! I used the Mainwindow as a parent here. Unfortunately, it seems that object does not deallocate the memory used from the image before once you load a new image. Thats what brought me to use this map here.–CommentedJul 5, 2023 at 21:32\\n- @DBMC_y337 Could you edit your question with more context, then ? Like, when do you populate your map and which image are your refering to, as well as when and why do you want it deleted ? You shouldn\\'t have to use an allocation map ever.–CommentedJul 6, 2023 at 19:20\\n- Before I used the map, I just created a QGraphicsScene* scene = new QGraphicsScene. Because of that, of course the old memory didnt get deallocated but every call of the function allocated new memory for a new image.–CommentedJul 6, 2023 at 22:24\\n- @DBMC_y337 Why didn\\'t you just store th ...\\n\\n\\n# Source 1:\\n------------\\n\\nTable of Contents\\n\\n## Introduction\\n\\nMemory management is a critical aspect of programming in C++. Memory allocation is the process of reserving a block of memory for use by a program. In C++, there are two main types of memory allocation: static and dynamic.\\n\\n- Static memory allocationis performed at compile time. The amount of memory allocated is fixed and cannot be changed at runtime. Static memory allocation is used for variables that are declared in the global scope or in the local scope of a function.\\n- Dynamic memory allocationis performed at runtime. The amount of memory allocated can be changed at runtime. Dynamic memory allocation is used for variables that need to be created and destroyed at runtime, such as objects.\\nEfficient memory usage not only enhances the performance of your applications but also helps prevent common pitfalls like memory leaks and crashes. In this comprehensive tutorial, we’ll delve into the intricacies of memory management in C++, discussing dynamic memory allocation, memory leaks, stack vs. heap, smart pointers, and best practices for beginners. Whether you’re a novice or an experienced developer, understanding these concepts is vital for creating robust and optimized C++ applications.\\n\\n## 1. Understanding Memory Management in C++\\n\\nBefore diving into the technical details, let’s grasp the basics of memory management in C++. In C++, memory management primarily involves allocating and deallocating memory for variables, data structures, and objects. There are two main memory areas: the stack and the heap.\\n\\n- The stackis a region of memory that is reserved for local variables. The stack is managed automatically by the compiler, so programmers do not need to worry about allocating and deallocating memory on the stack.\\n- The heapis a region of memory that is reserved for dynamically allocated objects. Programmers must use thenewanddeleteoperators to allocate and deallocate memory on the heap.\\n## 2. Dynamic Memory Allocation in C++\\n\\nDynamic memory allocation allows you to allocate memory during runtime using pointers. Thenewoperator is used for allocation, and thedeleteoperator is used for deallocation. Here’s a simple example:\\n\\nHowever, improper use of dynamic memory allocation can lead to memory leaks.\\n\\n## 3. Preventing Memory Leaks in C++\\n\\nMemory leaks occur when allocated memory is not properly deallocated, leading to a gradual loss of available memory. To prevent memory leaks, ensure you deallocate memory using thedeleteoperator:\\n\\nConsider using smart pointers to automate memory management and reduce the chances of memory leaks.\\n\\n## 4. Stack vs. Heap in C++\\n\\nIn C++, variables can be stored on the stack or the heap. Stack memory is used for local variables and is automatically managed, whereas heap memory is manually managed using dynamic memory allocation. Stack memory is faster to access, while heap memory provides greater flexibility in memory allocation.\\n\\n## 5. Utilizing Smart Pointers\\n\\nC++11 introduced smart pointers that provide automated memory management, reducing the likelihood of memory leaks. There are three types of smart pointers:unique_ptr,shared_ptr, andweak_ptr.\\n\\nHere’s an example of usingunique_ptr:\\n\\n## 6. Best Practices for Memory Management in C++\\n\\nFor beginners and experienced developers alike, adhering to memory management best practices is crucial:\\n\\n- Use stack memory for small, short-lived variables.\\n- Prefer smart pointers over raw pointers.\\n- Be cautious with circular references, which can prevent memory from being properly deallocated.\\n- Always deallocate dynamically allocated memory usingdeleteor appropriate smart pointers.\\n- Usestd::vectorand other standard containers instead of managing memory manually.\\n## 7. Memory Management in C++ for Game Development\\n\\nGame development demands efficient memory management to ensure smooth performance. Consider the following tips:\\n\\n- Use object pooling to reuse memory for frequently created and destroyed game objects.\\n- Minimize memory fragmentation by using memory allocators optimized for game engines.\\n- Profile and optimize  ...\\n\\n\\n# Source 1:\\n------------\\n\\n# Efficient Memory Management in C/C++: Techniques, Tools, and Best Practices\\n\\nWorking with memory in C++ feels like having a superpower - it gives you total control over how your program runs. But, like any superpower, it comes with responsibilities. Misusing this control can lead to frustrating problems like memory leaks, crashes, or those tricky dangling pointers that haunt developers for hours (or days!).\\n\\nThese issues often creep in when we manually manage resources like memory, file handles, or sockets. The good news? There’s a smarter way to handle this:\\xa0RAII (Resource Acquisition Is Initialization). It’s a simple concept that can save you tons of time, frustration, and bug-hunting. Let’s break it down.\\n\\n## What Exactly is RAII?\\n\\nRAII is a fancy name for a simple and powerful idea: tie your resources to the lifecycle of objects. If you create an object that uses a resource (like memory or a file), the resource is acquired when the object is created and automatically released when the object is destroyed.\\n\\nThink of it like a “set it and forget it” approach. You don’t have to manually clean things up because RAII does the work for you.\\n\\n## Why Should You Care About RAII?\\n\\nHere’s why RAII is a game-changer:\\n\\n- No More Resource Leaks: Forget to release a resource? Doesn’t matter—RAII has your back. If something goes wrong (like an exception), the object’s destructor ensures everything gets cleaned up properly.\\n- Cleaner, Simpler Code: Instead of scattering cleanup logic everywhere, RAII keeps it tidy. No need to remember tofree()memory orclose()files. It happens automatically.\\n- Fewer Bugs: Manual memory management is error-prone. With RAII, you reduce those hard-to-find bugs caused by forgetting to clean up resources.\\nIt’s like having a safety net: even if your program takes an unexpected turn, you know your resources are handled.\\n\\n### Example\\n\\nTo understand RAII, consider managing file resources. Without RAII, developers need to close files manually, risking leaks if an exception interrupts the program flow. For example:\\n\\nWith RAII, resource cleanup becomes automatic, as shown below:\\n\\nThe resource cleanup is guaranteed, even if an exception occurs or if the function returns early. The destructor of\\xa0std::ifstream ensures the file is properly closed.\\n\\n## Utilize Smart Pointers\\n\\nSmart pointers in C++ are assistants that take care of the memory for a specific variable. They handle the memory allocation and deallocation themselves so there is less chance of memory leaks or memory being destroyed more than once which is common in traditional C++ programming.\\n\\nFor example,std::unique_ptrensures only one pointer owns a piece of memory at any given time. So you don’t have to worry about deleting the same memory twice. On the other hand,std::shared_ptrallows multiple pointers to share the same memory. Smart pointers help manage memory by keeping count of how many parts of the program are using it. The memory is only deleted once everyone is finished with it.\\n\\nThis approach helps prevent memory issues while coding. Think of it as a safety net that automatically cleans up when we\\'re done, allowing us to focus on writing clear and simple code. Here\\'s an example to show how it works:\\n\\n### Example\\n\\nSuppose that you’re using a C++ dynamically allocated integer. If you are managing the memory yourself, you’d need thenewto allocate and thedeleteto clean up. The delete step can be easily forgotten which will lead to a memory leak. Worse, if you call delete twice by accident, it can crash your program.\\n\\nThe following snippet demonstrates the use ofstd:unique_ptr, which is a smart pointer for guaranteeing that memory management of the allocated object is done correctly and the memory is freed when the actual pointer is out of any scope.\\n\\nCombining smart pointers with static analyzers likeorcan further enhance code safety by identifying any misuse of smart pointers, and leveragingcan streamline the detection of potential memory issues.\\n\\n## Build Custom Memory Allocators\\n\\nIn performance-critical C++ programs that involve the regular creat ...\\n\\n', ['https://stackoverflow.com/questions/76608458/best-practice-for-managing-dynamic-allocated-memory-in-c', 'https://techgeekspro.com/technology/c-memory-management-best-practices-techniques-and-tips/', 'https://arbisoft.com/blogs/efficient-memory-management-in-c-techniques-tools-and-best-practices'])\n"
     ]
    }
   ],
   "source": [
    "print(search_tool(\"best practices for dynamic memory management and object destruction in C++\", 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Topic: python coding problems\n",
      " Given a list of integers, how would you write a Python function to find and return all unique pairs within the list that sum up"
     ]
    }
   ],
   "source": [
    "topics = [\"python math question\", \"git\", \"problem solving\", \"python debugging\", \"current knowledge\", \"terminal commands\", \"python coding problems\", \"computer science\"]\n",
    "\n",
    "for _ in range(500):\n",
    "    topic = random.choice(topics)\n",
    "    # topic = \"greeting\"\n",
    "    print(f\"## Topic: {topic}\", flush=True)\n",
    "    stream = ollama_infr(question_gen_template.format(topic_name=topic), extra_stops=[\"</question>\"])\n",
    "    question = ''\n",
    "    for part in stream:\n",
    "        print(part['response'], sep='', end='', flush=True)\n",
    "        question += part['response']\n",
    "        if len(question) > 1000:\n",
    "            break\n",
    "    print(flush=True)\n",
    "\n",
    "    if len(question) > 1000:\n",
    "        print(\"Question overflow\", flush=True)\n",
    "        continue\n",
    "    question = question.strip()\n",
    "\n",
    "    stream = ollama_infr(search_query_template.format(query=question), extra_stops=[\"</search>\"], temperature=0.3)\n",
    "    search_str = ''\n",
    "    print(\"Search str: \", end='', flush=True)\n",
    "    for part in stream:\n",
    "        print(part['response'], sep='', end='', flush=True)\n",
    "        search_str += part['response']\n",
    "    print(flush=True)\n",
    "    search_str = search_str.strip()\n",
    "    search_str = search_str.replace('\"', '')\n",
    "\n",
    "    if len(search_str) > 300:\n",
    "        print(\"Ignoring question and search string as search_str length is greater than limit\", flush=True)\n",
    "        continue\n",
    "\n",
    "    max_results = random.choice(range(1, 4))\n",
    "    context, source_urls = search_tool(search_str, max_results=max_results)\n",
    "    if context.strip() == '': \n",
    "        print(\"Empty context found\", flush=True)\n",
    "        continue\n",
    "    \n",
    "    print(\"### Search results:\", flush=True)\n",
    "    print(context, flush=True)\n",
    "    print(flush=True)\n",
    "\n",
    "    print(\"### Deepseek-r1\", flush=True)\n",
    "    think, answer = r1_response(question=question, context=context)\n",
    "    if answer is None:\n",
    "        print(\"No answer found from deepseek-r1\", flush=True)\n",
    "        continue\n",
    "\n",
    "    print(\"\\n\\n### LLM As Judge\", flush=True)\n",
    "    stream = ollama_infr(llm_judge_prompt.format(question=question, answer=answer), extra_stops=[\"</rating>\"])\n",
    "    judge_response = ''\n",
    "    for part in stream:\n",
    "        print(part['response'], sep='', end='', flush=True)\n",
    "        judge_response += part['response']\n",
    "\n",
    "    rating = extract_rating(judge_response)\n",
    "    print(\"\\n\\nRATING:\", rating, end=\"\", flush=True)\n",
    "    print(\"\\n--------\", flush=True)\n",
    "\n",
    "    if rating is not None and rating >= 3.0:\n",
    "        write_jsonl({\n",
    "            \"question\": question,\n",
    "            \"search_str\": search_str,\n",
    "            \"search_results\": context,\n",
    "            \"source_urls\": source_urls,\n",
    "            \"think\": think,\n",
    "            \"answer\": answer,\n",
    "            \"judge_response\": judge_response,\n",
    "            \"judge_rating\": rating\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
